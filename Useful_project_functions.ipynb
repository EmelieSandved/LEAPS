{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f0616f1-7c9a-43b6-9717-815d02d64524",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d3085-c71f-4480-b9e6-694553820078",
   "metadata": {},
   "source": [
    "I am cutting out/excluding:\n",
    "\n",
    "- parts of isochrones that cannot be fitted with a polynomial\n",
    "- cluster stars that do not fall within isochrone range\n",
    "- cluster stars that do not fall within isochrone range when doing interpolations\n",
    "- I am not counting in empty bins when fitting functions to the IMFs\n",
    "- I am not taking Kroopa intervals into account if they contain one or none bins\n",
    "\n",
    "\n",
    "Other notes:\n",
    "\n",
    "- The slopes are most reliable for $0.5$ to $1.0 \\,$M$_{\\odot}$ because there, both isochrone models are more complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdf3aa6-3b56-4397-8319-bb6704f4da22",
   "metadata": {},
   "source": [
    "**MIST**\n",
    "\n",
    "Challenges with MIST:\n",
    "\n",
    "- Contains giant branch, which makes isochrone polynomial fit impossible $\\rightarrow$ I am cutting off the isochrone at magnitude 0\n",
    "- Does not include high enough colours (only goes slightly past colour value of 3 whereas Baraffe goes past 5)\n",
    "- The lack of colours is because is does not contain masses below 0.1 solar masses whereas Baraffe goes down to 0.01\n",
    "- This limitation in colour removes a lot of the low-mass stars, which means that the age is underestimated and the IMF is more limited\n",
    "\n",
    "Benefits with MIST:\n",
    "\n",
    "- Contains higher stellar masses\n",
    "- Contains lower magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336870a-9cdb-40f3-bb18-8a1fa143003d",
   "metadata": {},
   "source": [
    "**Baraffe**\n",
    "\n",
    "Challenges with Baraffe:\n",
    "\n",
    "- Only contains few isochrones. This can somewhat be removed as a problem by interpolating between isochrones\n",
    "- Only has low magnitudes\n",
    "- Has a short colour range\n",
    "- Only contains stellar masses below $1.4 \\,$M$_{\\odot}$\n",
    "- The upper mass limit makes all high-mass stars get an interpolated mass of $1.4 \\,$M$_{\\odot}$, which is mis-leading and gives a bad IMF slope\n",
    "\n",
    "\n",
    "Benefits with Baraffe:\n",
    "\n",
    "- So far gives similar ages to the pre-determined ones\n",
    "- Contains low-mass stars\n",
    "- Contains very red stars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdcd0db",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9aeb9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as scopt\n",
    "from scipy import stats\n",
    "import sympy as sp\n",
    "\n",
    "\n",
    "# Astropy imports\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "from astropy.table import QTable\n",
    "from astropy.coordinates import Distance\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import votable\n",
    "\n",
    "# Special import\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d38bf31f-2417-4339-942d-70f92ac093c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'xtick.labelsize':15, 'ytick.labelsize':15, 'axes.titlesize':18, \n",
    "                     'axes.grid':True, 'axes.labelsize':14, 'legend.fontsize':14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f60a0",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd10b090",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f2b537",
   "metadata": {},
   "source": [
    "The distance modulus is calculated through \\textit{distance.distmod} and it is mathematically given by\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mu = 5 \\log_{10} d - 5 = m - M \\iff M = m - \\mu.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2ed533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_import(file_name):\n",
    "    \"\"\"\n",
    "    Imports the cluster data file and adds a distance column, an absolute magnitude column\n",
    "    and a G_BP-G_RP column\n",
    "    ---------------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    \n",
    "    file_name: str\n",
    "        The name of the data file that contains the data\n",
    "        \n",
    "    ---------------------------------------------------------------------------------------\n",
    "    Output:\n",
    "    \n",
    "    data: astropy QTable\n",
    "        Returns an astropy QTable with all the data including the units\n",
    "    \"\"\"\n",
    "    \n",
    "    data = QTable.read(f'Data/Clusters/{file_name}.txt', \n",
    "                         names=['GaiaID', 'gal_long', 'gal_lat', 'parallax', 'e_parallax', 'RA_pm', \n",
    "                                'e_RA_pm', 'DE_pm', 'e_DE_pm', 'M_apparent', 'G_BP', 'G_RP', \n",
    "                                'Flag', 'Cluster_id', 'RA_icrs', 'DE_icrs'], \n",
    "                         units = [u.m/u.m, u.deg, u.deg, u.mas, u.mas, u.mas/u.yr, u.mas/u.yr, \n",
    "                                  u.mas/u.yr, u.mas/u.yr, u.mag, u.mag, u.mag, u.m/u.m, u.m/u.m, \n",
    "                                  u.deg, u.deg], delimiter=' ', format = 'ascii')\n",
    "    \n",
    "    # Adds a distance column and converts the parallaxes to distance in pc\n",
    "    data['dist'] = Distance(parallax=data['parallax'])\n",
    "\n",
    "\n",
    "    # Calculates and adds an absolute magnitude column calculated from the photometric mean magnitude \n",
    "    # and the distance modulus, described above\n",
    "    data['M_V'] = data['M_apparent'] - data['dist'].distmod\n",
    "\n",
    "    # Calculating and adding G_bp - G_rp\n",
    "    data['bp_rp'] = data['G_BP'] - data['G_RP']\n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d461e-a594-4a95-b87a-156db30b2f62",
   "metadata": {},
   "source": [
    "## Importing and separating isochrones from one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b23244ae-be55-4fd2-93f2-65e9e441cc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def separate_isochrones(model, metallicity, survey):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: str\n",
    "        Name of isochrone model\n",
    "        \n",
    "    metallicity: str\n",
    "        String with metallicity value\n",
    "        \n",
    "    survey: str\n",
    "        Which survey was used, which affects the magnitude units\n",
    "    \"\"\"\n",
    "    all_iso = [] # List to gather all data for all isochrones in\n",
    "    models = ['Baraffe', 'MIST', 'Marigo'] # List of models\n",
    "    # List of filenames\n",
    "    file_names = [f'Baraffe_{survey}.txt', \n",
    "                  f'MIST_v1.2_feh_{metallicity}_vvcrit0.00.txt']\n",
    "    \n",
    "    list_position = models.index(model) # Finding list position for model\n",
    "    file_name = file_names[list_position] # Extracting filename\n",
    "    \n",
    "    # Opens file to read content\n",
    "    with open(f'Data/Isochrones/{model}/{file_name}', \"r\") as iso_file: \n",
    "        age = [] # List to put isochrone data divided by age (final output of function)\n",
    "        lines = [] # List to put all the line information into\n",
    "        \n",
    "        # Loops over every line and stores the data for all lines (all isochrones) in a list\n",
    "        for line in iso_file: # loop through each line\n",
    "            if line.startswith('#'): # do not add lines that don't contain any data\n",
    "                continue\n",
    "            elif line.startswith('!'):\n",
    "                continue\n",
    "            elif line.startswith(' !'):\n",
    "                continue\n",
    "            elif len(line)<2:\n",
    "                continue\n",
    "            else: # If it contains data, add it to list\n",
    "                val = line.split() # split each line and store them in a list\n",
    "                lines.append(val) # Store list of line values in another list\n",
    "        \n",
    "        \n",
    "        if model=='Baraffe':\n",
    "            iso_data_list = [] # List to fill with isochrone data points\n",
    "            iso_ages_list= []\n",
    "            # Looping over all lines and adding interesting ones to data lists\n",
    "            for i, l_vals in enumerate(lines, start=1): # l_vals = list of line/column values\n",
    "                #print(l_vals)\n",
    "                # if equal to 1 means new age\n",
    "                \n",
    "                if len(l_vals)==1: # means old list is finished\n",
    "                    if iso_data_list != []:\n",
    "                        # Want to add finished list to list with all isochrones\n",
    "                        # converting to array with shape:(n_points, parameters)\n",
    "                        iso_data_array = np.array(iso_data_list) \n",
    "                    \n",
    "                        # adding isochrone's data to isochrone list\n",
    "                        all_iso.append(iso_data_array.astype(float))\n",
    "            \n",
    "                    # making new list\n",
    "                    iso_data_list = []\n",
    "                    iso_ages_list.append(l_vals)\n",
    "                    \n",
    "            \n",
    "                else: # if the age is the same \n",
    "                    iso_data_list.append(l_vals) # filling old list\n",
    "            \n",
    "                if i==len(lines): # appends the last isochrone\n",
    "                    iso_data_list.append(l_vals)\n",
    "                    # converting to array with shape:(n_points, parameters)\n",
    "                    iso_data_array = np.array(iso_data_list)\n",
    "                    # adding isochrone's data to isochrone list\n",
    "                    all_iso.append(iso_data_array.astype(float)) \n",
    "            \n",
    "            iso_ages_array = np.array(iso_ages_list, dtype=float)\n",
    "            \n",
    "              \n",
    "        if model=='MIST':\n",
    "            iso_data_list = [] # List to fill with isichrone data points\n",
    "            iso_ages_list = []\n",
    "            iso_age = lines[0][1]\n",
    "            iso_ages_list.append(iso_age) # setting first iso_age\n",
    "            iso_data_list.append(lines[0]) # Adding first data line to list\n",
    "            # Looping over all lines and adding interesting ones to data lists\n",
    "            for i, l_vals in enumerate(lines, start=1): # l_vals = list of line/column values\n",
    "                \n",
    "                line_age = l_vals[1]\n",
    "                \n",
    "                # checking if isochrone age is same as before, is same\n",
    "                # If True, then this means that the old list is finished\n",
    "                if line_age!=iso_age: \n",
    "                    # Want to add finished list to list with all isochrones\n",
    "                    # converting to array with shape:(n_points, parameters)\n",
    "                    iso_data_array = np.array(iso_data_list) \n",
    "                    # adding isochrone's data to isochrone list\n",
    "                    all_iso.append(iso_data_array.astype(float)) \n",
    "            \n",
    "                    # Starting new list with new age\n",
    "                    iso_age = l_vals[1] # Otherwise replacing it with the new value\n",
    "                    iso_ages_list.append(iso_age)\n",
    "                    \n",
    "                    # making new list\n",
    "                    iso_data_list = []\n",
    "                    iso_data_list.append(l_vals)\n",
    "            \n",
    "                else: # if the age is the same   \n",
    "                    iso_data_list.append(l_vals) # filling old list\n",
    "            \n",
    "                if i==len(lines): # appends the last isochrone\n",
    "                    iso_data_list.append(l_vals)\n",
    "                    # converting to array with shape:(n_points, parameters)\n",
    "                    iso_data_array = np.array(iso_data_list) \n",
    "                    # adding isochrone's data to isochrone list\n",
    "                    all_iso.append(iso_data_array.astype(float)) \n",
    "                    \n",
    "                iso_ages_arr = np.array(iso_ages_list, dtype=float) # in MIST unit\n",
    "                iso_ages_array = 10**(iso_ages_arr)*10**(-9) # Converts to Gyr\n",
    "                \n",
    "    iso_file.close()   \n",
    "    \n",
    "    # Only keeping the relevant information from the isochrones\n",
    "    for i, iso in enumerate(all_iso):\n",
    "        \n",
    "        if survey=='gaia':\n",
    "            new_iso_array = np.empty((len(iso), 4)) # Contains: time, mass, M_V, bp_rp\n",
    "            \n",
    "            if model=='Baraffe':\n",
    "                # Adding the age to the new array\n",
    "                new_iso_array[:, 0] = iso_ages_array[i]\n",
    "                new_iso_array[:, 1] = iso[:, 0] # Adding the mass to the new array \n",
    "                new_iso_array[:, 2] = iso[:, 22] # Adding M_V\n",
    "                    \n",
    "                bp = iso[:, 23]\n",
    "                rp = iso[:, 24]\n",
    "                new_iso_array[:, 3] = bp-rp # Adding bp_rp\n",
    "                \n",
    "            elif model=='MIST':\n",
    "                # Adding the age to the new array and converting to Gyr\n",
    "                new_iso_array[:, 0] = 10**(iso[:, 1])*10**(-9) \n",
    "                new_iso_array[:, 1] = iso[:, 3] # Adding the mass to the new array (initial mass vs star mass???)\n",
    "                new_iso_array[:, 2] = iso[:, 30] # Adding M_V\n",
    "                \n",
    "                bp = iso[:, 31]\n",
    "                rp = iso[:, 32]\n",
    "                new_iso_array[:, 3] = bp-rp # Adding bp_rp to array\n",
    "                #new_iso_array = new_iso_array[new_iso_array[:, 3].argsort()] # sort after colour\n",
    "                magnitude_mask = 0<new_iso_array[:, 2]\n",
    "                new_iso_array = new_iso_array[magnitude_mask]\n",
    "                \n",
    "                \n",
    "        elif survey=='2mass':\n",
    "            new_iso_array = np.empty((len(iso), 5)) # Contains: time, mass, J, H, K\n",
    "            \n",
    "            if model=='Baraffe':\n",
    "                # Adding the age to the new array\n",
    "                new_iso_array[:, 0] = iso_ages_array[i]\n",
    "                new_iso_array[:, 1] = iso[:, 0] # Adding the mass to the new array \n",
    "                new_iso_array[:, 2] = iso[:, 6] # Adding J\n",
    "                new_iso_array[:, 3] = iso[:, 7] # Adding H\n",
    "                new_iso_array[:, 4] = iso[:, 8] # Adding K\n",
    "                \n",
    "            elif model=='MIST':\n",
    "                # Adding the age to the new array and converting to Gyr\n",
    "                new_iso_array[:, 0] = 10**(iso[:, 1])*10**(-9) \n",
    "                new_iso_array[:, 1] = iso[:, 3] # Adding the mass to the new array (initial mass vs star mass???)\n",
    "                new_iso_array[:, 2] = iso[:, 14] # Adding J\n",
    "                new_iso_array[:, 3] = iso[:, 15] # Adding H\n",
    "                new_iso_array[:, 4] = iso[:, 16] # Adding K\n",
    "                \n",
    "                #magnitude_mask = 0<new_iso_array[:, 2]\n",
    "                #new_iso_array = new_iso_array[magnitude_mask]\n",
    "                \n",
    "        all_iso[i] = new_iso_array\n",
    "    \n",
    "    return all_iso, iso_ages_array\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b51ba",
   "metadata": {},
   "source": [
    "## Importing the isochrone data and extracting fitting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec86447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isochrone_params(isos_data, model, survey):\n",
    "    \"\"\"\n",
    "    Imports the isochrone data file\n",
    "    ---------------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    \n",
    "    file_names: lst\n",
    "        List of the file names of the data files that contains each isochrone's data\n",
    "        \n",
    "    model: str or list\n",
    "        The name of the model isochrone to use\n",
    "        \n",
    "    ---------------------------------------------------------------------------------------\n",
    "    Output:\n",
    "    \n",
    "    data: array\n",
    "        Returns an array with all the isochrone data for plotting with [G, G_BP-G_RP]\n",
    "    \"\"\"\n",
    "    # Useful lists\n",
    "    #models = ['Baraffe'] # List of model names\n",
    "    \n",
    "    #column_names = [['Mass', 'Teff', 'Luminosity', 'g', 'Radius', 'Li', 'F33', 'F33B', 'F41', 'F45B', \n",
    "    #                 'F47', 'F51', 'FHa', 'F57', 'F63B', 'F67', 'F75', 'F78', 'F82', 'F82B', 'F89', \n",
    "    #                 'G_RSV', 'M_V', 'G_BP', 'G_RP']] # List of column names for each model\n",
    "    \n",
    "    #units = [[u.Msun, u.K, u.Lsun, u.m/u.m, u.Rsun, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, \n",
    "    #          u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, \n",
    "    #          u.m/u.m, u.m/u.m, u.m/u.m, u.mag, u.mag, u.mag]] # List of units for the columns for each model\n",
    "    \n",
    "    #Useful parameter for the loop\n",
    "    #i = models.index(model)\n",
    "    \n",
    "    #all_iso_data = []\n",
    "    \n",
    "    fit_params = np.empty((6, len(isos_data)))\n",
    "    \n",
    "    for j, isochrone in enumerate(isos_data):\n",
    "        \n",
    "        #iso_data = QTable.read(f'Data/Isochrones/{model}/Isochrone_{model}_{isochrone}.txt', \n",
    "        #                       names=column_names[i], units = units[i], delimiter=' ', \n",
    "        #                       format = 'ascii')\n",
    "        \n",
    "        #iso_data['bp_rp'] = iso_data['G_BP'] - iso_data['G_RP'] # Calculating colour\n",
    "        \n",
    "        #data = np.empty((len(iso_data), 3))\n",
    "        #data[:, 0] = iso_data['M_V']\n",
    "        #data[:, 1] = iso_data['bp_rp']\n",
    "        #data[:, 2] = iso_data['Mass']\n",
    "        \n",
    "        #all_iso_data.append(data)\n",
    "        \n",
    "        if survey=='gaia':\n",
    "        \n",
    "            magn_mask = (isochrone[:, 2]<16) & (isochrone[:, 2]>0)# Magnitude mask\n",
    "        \n",
    "            iso_x = isochrone[:, 3][magn_mask] # Colour\n",
    "            iso_y = isochrone[:, 2][magn_mask] # Magnitude\n",
    "        \n",
    "            k5, k4, k3, k2, k1, c = np.polyfit(iso_x, iso_y, 5)\n",
    "            \n",
    "            \n",
    "        elif survey=='2mass':\n",
    "        \n",
    "            magn_mask = (isochrone[:, 2]<16) & (isochrone[:, 2]>0)# J mask\n",
    "        \n",
    "            iso_x = isochrone[:, 2][magn_mask] - isochrone[:, 4][magn_mask] # Colour, J-K\n",
    "            iso_y = isochrone[:, 2][magn_mask] # J\n",
    "        \n",
    "            k5, k4, k3, k2, k1, c = np.polyfit(iso_x, iso_y, 5)\n",
    "        \n",
    "        \n",
    "        fit_params[0, j] = k5\n",
    "        fit_params[1, j] = k4 \n",
    "        fit_params[2, j] = k3 \n",
    "        fit_params[3, j] = k2 \n",
    "        fit_params[4, j] = k1 \n",
    "        fit_params[5, j] = c\n",
    "    \n",
    "    return fit_params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b269d3b",
   "metadata": {},
   "source": [
    "## Plotting isochrones with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e123ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_iso_and_data(all_data, all_iso_data, cluster_names, model, survey, data_alpha=0.5,\n",
    "                          CMD_or_mass='CMD'): # n_plots=1\n",
    "    \"\"\"\n",
    "    Plots the data and/or isochrones\n",
    "    ----------------------------------\n",
    "    Parameters:\n",
    "    \n",
    "    all_data: list of arrays\n",
    "        List of data for different clusters\n",
    "        \n",
    "    all_iso_data: list of arrays\n",
    "        List of data from one or several different isochrones\n",
    "        \n",
    "    cluster_names: list\n",
    "        List or string with names of the used clusters\n",
    "        \n",
    "    n_plots: int\n",
    "        The number of plots to plot\n",
    "        \n",
    "    Output:\n",
    "    --------\n",
    "    Plot\n",
    "    \"\"\"\n",
    "    # 16 different colours to plot\n",
    "    colours = ['b', 'r', 'deepskyblue', 'firebrick', 'cyan', 'crimson', 'teal', 'peru', 'orange',  \n",
    "               'blueviolet', 'silver', 'purple', 'dimgray', 'magenta', 'g', 'lawngreen']\n",
    "    \n",
    "    rev_colours = colours[::-1]\n",
    "    \n",
    "    if all_data==None: # Only plotting isochrones\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        if survey=='gaia':\n",
    "            if CMD_or_mass == 'CMD':\n",
    "                for i, iso in enumerate(all_iso_data):\n",
    "                        ax.plot(iso[:, 3], iso[:, 2], color=colours[i], label=f't = {iso[i, 0]:.1e} Gyr')\n",
    "            \n",
    "                ax.set_xlabel(r'G$_{BP}$ - G$_{RP}$ [mag]')\n",
    "                ax.set_ylabel(r'M$_{V}$ [mag]')\n",
    "                ax.set_title(f'CMD for {len(all_iso_data)} {model} isochrones')\n",
    "                ax.invert_yaxis()\n",
    "            \n",
    "            elif CMD_or_mass == 'mass':\n",
    "                for i, iso in enumerate(all_iso):\n",
    "                    ax.plot(iso[:, 3], iso[:, 1], color=colours[i], label=f't = {iso[i, 0]:.1e} Gyr')\n",
    "            \n",
    "                ax.set_xlabel(r'G$_{BP}$ - G$_{RP}$ [mag]')\n",
    "                ax.set_ylabel(r'Mass [M$_{\\odot}$]')\n",
    "                ax.set_title(f'Mass vs colour for {len(all_iso_data)} {model} isochrones')\n",
    "                \n",
    "        if survey=='2mass':\n",
    "            if CMD_or_mass == 'CMD':\n",
    "                for i, iso in enumerate(all_iso_data):\n",
    "                    iso_colour = iso[:, 2] - iso[:, 4]\n",
    "                    ax.plot(iso_colour, iso[:, 2], color=colours[i], label=f't = {iso[i, 0]:.1e} Gyr')\n",
    "            \n",
    "                ax.set_xlabel(r'J - K [mag]')\n",
    "                ax.set_ylabel(r'J [mag]')\n",
    "                ax.set_title(f'CMD for {len(all_iso_data)} {model} isochrones')\n",
    "                ax.invert_yaxis()\n",
    "            \n",
    "            elif CMD_or_mass == 'mass':\n",
    "                for i, iso in enumerate(all_iso):\n",
    "                    iso_colour = iso[:, 2] - iso[:, 4]\n",
    "                    ax.plot(iso_colour, iso[:, 1], color=colours[i], label=f't = {iso[i, 0]:.1e} Gyr')\n",
    "            \n",
    "                ax.set_xlabel(r'J - K [mag]')\n",
    "                ax.set_ylabel(r'Mass [M$_{\\odot}$]')\n",
    "                ax.set_title(f'Mass vs colour for {len(all_iso_data)} {model} isochrones')\n",
    "            \n",
    "        ax.legend()\n",
    "            \n",
    "        ax.grid(True)\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "    elif all_iso_data==None: # Only plotting data\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        for i, data in enumerate(all_data):\n",
    "            ax.scatter(data['bp_rp'].value, data['M_V'].value, c=rev_colours[i], \n",
    "                       alpha=data_alpha, s=10, label=f'Cluster {cluster_names[i]}')\n",
    "        \n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel(r'G$_{BP}$ - G$_{RP}$ [mag]')\n",
    "        ax.set_ylabel(r'M$_{V}$ [mag]')\n",
    "        ax.set_title(f'Cluster data for {len(all_data)} clusters')\n",
    "        ax.legend()\n",
    "            \n",
    "        ax.grid(True)\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    elif (all_data!=None) and (all_iso_data!=None): # Plotting both\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "            \n",
    "        # Plotting data\n",
    "        for i, data in enumerate(all_data):\n",
    "            ax.scatter(data['bp_rp'].value, data['M_V'].value, c=rev_colours[i], \n",
    "                   alpha=data_alpha, s=10, label=f'Cluster {cluster_names[i]}')\n",
    "            \n",
    "        # Plotting isochrones\n",
    "        for i, iso in enumerate(all_iso_data):\n",
    "            ax.plot(iso[:, 3], iso[:, 2], color=colours[i], label=f't = {iso[i, 0]} Gyr')\n",
    "                \n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel(r'G$_{BP}$ - G$_{RP}$ [mag]')\n",
    "        ax.set_ylabel(r'M$_{V}$ [mag]')\n",
    "        ax.set_title(f'Cluster data for {len(all_data)} clusters and isochrones')\n",
    "        ax.legend()\n",
    "            \n",
    "        ax.grid(True)\n",
    "            \n",
    "        plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de788be2-db55-4e76-84c0-d81006b1758a",
   "metadata": {},
   "source": [
    "## Fitting function for isochrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc01cb0-2ea5-4f07-8407-6469efbb0d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_fcn(x, args):\n",
    "    k5, k4, k3, k2, k1, c = args\n",
    "    return k5*x**5 + k4*x**4 + k3*x**3 + k2*x**2 + k1*x + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6022de02-971f-491e-a900-b27cc62a5488",
   "metadata": {},
   "source": [
    "## Chi-square fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba4481c-09c4-4477-86b8-7463df0d7846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_fitting(model_fcn, data, iso_params, isochrones, survey):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_fcn: fcn\n",
    "        The model function for the isochrone fit\n",
    "        \n",
    "    data: astropy QTable\n",
    "        The cluster data\n",
    "        \n",
    "    iso_params: array\n",
    "        The fitted isochrone parameters\n",
    "        \n",
    "    isochrones: array\n",
    "        Isochrone data\n",
    "    ----------------------------------------------\n",
    "    Output:\n",
    "    -------\n",
    "    chisq_value: array\n",
    "        The sum of all differences for each star for every isochrone shape:(len(isochrones))\n",
    "    \"\"\"\n",
    "    n_isochrones = np.shape(iso_params)[1]\n",
    "    #diff = np.empty((len(data), n_isochrones)) # shape (data_points,isochrones)\n",
    "    chisq_value = np.empty((n_isochrones))\n",
    "    for i in range(n_isochrones):\n",
    "        if survey=='gaia':\n",
    "            min_col = np.min(isochrones[i][:, 3])\n",
    "            max_col = np.max(isochrones[i][:, 3])\n",
    "            colour_mask = (min_col<=data['bp_rp'].value)&(data['bp_rp'].value<=max_col)\n",
    "            data = data[colour_mask]\n",
    "            #magnitude_mask = (0<=data['M_V'].value)&(data['M_V'].value<=16)\n",
    "            #data = data[magnitude_mask]\n",
    "        \n",
    "            sigma=np.ones((len(data)))\n",
    "        \n",
    "            params = iso_params[:, i]\n",
    "        \n",
    "            # Absolute magnitudes for data according to isochrone\n",
    "            model_data = model_fcn(data['bp_rp'].value, params)\n",
    "        \n",
    "            diff = ((data['M_V'].value - model_data)**2 /sigma) # diff[:, i]\n",
    "            chisq_value[i] = np.nansum(diff, axis=0)\n",
    "            \n",
    "            \n",
    "        if survey=='2mass':\n",
    "            # J - K\n",
    "            iso_col = isochrones[i][:, 2] - isochrones[i][:, 4]\n",
    "            min_col = np.min(iso_col)\n",
    "            max_col = np.max(iso_col)\n",
    "            colour_mask = (min_col<=data['J-K'].value)&(data['J-K'].value<=max_col)\n",
    "            data = data[colour_mask]\n",
    "            #magnitude_mask = (0<=data['M_V'].value)&(data['M_V'].value<=16)\n",
    "            #data = data[magnitude_mask]\n",
    "        \n",
    "            sigma=np.ones((len(data)))\n",
    "        \n",
    "            params = iso_params[:, i]\n",
    "        \n",
    "            # Absolute magnitudes for data according to isochrone\n",
    "            model_data = model_fcn(data['J-K'].value, params)\n",
    "        \n",
    "            diff = ((data['J'].value - model_data)**2 /sigma) # diff[:, i]\n",
    "            chisq_value[i] = np.nansum(diff, axis=0)\n",
    "    \n",
    "    return chisq_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ed74c",
   "metadata": {},
   "source": [
    "## Getting IMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce168381-a430-4a4f-9f7f-cb6dd4610201",
   "metadata": {},
   "source": [
    "Maybe make possible for many clusters at the same time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "81c07c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMF(colour_data, model_data, cluster_name, model_name, nbins, time, check=True, \n",
    "        save_check=False, plot=True, save_plot=True):\n",
    "    \"\"\"\n",
    "    Interpolates the stellar masses from isochrone colours\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    colour_data: array\n",
    "        Colour from cluster stars\n",
    "        \n",
    "    model_data: array\n",
    "        Isochrone data containing time, mass, M_V, bp_rp\n",
    "        \n",
    "    cluster_name: str\n",
    "        name of cluster for plots\n",
    "        \n",
    "    model_name: str\n",
    "        Name of ispchrone models\n",
    "        \n",
    "    nbins:\n",
    "    \n",
    "    time:\n",
    "        \n",
    "    check: bool\n",
    "        True if you want to check the interpolation\n",
    "        \n",
    "    save_check: bool\n",
    "        True if the plot of the interpolation is supposed to be saved\n",
    "        \n",
    "    plot: bool\n",
    "        True if the histograms should be plotted\n",
    "        \n",
    "    save_plot: bool\n",
    "        True if the plots of the histograms should be saved\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sorting all columns in data according to the colour\n",
    "    sorted_model_data = model_data[model_data[:, 3].argsort()]\n",
    "    \n",
    "    stellar_masses = np.array(np.interp(colour_data, sorted_model_data[:, 3], sorted_model_data[:, 1]))\n",
    "    \n",
    "    if check:\n",
    "        fig1, ax1 = plt.subplots(figsize=(5, 4))\n",
    "    \n",
    "        ax1.plot(sorted_model_data[:, 3], sorted_model_data[:, 1], color='b', label='Model data')\n",
    "        ax1.scatter(colour_data, stellar_masses, c='r', s=5, label='Interpolation', zorder=20)\n",
    "        \n",
    "        ax1.set_xlabel(r'G$_{BP}$ - G$_{RP}$ [mag]')\n",
    "        ax1.set_ylabel(r'Mass [M$_{\\odot}$]')\n",
    "        ax1.set_title(f'Interpolation check, {model_name} model, age = {time:.1e} Gyr')\n",
    "        \n",
    "        ax1.legend()\n",
    "        \n",
    "        if save_check:\n",
    "            plt.savefig(f'Plots/Interpolation_check_{cluster_name}_{model_name}_model.png', bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    if plot:\n",
    "        # Plotting histogram in normal scale\n",
    "        min_mass = np.min(stellar_masses)\n",
    "        max_mass = np.max(stellar_masses)\n",
    "        \n",
    "        fig2, ax2 = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        ax2[0].hist(stellar_masses, bins=nbins,\n",
    "                     histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "\n",
    "        ax2[0].set_xlabel(r'Mass [M$_{\\odot}$]')\n",
    "        ax2[0].set_ylabel('Counts')\n",
    "        ax2[0].set_title(f'{model_name} IMF for {cluster_name}, age = {time:.1e} Gyr: normal scale')\n",
    "        \n",
    "        \n",
    "        # Plotting histogram in log scale\n",
    "        ax2[1].hist(stellar_masses, range=(np.log10(min_mass), np.log10(max_mass)), \n",
    "                     bins=np.logspace(np.log10(min_mass), np.log10(max_mass), nbins+1),\n",
    "                     histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "\n",
    "        ax2[1].set_xlabel(r'Log Mass [M$_{\\odot}$]')\n",
    "        ax2[1].set_ylabel('Counts')\n",
    "        ax2[1].set_title(f'{model_name} IMF for {cluster_name}, age = {time:.1e} Gyr: log scale')\n",
    "\n",
    "        ax2[1].set_xscale('log')\n",
    "        \n",
    "        if save_plot:\n",
    "            plt.savefig(f'Plots/{cluster_name}_{model_name}_IMF_log_and_normal.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    return stellar_masses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f392c2-2e07-4911-a590-ec15b1dcd807",
   "metadata": {},
   "source": [
    "## Age interpolation from in between isochrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "59a26322-216b-428f-b519-4ebcd2514dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_age_interpolation(chi_values, isochrone_data, iso_ages, cluster_name, plot=True):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    chi_values: int\n",
    "        Values of sum(chi**2) for each isochrone\n",
    "        \n",
    "    isochrone_data: array\n",
    "        The data from all isochrones\n",
    "        \n",
    "    iso_ages: array/list\n",
    "        list/array of isochrone ages\n",
    "    \"\"\"\n",
    "    min_chi = np.min(chi_values)\n",
    "    pos_min_chi = np.where(chi_values==min_chi)[0][0]\n",
    "    \n",
    "    \n",
    "    if pos_min_chi==0:\n",
    "        new_cluster_age = iso_ages[pos_min_chi] # Find new age based on new minimum chi value\n",
    "        \n",
    "        younger_isochrone = isochrone_data[pos_min_chi]\n",
    "        younger_age = iso_ages[pos_min_chi]\n",
    "        older_isochrone = isochrone_data[pos_min_chi]  \n",
    "        older_age = iso_ages[pos_min_chi]\n",
    "        \n",
    "        plot=False\n",
    "        \n",
    "        print(f'Could not interpolate age for cluster {cluster_name}.')\n",
    "        \n",
    "    else:\n",
    "        # Limiting data to desired range\n",
    "        pnt_below = int(pos_min_chi-1)\n",
    "        pnt_above = int(pos_min_chi+2)\n",
    "    \n",
    "        #print(pnt_below)\n",
    "        #print(pnt_above)\n",
    "        # data for min chi, one above and one below\n",
    "        closest_isos = isochrone_data[pnt_below : pnt_above] # isochrone data for points \n",
    "        closest_ages = iso_ages[pnt_below : pnt_above] # isochrone ages for points\n",
    "        closest_chis = chi_values[pnt_below : pnt_above] # chi values for points\n",
    "    \n",
    "        #print(closest_ages)\n",
    "        #print(closest_chis)\n",
    "        # Fitting a quadratic function to interval\n",
    "        k2, k1, c = np.polyfit(closest_ages, closest_chis, deg=2)\n",
    "    \n",
    "        # Makes 1000 points within age interval\n",
    "        ages = np.linspace(np.min(closest_ages), np.max(closest_ages), 10000)\n",
    "        chis = k2*ages**2 + k1*ages + c # Calculates corresponding chi values from fit\n",
    "        new_min_chi = np.min(chis) # Find minimum chi value in interval\n",
    "        pos_new_min_chi = np.where(chis==new_min_chi)[0] # Find position of minimum chi value\n",
    "        new_cluster_age = ages[pos_new_min_chi][0] # Find new age based on new minimum chi value\n",
    "    \n",
    "        # Finding masses\n",
    "        if new_cluster_age<iso_ages[pos_min_chi]:\n",
    "            younger_isochrone = isochrone_data[int(pos_min_chi-1)]\n",
    "            younger_age = iso_ages[int(pos_min_chi-1)]\n",
    "            older_isochrone = isochrone_data[pos_min_chi]\n",
    "            older_age = iso_ages[pos_min_chi]\n",
    "            \n",
    "        elif new_cluster_age>iso_ages[pos_min_chi]:\n",
    "            younger_isochrone = isochrone_data[pos_min_chi]\n",
    "            younger_age = iso_ages[pos_min_chi]\n",
    "            older_isochrone = isochrone_data[int(pos_min_chi+1)]  \n",
    "            older_age = iso_ages[int(pos_min_chi+1)]\n",
    "        \n",
    "    if plot:\n",
    "        # Fixing data to plot\n",
    "        ages_fit = np.linspace(np.min(closest_ages), np.max(closest_ages), 100)\n",
    "        chi_vals_fit = k2*ages_fit**2 + k1*ages_fit + c\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(7, 6))\n",
    "        \n",
    "        # Plotting chi for each isochrone\n",
    "        ax.scatter(iso_ages, chi_values, c='b', s=10, label=r'$\\chi^2$ per isoc.')\n",
    "        # Plotting minimum chi from isochrones\n",
    "        ax.scatter(iso_ages[pos_min_chi], min_chi, c='r', s=20, label=r'Age$_{min}$ isoc.')\n",
    "        # Plotting chi-age fit\n",
    "        ax.plot(ages_fit, chi_vals_fit, color='orange', label=r'Age fit')\n",
    "        \n",
    "        # Marking the newly determined age\n",
    "        ax.axvline(new_cluster_age, linestyle='dashed', color='g', \n",
    "                   label=f'Age={new_cluster_age:.3} Gyr')\n",
    "        \n",
    "        ax.set_xlabel('Ages [Gyr]')\n",
    "        ax.set_ylabel(r'$\\chi^2$')\n",
    "        ax.set_title(f'Age fit {cluster_name}')\n",
    "        \n",
    "        ax.set_xlim(xmin=np.min(closest_ages)-0.005, xmax=np.max(closest_ages)+0.005)\n",
    "        ax.set_ylim(ymin=np.min(chi_vals_fit)-50, ymax=np.max(chi_vals_fit)+50)\n",
    "        \n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_xticks(np.linspace(np.min(closest_ages)-0.005, np.max(closest_ages)+0.005, 6))\n",
    "        #plt.savefig('Plots/Age_fit_plot.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    return new_cluster_age, younger_isochrone, younger_age, older_isochrone, older_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e6692-8edd-47e9-9359-75871dabf28b",
   "metadata": {},
   "source": [
    "## Interpolated mass from in between isochrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ab9e05a6-4ffe-45b3-9e07-6362f7270b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolated_mass(cluster_data, cluster_name, new_cluster_age, younger_data, older_data, \n",
    "                      younger_age, older_age, model_name, bin_width, plot=True, save_plot=False):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ------------\n",
    "    cluster_data:\n",
    "    \n",
    "    cluster_names:\n",
    "    \n",
    "    younger_data: array\n",
    "        data for younger isochrone\n",
    "        \n",
    "    older_data: array\n",
    "        data for older isochrone\n",
    "        \n",
    "    younger_age: array\n",
    "        age for younger isochrone\n",
    "        \n",
    "    older_age: array\n",
    "        age for older isochrone\n",
    "        \n",
    "    model_name:\n",
    "    \"\"\"\n",
    "    #print(np.min(younger_data[:, 3]))\n",
    "    #print(np.min(younger_data[:, 3]))\n",
    "    colour_mask = (np.min(younger_data[:, 3])<=cluster_data['bp_rp'].value)&(cluster_data['bp_rp'].value<=np.max(older_data[:, 3]))\n",
    "    \n",
    "    cluster_data = cluster_data[colour_mask]\n",
    "    #print(cluster_data)\n",
    "    \n",
    "    # Interpolating masses from model isochrones above and below new age\n",
    "    young_stellar_masses = IMF(cluster_data['bp_rp'].value, younger_data, cluster_name, \n",
    "                               model_name, 15, younger_age, check=False, save_check=False, \n",
    "                               plot=False, save_plot=False)[:, np.newaxis]\n",
    "    \n",
    "    old_stellar_masses = IMF(cluster_data['bp_rp'].value, older_data, cluster_name, \n",
    "                               model_name, 15, older_age, check=False, save_check=False, \n",
    "                               plot=False, save_plot=False)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    # Putting masses into same array, shape: (n_stars, age=2)\n",
    "    model_masses = np.concatenate([young_stellar_masses, old_stellar_masses], axis=1)\n",
    "    # Sort for the interpolation\n",
    "    #sorted_model_masses = model_masses[model_masses[:, 0].argsort()] # Sort according to young masses\n",
    "    \n",
    "    # Creating arrays of ages from model isochrones above and below new age\n",
    "    # Fills entire array with same age as is it constant for each isochrone\n",
    "    young_age_array = np.empty(len(cluster_data))\n",
    "    young_age_array[:] = younger_age \n",
    "    young_age_array = young_age_array[:, np.newaxis]\n",
    "    \n",
    "    old_age_array = np.empty(len(cluster_data))\n",
    "    old_age_array[:] = older_age # Fills entire array with same age\n",
    "    old_age_array = old_age_array[:, np.newaxis]\n",
    "    \n",
    "    # Putting ages into same array, shape: (n_stars, models=2)\n",
    "    model_ages = np.concatenate((young_age_array, old_age_array), axis=1)\n",
    "    \n",
    "    \n",
    "    cluster_stellar_masses = np.empty(len(cluster_data))\n",
    "    \n",
    "    # Want to loop over each star => loop over each row. Gives 2 model points for each star\n",
    "    for i in range(len(cluster_data)):\n",
    "        cluster_stellar_masses[i] = np.interp(new_cluster_age, model_ages[i, :], \n",
    "                                              model_masses[i, :])\n",
    "        \n",
    "        \n",
    "        \n",
    "    if plot:\n",
    "        # Plotting histogram in normal scale\n",
    "        min_mass = np.min(cluster_stellar_masses)\n",
    "        max_mass = np.max(cluster_stellar_masses)\n",
    "        \n",
    "        nbins = int(np.round(2*(np.log10(max_mass) - np.log10(min_mass))/bin_width))\n",
    "        \n",
    "        \n",
    "        fig2, ax2 = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        \n",
    "        #ax2[0].hist(cluster_stellar_masses, bins=nbins,\n",
    "        #             histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "\n",
    "        #ax2[0].set_xlabel(r'Mass [M$_{\\odot}$]')\n",
    "        #ax2[0].set_ylabel('Counts')\n",
    "        #ax2[0].set_title(f'{model_name} IMF for {cluster_name}, age = {new_cluster_age:.2e} Gyr: normal scale')\n",
    "        #\n",
    "        #if model_name=='MIST':\n",
    "        #    ax2[0].set_xlim(xmin=0, xmax=5)\n",
    "        #        \n",
    "        #elif model_name=='Baraffe':\n",
    "        #    ax2[0].set_xlim(xmin=0, xmax=1.5)\n",
    "        \n",
    "        \n",
    "        # Plotting histogram in log scale\n",
    "        ax2.hist(cluster_stellar_masses, range=(np.log10(min_mass), np.log10(max_mass)), \n",
    "                     bins=np.logspace(np.log10(min_mass), np.log10(max_mass), nbins+1),\n",
    "                     histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "\n",
    "        ax2.set_xlabel(r'Log Mass [M$_{\\odot}$]')\n",
    "        ax2.set_ylabel('Counts')\n",
    "        ax2.set_title(f'{model_name} IMF for {cluster_name}, age = {new_cluster_age:.2e} Gyr: log scale')\n",
    "\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "        if model_name=='MIST':\n",
    "            ax2.set_xlim(xmin=0.08, xmax=5)\n",
    "                \n",
    "        elif model_name=='Baraffe':\n",
    "            ax2.set_xlim(xmin=0.01, xmax=1.5)\n",
    "        \n",
    "        if save_plot:\n",
    "            plt.savefig(f'Plots/{cluster_name}_{model_name}_IMF_log_and_normal.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    return cluster_stellar_masses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a78a6-40c9-41ce-8809-8d9a4f224015",
   "metadata": {},
   "source": [
    "## All in one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0d208-5aa9-4fb0-a90f-9c29fcb1b540",
   "metadata": {},
   "source": [
    "**Check** if it is better to have varying numbers of bins for each cluster. Then nbins has to be a list of number of bins which is looped over for each cluster. The counts and edges arrays also have to be converted into lists instead of arrays because they will then vary in size. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4389d349-867c-4f2c-bb46-85d80f7e2596",
   "metadata": {},
   "source": [
    "**Fix!!!** Interpolation when data is outside interpolation interval!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "401fad70-c68b-4bc2-9f33-b9e7b86a3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_IMFs(cluster_data, cluster_names, model, metallicity, bin_width, age_fit_plot=True, \n",
    "               chi_plot=True, save_chi_plot=False, plot_hists=True, save_plot_hists=True): \n",
    "    #check_interp=True, save_check_interp=False,  cluster_tmass_data, \n",
    "    \"\"\"\n",
    "    Finds the best fitting isochrone to the data\n",
    "    ---------------------------------------------\n",
    "    Parameters:\n",
    "    -----------\n",
    "    cluster_data: list\n",
    "        List of cluster data for different clusters\n",
    "        \n",
    "    cluster_names: list\n",
    "        List of the names of all clusters\n",
    "        \n",
    "    iso_file_names: list\n",
    "        List of possible isochrones\n",
    "        \n",
    "    model: str\n",
    "        Isochrone model\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    # Extracting isochrone data for the Gaia magnitudes\n",
    "    iso_data, iso_ages = separate_isochrones(model, metallicity, 'gaia')\n",
    "    # FLattening the isochrone ages\n",
    "    iso_ages = iso_ages.flatten()\n",
    "    # Extracting the isochrone parameters\n",
    "    isochrone_parameters_gaia = isochrone_params(iso_data, model, 'gaia') # A (6, n_isochsones) array\n",
    "    \n",
    "    # Extracting the isochrone data for the 2MASS magnitudes\n",
    "    #iso_tmass_data, iso_tmass_ages = separate_isochrones(model, metallicity, '2mass')\n",
    "    \n",
    "    \n",
    "    # Initiating outputlists\n",
    "    log_counts = [] #np.empty((nbins, len(cluster_data)))\n",
    "    log_edges = [] #np.empty((nbins+1, len(cluster_data)))\n",
    "    all_masses = []\n",
    "    all_ages = []\n",
    "    same_as_first_iso = []\n",
    "    \n",
    "    all_cluster_names = cluster_names.copy() #np.array([float(name) for name in cluster_names])\n",
    "    \n",
    "    for i, cl_data in enumerate(cluster_data): # Loops over all clusters in list\n",
    "        print(f'i new = {i}')\n",
    "        \n",
    "        # Removing stars with missing colour values in both datasets\n",
    "        data_mask = cl_data['bp_rp'].mask==False # \n",
    "        cl_data = cl_data[data_mask]\n",
    "        #cl_tmass_data = cluster_tmass_data[i]\n",
    "        \n",
    "        \n",
    "        # Finding common stars for Gaia and 2MASS data \n",
    "        #gaia_2mass_inters, gaia_indices, tmass_indices = np.intersect1d(cl_data['GaiaID'].value, \n",
    "        #                                                                cl_tmass_data['GaiaID'].value,\n",
    "        #                                                                return_indices=True)\n",
    "        #\n",
    "        \n",
    "       # if len(gaia_indices)!=len(cl_tmass_data):\n",
    "       #     cl_member_indices = np.linspace(0, len(cl_tmass_data)-1, len(cl_tmass_data), dtype=int)\n",
    "       #     cl_member_indices = np.delete(cl_member_indices, tmass_indices)\n",
    "       #     cl_tmass_data.remove_rows(cl_member_indices)\n",
    "            \n",
    "        \n",
    "        # Finding best fitting isochrone \n",
    "        chi_values = chi_fitting(fit_fcn, cl_data, isochrone_parameters_gaia, iso_data, 'gaia')\n",
    "        min_chi = np.min(chi_values)\n",
    "        pos_min_chi = np.where(chi_values==min_chi)[0][0]\n",
    "        \n",
    "        min_chis = np.array([0., pos_min_chi])\n",
    "        \n",
    "        first_iso = pos_min_chi\n",
    "        \n",
    "        ##################################################################################\n",
    "        #min_col = np.min(cl_data[])\n",
    "        #nbins = int(np.round(2*(np.log10(max_mass) - np.log10(min_mass))/bin_width))\n",
    "        #cl_name = cluster_names[i]\n",
    "        #best_isochrone = iso_tmass_data[pos_min_chi]\n",
    "        #best_iso_col = best_isochrone[:, 2]-best_isochrone[:, 4]\n",
    "        #best_iso_mag = best_isochrone[:, 2]\n",
    "        #fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        \n",
    "        #ax.hist(np.array(cl_data['bp_rp'].value), bins=15,\n",
    "        #        align='left', histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "        #ax[0].plot(best_iso_col, best_iso_mag, 'r')\n",
    "        #ax[0].scatter(cl_tmass_data['J-K'], cl_tmass_data['J'], c='b', s=10, alpha=0.5)\n",
    "        #ax[0].set_xlim(-5, 6)\n",
    "        #ax[0].set_ylim(-5, 15)\n",
    "        #ax[0].set_title(f'CMD Beforecluster  {i}')\n",
    "        #ax[0].invert_yaxis()\n",
    "        #ax[0].grid(True)\n",
    "        \n",
    "        #ax.grid(True)\n",
    "        #plt.show()\n",
    "        ######################################################################################\n",
    "        \n",
    "        #while min_chis[0]!=min_chis[1]:\n",
    "        #    \n",
    "        #    #print(min_chis)\n",
    "        #    min_chis[0] = pos_min_chi\n",
    "        #    \n",
    "        #    best_isochrone = iso_tmass_data[pos_min_chi]\n",
    "        #    \n",
    "        #    iso_jh = best_isochrone[:, 2] - best_isochrone[:, 3] # Isochrone CCD values\n",
    "        #    iso_hk = best_isochrone[:, 3] - best_isochrone[:, 4] # Isochrone CCD values\n",
    "        #    \n",
    "        #    iso_interval_fit_mask = (0.18<=iso_hk)&(iso_hk<=0.28) \n",
    "        #    \n",
    "        #    iso_hk_interval = iso_hk[iso_interval_fit_mask]\n",
    "        #    iso_jh_interval = iso_jh[iso_interval_fit_mask]\n",
    "        #    \n",
    "        #    k_iso_fit, m_iso_fit = np.polyfit(iso_hk_interval, iso_jh_interval, deg=1)\n",
    "        #    \n",
    "        #    \n",
    "        #    # Correcting 2MASS data\n",
    "        #    cl_tmass_data = extinction(k_iso_fit, m_iso_fit, cl_tmass_data)\n",
    "        #    #print(cl_tmass_data)\n",
    "        #    mean_A_G = np.mean(cl_tmass_data['A_G'].value)*u.mag\n",
    "        #    mean_A_BP = np.mean(cl_tmass_data['A_BP'].value)*u.mag\n",
    "        #    mean_A_RP = np.mean(cl_tmass_data['A_RP'].value)*u.mag\n",
    "        #    #print(mean_extinction)\n",
    "        #    #print(np.min(cl_tmass_data['Extinction'].value), np.max(cl_tmass_data['Extinction'].value))\n",
    "        #    \n",
    "        #    # Adding extinction column to Gaia data\n",
    "        #    cl_data['A_G'] = np.zeros((len(cl_data)))\n",
    "        #    cl_data['A_BP'] = np.zeros((len(cl_data)))\n",
    "        #    cl_data['A_RP'] = np.zeros((len(cl_data)))\n",
    "        #    \n",
    "        #    # Adds extracted values from 2MASS data\n",
    "        #    cl_data['A_G'][gaia_indices] = cl_tmass_data['A_G']\n",
    "        #    cl_data['A_BP'][gaia_indices] = cl_tmass_data['A_BP']\n",
    "        #    cl_data['A_RP'][gaia_indices] = cl_tmass_data['A_RP']\n",
    "        #    \n",
    "        #    # Finding the non-xmatched star positions\n",
    "        #    star_positions = np.linspace(0, len(cl_data)-1, len(cl_data), dtype=int)\n",
    "        #    non_xmatched_pos = np.delete(star_positions, gaia_indices)\n",
    "        #    \n",
    "        #    # Assigning mean extintion to the non-xmatched stars in the Gaia data\n",
    "        #    cl_data['A_G'][non_xmatched_pos] = mean_A_G\n",
    "        #    cl_data['A_BP'][non_xmatched_pos] = mean_A_BP\n",
    "        #    cl_data['A_RP'][non_xmatched_pos] = mean_A_RP\n",
    "        #    \n",
    "        #    ########### Change according to table in paper!!!!!!!!####################\n",
    "        #    #extinction_G = 0.789*cl_data['Extinction']*u.mag #(+-0.005) #extinction_per_band('G', cl_data['bp_rp'].value, cl_data['Extinction'].value)\n",
    "        #    #extinction_BP = 1.002*cl_data['Extinction']*u.mag #(+-0.007) #extinction_per_band('BP', cl_data['bp_rp'].value, cl_data['Extinction'].value)\n",
    "        #    #extinction_RP = 0.589*cl_data['Extinction']*u.mag #(+-0.004) #extinction_per_band('RP', cl_data['bp_rp'].value, cl_data['Extinction'].value)\n",
    "        #    \n",
    "        #    extinction_bp_rp = cl_data['A_BP'].value - cl_data['A_RP'].value\n",
    "        #    \n",
    "        #    # Correcting the absolute magnitude in Gaia data\n",
    "        #    cl_data['M_V'] = (cl_data['M_V'].value - cl_data['A_G'].value)*u.mag #(cl_data['M_apparent'].value - 5*np.log10(cl_data['dist'].value) + 5 - cl_data['Extinction'].value)*u.mag\n",
    "        #    cl_data['bp_rp'] = (cl_data['bp_rp'].value - extinction_bp_rp)*u.mag\n",
    "        #    #print(cl_data['M_V'])\n",
    "        #\n",
    "        #    \n",
    "        #    chi_values = chi_fitting(fit_fcn, cl_data, isochrone_parameters_gaia, iso_data, 'gaia')\n",
    "        #    #print(chi_values)\n",
    "        #    min_chi = np.min(chi_values)\n",
    "        #    #print(min_chi)\n",
    "        #    pos_min_chi = np.where(chi_values==min_chi)[0][0]\n",
    "        #    \n",
    "        #    min_chis[1] =pos_min_chi\n",
    "        #    #print(min_chis)\n",
    "        #    #print()\n",
    "        \n",
    "        #best_isochrone = iso_tmass_data[pos_min_chi]\n",
    "        \n",
    "        #ax[1].plot(best_isochrone[:, 2] - best_isochrone[:, 4], best_isochrone[:, 2], 'r')\n",
    "        #ax[1].scatter(cl_tmass_data['J-K'], cl_tmass_data['J'], c='b', s=10, alpha=0.5)\n",
    "        #ax[1].set_xlim(-5, 6)\n",
    "        #ax[1].set_ylim(-5, 15)\n",
    "        #ax[1].set_title('CMD After')\n",
    "        #ax[1].invert_yaxis()\n",
    "        #ax[1].grid(True)\n",
    "        \n",
    "        #plt.tight_layout()\n",
    "        #plt.show()\n",
    "        #fig2, ax2 = plt.subplots(figsize=(5, 4))\n",
    "        \n",
    "        #ax2.hist(np.array(cl_data['bp_rp'].value), bins=80,\n",
    "        #        align='left', histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "            #ax.scatter(cl_data['bp_rp'], cl_data['M_V'], s=10, alpha=0.5)\n",
    "        #ax2.set_xlim(xmin=0)\n",
    "        #ax.set_ylim(-5, 15)\n",
    "        #ax.set_title('Initially')\n",
    "        #ax.set_xscale('log')\n",
    "        #ax.set_yscale('log')\n",
    "        #ax2.grid(True)\n",
    "        #ax.invert_yaxis()\n",
    "        #plt.show()\n",
    "        \n",
    "        \n",
    "        if first_iso == pos_min_chi:\n",
    "            same_as_first_iso.append(cl_data['Cluster_number'][0])\n",
    "        \n",
    "        cl_age, iso_young, age_young, iso_old, age_old = new_age_interpolation(chi_values, iso_data, \n",
    "                                                                            iso_ages, cluster_names[i],\n",
    "                                                                            plot=age_fit_plot)\n",
    "        \n",
    "        all_ages.append(cl_age)\n",
    "        #min_chi = np.min(chi_values)\n",
    "        #min_iso_pos = int(np.where(chi_values==min_chi)[0])\n",
    "        \n",
    "        if chi_plot:\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            \n",
    "            ax.scatter(iso_ages, chi_values, c='b', s=10, label=r'$\\chi^2$ values')\n",
    "            #ax.scatter(iso_ages[min_iso_pos], min_chi, c='r', s=15, label=r'Minimum $\\chi^2$')\n",
    "            \n",
    "            ax.axvline(cl_age, linestyle='dashed', c='g')\n",
    "            \n",
    "            ax.set_xlabel('Age [Gyr]')\n",
    "            ax.set_ylabel(r'$\\chi^2$ values')\n",
    "            ax.set_title(r'$\\chi^2$ values for isochrone ages')\n",
    "            ax.set_xscale('log')\n",
    "            ax.legend()\n",
    "            \n",
    "            if save_chi_plot:\n",
    "                plt.savefig(f'Plots/Chi_plot_{cluster_names[i]}.png', bbox_inches='tight')\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        # \n",
    "        #best_iso_params = isochrone_parameters[:, min_iso_pos]\n",
    "        #best_iso_data = iso_data[min_iso_pos] # Contains (time, M_V, bp_rp, Mass)\n",
    "        \n",
    "        #colour_cluster_mask = (np.min(best_iso_data[:, 3])<=cl_data['bp_rp'].value)&(cl_data['bp_rp'].value<=np.max(best_iso_data[:, 3]))\n",
    "        \n",
    "        #cl_data = cl_data[colour_cluster_mask]\n",
    "        \n",
    "        #cluster_masses = IMF(cl_data['bp_rp'].value, best_iso_data, cluster_names[i], model, \n",
    "        #                     nbins=nbins, time=iso_ages[min_iso_pos], check=check_interp, \n",
    "        #                     save_check=save_check_interp, plot=plot_hists, \n",
    "        #                     save_plot=save_plot_hists)\n",
    "        \n",
    "        cluster_masses = interpolated_mass(cl_data, cluster_names[i], cl_age, iso_young, iso_old,\n",
    "                                           age_young, age_old, model, bin_width, plot_hists, \n",
    "                                           save_plot_hists)\n",
    "        \n",
    "        \n",
    "        mass_mask = cluster_masses>0.3\n",
    "        \n",
    "        cluster_masses = cluster_masses[mass_mask]\n",
    "        cl_name = cluster_names[i]\n",
    "        #print(f'{len(cluster_names) = }')\n",
    "        #print(f'{i = }')\n",
    "        \n",
    "        if len(cluster_masses)<10:\n",
    "            del [all_ages[-1]]\n",
    "            name_pos = np.where(all_cluster_names==cl_name)[0]\n",
    "            all_cluster_names = np.delete(all_cluster_names, name_pos)\n",
    "            continue\n",
    "            \n",
    "        #print(f'{len(cluster_names) = }')\n",
    "        #print(f'{i = }')\n",
    "        #print()\n",
    "        \n",
    "        all_masses.append(cluster_masses)\n",
    "        \n",
    "        min_mass = np.min(cluster_masses)\n",
    "        max_mass = np.max(cluster_masses)\n",
    "        \n",
    "        nbins = int(np.round(2*(np.log10(max_mass)-np.log10(min_mass))/(bin_width)))\n",
    "        \n",
    "        #normal_counts[:, i], normal_edges[:, i] = np.histogram(cluster_masses, nbins, \n",
    "        #                                                       range=(np.min(cluster_masses), \n",
    "        #                                                       np.max(cluster_masses)))\n",
    "        \n",
    "        l_counts, l_edges = np.histogram(cluster_masses, \n",
    "                                         bins=np.logspace(np.log10(np.min(cluster_masses)), \n",
    "                                                          np.log10(np.max(cluster_masses)), \n",
    "                                                          nbins+1),\n",
    "                                         range=(np.log10(np.min(cluster_masses)), \n",
    "                                                np.log10(np.max(cluster_masses))))\n",
    "        log_counts.append(l_counts)\n",
    "        log_edges.append(l_edges)\n",
    "    return log_counts, log_edges, all_masses, all_ages, same_as_first_iso, all_cluster_names\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1f1ca-dc4b-4803-9d9c-de01fc118439",
   "metadata": {},
   "source": [
    "## Separating cluster data into separate arrays for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4be2de2-44fc-4cdf-8efb-bf1d66df9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_list(cluster_table, N_limit, survey, check_effect, dist_cut=600):\n",
    "    \n",
    "    clusters = []\n",
    "    names = []\n",
    "    \n",
    "    cluster_table = cluster_table[cluster_table['Cluster_number'].argsort()]\n",
    "    cluster_table['dist'] = np.zeros((len(cluster_table))) * u.pc\n",
    "    cluster_table['dist_error'] = np.zeros((len(cluster_table))) * u.pc\n",
    "    \n",
    "    for i in range(1, cluster_table['Cluster_number'][-1]+1):\n",
    "        # Creates a mask that only leaves one cluster\n",
    "        cluster_mask = cluster_table['Cluster_number']==i\n",
    "        \n",
    "        # Creates a table with only one cluster\n",
    "        cluster = cluster_table[cluster_mask]\n",
    "        \n",
    "        # Checking that the cluster is not too small\n",
    "        if len(cluster)<N_limit:\n",
    "            continue\n",
    "        \n",
    "        else:        \n",
    "            if survey=='gaia':\n",
    "        \n",
    "                cluster['bp_rp'] = cluster['G_bp'] - cluster['G_rp']\n",
    "            \n",
    "                # Sorting cluster according to brightest stars\n",
    "                cluster = cluster[cluster['M_apparent'].argsort()]\n",
    "                # 10 brightest stars in the cluster have the lowest magnitudes\n",
    "                brightest_stars = cluster[:10]\n",
    "                # Distances of brightest stars\n",
    "                distance = 1/(brightest_stars['Parallax'].value*1e-3) * u.pc\n",
    "                # Mean distance of the cluster based on the 10 brightest stars\n",
    "                mean_distance = np.mean(distance)\n",
    "                #print(mean_distance)\n",
    "                #print(type(mean_distance))\n",
    "                \n",
    "                if mean_distance>dist_cut*u.pc:\n",
    "                    continue\n",
    "                \n",
    "                cluster['dist'] = mean_distance #Distance(parallax=cluster['Parallax'])\n",
    "                \n",
    "                expr = -((brightest_stars['Parallax_error'].value * 1e-3)/(brightest_stars['Parallax'].value * 1e-3)**2)\n",
    "                #print(expr)\n",
    "                distance_error = np.sqrt((1/10)*np.sum(expr**2)) * u.pc\n",
    "                #print(distance_error)\n",
    "                cluster['dist_error'] = distance_error\n",
    "                \n",
    "                if check_effect=='+':\n",
    "                    cluster['dist'] = cluster['dist'] + cluster['dist_error']\n",
    "                    \n",
    "                elif check_effect=='-':\n",
    "                    cluster['dist'] = cluster['dist'] - cluster['dist_error']\n",
    "                \n",
    "                # Calculates and adds an absolute magnitude column calculated from the photometric mean magnitude \n",
    "                # and the distance modulus, described above\n",
    "                cluster['M_V'] = (cluster['M_apparent'].value - 5*np.log10(cluster['dist'].value) + 5)*u.mag\n",
    "            \n",
    "            \n",
    "            elif survey=='2mass':\n",
    "                cluster['J-H'] = (cluster['j_m'].value - cluster['h_m'].value)*u.mag\n",
    "                cluster['H-K'] = (cluster['h_m'].value - cluster['k_m'].value)*u.mag\n",
    "            \n",
    "                cluster['J'] = cluster['j_m'].value * u.mag\n",
    "                cluster['H'] = cluster['h_m'].value * u.mag\n",
    "                cluster['K'] = cluster['k_m'].value * u.mag\n",
    "                cluster['J-K'] = (cluster['j_m'].value - cluster['k_m'].value)*u.mag\n",
    "        \n",
    "                # Sorting cluster according to brightest stars\n",
    "                cluster = cluster[cluster['M_apparent'].argsort()]\n",
    "                # 10 brightest stars in the cluster have the lowest magnitudes\n",
    "                brightest_stars = cluster[:10]\n",
    "                # Distances of brightest stars\n",
    "                distance = 1/(brightest_stars['Parallax'].value*1e-3) * u.pc\n",
    "                # Mean distance of the cluster based on the 10 brightest stars\n",
    "                mean_distance = np.mean(distance)\n",
    "                #print(mean_distance)\n",
    "                #print(type(mean_distance))\n",
    "            \n",
    "                cluster['dist'] = mean_distance #Distance(parallax=cluster['Parallax'])\n",
    "            \n",
    "                if mean_distance>dist_cut*u.pc:\n",
    "                    continue\n",
    "            \n",
    "            \n",
    "            clusters.append(cluster)\n",
    "            names.append(f\"{cluster['Cluster_number'][0]}\")\n",
    "            \n",
    "    return clusters, names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b094cc-4d36-41ff-a9f5-bdd95d2a1714",
   "metadata": {},
   "source": [
    "## Fitting IMF slopes function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0101b19c-dec9-4d18-b907-cb978759e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMF_fit_fcn(x, a, C):\n",
    "    return C*x**a\n",
    "\n",
    "def IMF_slopes(log_edges, log_counts, all_cluster_masses, model, intervals='Kroupa', \n",
    "               plot=True):\n",
    "    # Want to plot, give a list of all slopes, chose if I want to use all intervals\n",
    "    # Comparison with Kroupa\n",
    "    # Plot fits with histograms\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    log_edges: list\n",
    "        List with edges of the logarithmic bins\n",
    "        \n",
    "    log_counts: list\n",
    "        List with logarithmic bin counts\n",
    "        \n",
    "    all_cluster_masses: list\n",
    "        List of all clusters' stellar mass arrays\n",
    "        \n",
    "    Output:\n",
    "    -------\n",
    "    bin_widths:\n",
    "    \n",
    "    slopes:\n",
    "    \"\"\"\n",
    "    \n",
    "    bin_widths = np.zeros((len(all_cluster_masses)))\n",
    "    \n",
    "    # shape(n_clusters, 2 parameters, 4 intervals)\n",
    "    all_cluster_params = np.full((len(all_cluster_masses), 2, 4), fill_value=np.nan) \n",
    "    \n",
    "    kroupa_diff = np.full((len(all_cluster_masses), 4), fill_value=np.nan)\n",
    "    \n",
    "    it=0\n",
    "    # Loops over each cluster\n",
    "    for i, cluster_masses in enumerate(all_cluster_masses):\n",
    "        print(i)\n",
    "        #print()\n",
    "        min_masses = np.min(cluster_masses)\n",
    "        max_masses = np.max(cluster_masses)\n",
    "        edges = log_edges[i]#.flatten()\n",
    "        \n",
    "        # Rolling edges array such that for-loop is not needed\n",
    "        rolled_edges = np.roll(edges, shift=1)\n",
    "        \n",
    "        n_bins = len(edges)-1\n",
    "        \n",
    "        # Getting bin widths and bin positions\n",
    "        bin_mid = np.exp((np.log(edges) + np.log(rolled_edges))/2)\n",
    "        bin_mid = bin_mid[1:]\n",
    "        \n",
    "        bin_width = np.abs(np.log(edges) - np.log(rolled_edges))\n",
    "        bin_width = bin_width[1:]\n",
    "        bin_width_diff = np.round(np.abs(bin_width - np.roll(bin_width, shift=1)), decimals=0)\n",
    "        if all(bin_width_diff==0):\n",
    "            bin_widths[i] = bin_width[0]\n",
    "        \n",
    "        else:\n",
    "            print('Not constant bin width!')\n",
    "        \n",
    "        \n",
    "        cluster_counts = log_counts[i]\n",
    "        \n",
    "        if intervals=='Kroupa':\n",
    "            # Creating interval mass masks\n",
    "            interval_1_mask = (0.01<=bin_mid)&(bin_mid<=0.08)\n",
    "            interval_2_mask = (0.3<=bin_mid)&(bin_mid<=0.5) #0.08\n",
    "            interval_3_mask = (0.5<=bin_mid)&(bin_mid<=1.0)\n",
    "            interval_4_mask = (1.0<=bin_mid)\n",
    "            \n",
    "            all_intervals = np.array([1, 2, 3, 4])\n",
    "            \n",
    "            interval_masks = [interval_1_mask, interval_2_mask, interval_3_mask, interval_4_mask]\n",
    "            interval_edges = [(0.01, 0.08), (0.3, 0.5), (0.5, 1.0), (1.0, np.max(cluster_masses))]\n",
    "            \n",
    "            all_interval_masses = [bin_mid[mask] for mask in interval_masks]\n",
    "            all_interval_counts = [cluster_counts[mask] for mask in interval_masks]\n",
    "            \n",
    "            model_slopes = np.array([0.3, 1.3, -2.3, -2.3])\n",
    "            model_slope_errors = np.array([0.7, 0.5, 0.3, 0.7])\n",
    "            \n",
    "            lengths = np.array([len(int_mask[int_mask==True]) for int_mask in interval_masks])# Works! Use this in the if-statement!\n",
    "            \n",
    "            \n",
    "            if any(length<=1 for length in lengths):\n",
    "                short_len_positions = [k for k,length in enumerate(lengths) if length<=1]\n",
    "                short_len_mask = lengths>1\n",
    "                \n",
    "                remove_pos = short_len_positions[0]\n",
    "                    \n",
    "                interval_masks = [mask for k, mask in enumerate(interval_masks) if len(mask[mask==True])>1]\n",
    "                interval_edges.remove(interval_edges[remove_pos])\n",
    "                \n",
    "                all_intervals = all_intervals[short_len_mask]\n",
    "                \n",
    "                all_interval_masses = [masses for k, masses in enumerate(all_interval_masses) if len(masses)>1]\n",
    "                all_interval_counts = [counts for k, counts in enumerate(all_interval_counts) if len(counts)>1]\n",
    "                \n",
    "                model_slopes = np.delete(model_slopes, short_len_positions)\n",
    "                model_slope_errors = np.delete(model_slope_errors, short_len_positions)\n",
    "            \n",
    "            counter = 0\n",
    "            # Ignoring intervals with only one non-zero bin\n",
    "            while any([len(int_counts[int_counts>0])<=1 for int_counts in all_interval_counts]):\n",
    "                counter = counter +1\n",
    "                # Finds indices for intervals for which there is only one non-zero bin\n",
    "                failed_int_pos = np.array([index for index, int_counts in enumerate(all_interval_counts) if len(int_counts[int_counts>0])<=1])\n",
    "                \n",
    "                del interval_masks[failed_int_pos[0]]                \n",
    "                del interval_edges[failed_int_pos[0]]\n",
    "                \n",
    "                all_intervals = np.delete(all_intervals, failed_int_pos[0])\n",
    "                \n",
    "                del all_interval_masses[failed_int_pos[0]]\n",
    "                del all_interval_counts[failed_int_pos[0]]\n",
    "                \n",
    "                model_slopes = np.delete(model_slopes, failed_int_pos[0])\n",
    "                model_slope_errors = np.delete(model_slope_errors, failed_int_pos[0])\n",
    "                \n",
    "            \n",
    "            # shape(fit_length, n intervals)\n",
    "            x_fit_values = np.empty((500, len(interval_masks))) \n",
    "            y_fit_values = np.empty((500, len(interval_masks)))\n",
    "            \n",
    "            # shape(2 params, n intervals)\n",
    "            #cluster_params = np.zeros((2, 4))  #len(interval_masks)\n",
    "               \n",
    "            it = it+1\n",
    "        \n",
    "        #print(it)\n",
    "        #print(interval_edges)\n",
    "        # Loop over mass intervals to fit parameters\n",
    "        for j, interval_masses in enumerate(all_interval_masses):\n",
    "            #print(j)\n",
    "            interval_counts = all_interval_counts[j].flatten()\n",
    "            #print(interval_edges[j])\n",
    "            #print(interval_counts)\n",
    "            #print(interval_masses)\n",
    "            \n",
    "            fitted_params, covariance = scopt.curve_fit(IMF_fit_fcn, xdata=interval_masses, \n",
    "                                                        ydata=interval_counts, p0=[model_slopes[j], 30],\n",
    "                                                        maxfev=5000) # , full_output=True\n",
    "            \n",
    "            #print(covariance)\n",
    "            # Adding to final list/array\n",
    "            all_cluster_params[i, :, all_intervals[j]-1] = fitted_params\n",
    "            kroupa_diff[i, all_intervals[j]-1] = (fitted_params[0] - model_slopes[j]) # all_cluster_params[i, :, intervals[j]]\n",
    "            \n",
    "            # Dividing up\n",
    "            slope_fit, C_fit = fitted_params\n",
    "            \n",
    "            x_fit_values[:, j] = np.linspace(interval_edges[j][0], interval_edges[j][1], 500)\n",
    "            y_fit_values[:, j] = IMF_fit_fcn(x_fit_values[:, j], slope_fit, C_fit)\n",
    "        \n",
    "        \n",
    "        if plot:\n",
    "            colours = ['r', 'orange', 'g', 'm', 'skyblue', 'limegreen']\n",
    "            #min_masses = np.min(cluster_masses)\n",
    "            #max_masses = np.max(cluster_masses)\n",
    "            \n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(7, 6))\n",
    "            \n",
    "            ax.hist(cluster_masses, range=(np.log10(min_masses), np.log10(max_masses)), \n",
    "                    bins=np.logspace(np.log10(min_masses), np.log10(max_masses), n_bins),\n",
    "                    histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5, \n",
    "                    label='IMF histogram')\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Loop over mass intervals to fit parameters\n",
    "            for j, interval_masses in enumerate(all_interval_masses):\n",
    "                ax.plot(x_fit_values[:, j], y_fit_values[:, j], color=colours[j], \n",
    "                        label=f'{interval_edges[j][0]}'+r'$\\leq$m/'+r'M$_{\\odot}$<'+f'{interval_edges[j][1]:.3}')\n",
    "                \n",
    "            ax.set_xlabel(r'Mass [M$_{\\odot}$]')\n",
    "            ax.set_ylabel(r'Counts')\n",
    "            ax.set_title('Histogram with fitted IMF slopes')\n",
    "            \n",
    "            ax.legend(loc='lower right')\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_yscale('log')\n",
    "            \n",
    "            if model=='MIST':\n",
    "                ax.set_xlim(xmin=0.08, xmax=5)\n",
    "                \n",
    "            elif model=='Baraffe':\n",
    "                ax.set_xlim(xmin=1e-2, xmax=2)\n",
    "                ax.set_ylim(ymin=8e-1, ymax=2e2)\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "    \n",
    "    \n",
    "    return bin_widths, all_cluster_params, kroupa_diff, counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059a725-32c8-4be5-b6ca-bce1ba2dec30",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assigning cluster numbers to 2MASS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee694cd-fcc3-45fa-9a5f-8e1deab807d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_2mass_data(tmass_data):\n",
    "    \"\"\"\n",
    "    Assigns cluster numbers to the 2MASS data\n",
    "    \"\"\"\n",
    "    tmass_data_new = tmass_data\n",
    "    \n",
    "    star_ids_data = votable.parse_single_table('Filter_containing_tmassID.vot').to_table()\n",
    "    cluster_data = votable.parse_single_table('Vizier_data_filtered.vot').to_table()\n",
    "    \n",
    "    cluster_data.rename_column('cluster_number', 'Cluster_number')\n",
    "    cluster_data.rename_column('gaiaid', 'GaiaID')\n",
    "    cluster_data.rename_column('g_bp', 'G_bp')\n",
    "    cluster_data.rename_column('g_rp', 'G_rp')\n",
    "    cluster_data.rename_column('parallax', 'Parallax')\n",
    "    cluster_data.rename_column('parallax_error', 'Parallax_error')\n",
    "    cluster_data.rename_column('m_apparent', 'M_apparent')\n",
    "   \n",
    "    \n",
    "    # Sorting data according to Gaia ID\n",
    "    cluster_order = cluster_data['GaiaID'].argsort()\n",
    "    cluster_data = cluster_data[cluster_order]\n",
    "    \n",
    "    id_order = star_ids_data['source_id'].argsort()\n",
    "    star_ids_data = star_ids_data[id_order]\n",
    "    tmass_data_new = tmass_data_new[id_order]\n",
    "    \n",
    "    km_mask = tmass_data_new['k_m']!='NULL'\n",
    "    \n",
    "    tmass_data_new = tmass_data_new[km_mask]\n",
    "    tmass_data_new['k_m'] = tmass_data_new['k_m'].astype(float)\n",
    "    \n",
    "    cluster_data = cluster_data[km_mask]\n",
    "    star_ids_data = star_ids_data[km_mask]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Assigning cluster numbers and the Gaia IDs\n",
    "    tmass_data_new['Cluster_number'] = cluster_data['Cluster_number']\n",
    "    tmass_data_new['GaiaID'] = cluster_data['GaiaID']\n",
    "    tmass_data_new['Parallax'] = cluster_data['Parallax']\n",
    "    tmass_data_new['Parallax_error'] = cluster_data['Parallax_error']\n",
    "    tmass_data_new['M_apparent'] = cluster_data['M_apparent']\n",
    "    \n",
    "    unique_tmass_ids, n_id_occurances = np.unique(tmass_data_new['tmass_oid'], return_counts=True)\n",
    "    \n",
    "    duplicates = unique_tmass_ids[n_id_occurances>1]\n",
    "    \n",
    "    for duplicate in duplicates:\n",
    "        duplicate_pos = np.where(tmass_data_new['tmass_oid']==duplicate)\n",
    "        \n",
    "        tmass_data_new.remove_rows(duplicate_pos)\n",
    "        np.delete(star_ids_data, duplicate_pos)\n",
    "        np.delete(cluster_data, duplicate_pos)    \n",
    "    \n",
    "      \n",
    "    return tmass_data_new, cluster_data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e323a0-749b-46ba-8c8b-51b4ec21b3f5",
   "metadata": {},
   "source": [
    "## Determining extinction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59851c87-4065-4049-85d2-053c8c3aa9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extinction(k_iso_fit, m_iso_fit, cluster_data):\n",
    "    \"\"\"\n",
    "    Corrects the extincted stars in the cluster data\n",
    "    -------------------------------------------------\n",
    "    Parameters:\n",
    "    -----------\n",
    "    k_iso_fit: float\n",
    "        Slope of the isochrone line fit\n",
    "        \n",
    "    m_iso_fit: float\n",
    "        y-axis crossing of the isochrone line fit\n",
    "        \n",
    "    Cluster_data: table\n",
    "        2MASS data for the cluster\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    The corrected cluster data\n",
    "    \"\"\"\n",
    "    # Cardelli (1989) table 3 values\n",
    "    A_J = 0.282\n",
    "    A_H = 0.190\n",
    "    A_K = 0.114\n",
    "            \n",
    "    A_jh = A_J - A_H\n",
    "    A_hk = A_H - A_K\n",
    "    \n",
    "    # Length of Av=1 vector\n",
    "    len_ext_vector = np.sqrt(A_jh**2 + A_hk**2)\n",
    "    #print()\n",
    "    #Getting slope for extinction vector            \n",
    "    k_ext_vector, m_ext_vector = np.polyfit(np.array([0, A_hk]), np.array([0, A_jh]), deg=1)\n",
    "    \n",
    "    # Adding extinction column to data table\n",
    "    cluster_data['A_G'] = np.zeros((len(cluster_data)))\n",
    "    cluster_data['A_BP'] = np.zeros((len(cluster_data)))\n",
    "    cluster_data['A_RP'] = np.zeros((len(cluster_data)))\n",
    "    cluster_data['A_J'] = np.zeros((len(cluster_data)))\n",
    "    cluster_data['A_H'] = np.zeros((len(cluster_data)))\n",
    "    cluster_data['A_K'] = np.zeros((len(cluster_data)))\n",
    "    #cluster_data['A_JK'] = np.zeros((len(cluster_data)))\n",
    "    \n",
    "    \n",
    "    # Create x value range\n",
    "    min_x_val = np.min(cluster_data['H-K'].value)\n",
    "    max_x_val = np.max(cluster_data['H-K'].value)\n",
    "    #print(any(np.isnan(cluster_data['H-K'].value)))\n",
    "    #print(max_x_val)\n",
    "    x_range = np.linspace(-5*max_x_val, max_x_val, int(1e6))\n",
    "    \n",
    "    # y_isochrone_line - kx_isochrone_line\n",
    "    m_upper_line = (k_iso_fit*0.16 + m_iso_fit) - k_ext_vector*0.16\n",
    "    m_lower_line = (k_iso_fit*0.33 + m_iso_fit) - k_ext_vector*0.33\n",
    "    \n",
    "    ######################################################################################################\n",
    "    #fig, ax = plt.subplots(1, 2, figsize=(10, 8))\n",
    "    \n",
    "    #ax[0].scatter(cluster_data['H-K'], cluster_data['J-H'], c='b', s=10, alpha=0.5)\n",
    "    #ax[0].plot(x_range, k_iso_fit*x_range + m_iso_fit, linestyle='dashed', color='g')\n",
    "    #ax[0].plot(x_range, k_ext_vector*x_range + m_upper_line, linestyle='dashed', color='m')\n",
    "    #ax[0].plot(x_range, k_ext_vector*x_range + m_lower_line, linestyle='dashed', color='m')\n",
    "    \n",
    "    #ax[0].grid()\n",
    "    #ax[0].set_xlim(-2, 3)\n",
    "    #ax[0].set_ylim(-2, 5)\n",
    "    ######################################################################################################\n",
    "    \n",
    "    \n",
    "    # Find stars above isochrone line\n",
    "    iso_line_mask = cluster_data['J-H'].value>(k_iso_fit*cluster_data['H-K'].value + m_iso_fit)\n",
    "    \n",
    "    upper_line_mask = cluster_data['J-H'].value < (k_ext_vector*cluster_data['H-K'].value + m_upper_line)\n",
    "    lower_line_mask = cluster_data['J-H'].value > (k_ext_vector*cluster_data['H-K'].value + m_lower_line)\n",
    "    extincted_stars_mask = iso_line_mask*upper_line_mask*lower_line_mask #\n",
    "    \n",
    "    extincted_stars = cluster_data[extincted_stars_mask]\n",
    "    #print(len(extincted_stars))\n",
    "    \n",
    "    if len(extincted_stars)==0:\n",
    "        return cluster_data\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        upper_line_mask_2 = cluster_data['J-H'].value > (k_ext_vector*cluster_data['H-K'].value + m_upper_line)\n",
    "        \n",
    "        left_stars_mask = upper_line_mask_2*iso_line_mask\n",
    "        \n",
    "        left_stars = cluster_data[left_stars_mask]\n",
    "        #print(len(left_stars))\n",
    "        \n",
    "        left_stars['A_G'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_BP'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_RP'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_J'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_H'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_K'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_JK'] = np.empty((len(left_stars)))\n",
    "        \n",
    "        lower_line_mask_2 = cluster_data['J-H'].value < (k_ext_vector*cluster_data['H-K'].value + m_lower_line)\n",
    "    \n",
    "        right_stars_mask = lower_line_mask_2*iso_line_mask\n",
    "    \n",
    "        right_stars = cluster_data[right_stars_mask]\n",
    "        #print(len(right_stars))\n",
    "    \n",
    "        right_stars['A_G'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_BP'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_RP'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_J'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_H'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_K'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_JK'] = np.empty((len(right_stars)))\n",
    "        \n",
    "        # Create new line for each point by finding its m_value\n",
    "        # m = y - kx\n",
    "        m_values = extincted_stars['J-H'].value - k_ext_vector*extincted_stars['H-K'].value\n",
    "        \n",
    "        extinctions = np.empty((len(extincted_stars))) # \n",
    "        \n",
    "        # Looping over every extincted star in cluster\n",
    "        for i, m_value in enumerate(m_values):\n",
    "            #print(i)\n",
    "            # Find where it crosses isochrone line for each star\n",
    "            # |extinction_vector_star_slope - isochrone_line_fit|\n",
    "            \n",
    "            #x_var = sp.symbols('x')\n",
    "            #to_solve = (k_ext_vector*x_var+m_value) - (k_iso_fit*x_var+m_iso_fit)\n",
    "            #x_coord = float(sp.solve(to_solve)[0])\n",
    "            \n",
    "            diff = np.abs((k_ext_vector*x_range+m_value) - (k_iso_fit*x_range+m_iso_fit))\n",
    "            \n",
    "            # Crossing is where the difference is closest to zero\n",
    "            crossing = np.where(diff==np.min(diff))[0][0]\n",
    "            \n",
    "            # Crossing coordinate\n",
    "            x_coord = x_range[crossing] # H-K colour\n",
    "            y_coord = k_ext_vector*x_coord+m_value # J-H colour\n",
    "            \n",
    "            cluster_data['J-H'].value>(k_iso_fit*cluster_data['H-K'].value + m_iso_fit)\n",
    "            \n",
    "            while y_coord>=k_iso_fit*x_coord + m_iso_fit:\n",
    "                crossing = crossing - 1\n",
    "                x_coord = x_range[crossing] # H-K colour\n",
    "                y_coord = k_ext_vector*x_coord+m_value # J-H colour\n",
    "            \n",
    "            extincted_stars[i]['H-K'] = x_coord*u.mag\n",
    "            extincted_stars[i]['J-H'] = y_coord*u.mag\n",
    "        \n",
    "            # Find distance between/length of isochrone line and data point\n",
    "            dx = cluster_data[i]['H-K'].value - x_coord\n",
    "            dy = cluster_data[i]['J-H'].value - y_coord\n",
    "        \n",
    "            length = np.sqrt(dx**2 + dy**2)\n",
    "            #print(length)\n",
    "            # Divide by A_v=1 length to get extinction\n",
    "            extinctions[i] = length/len_ext_vector\n",
    "        \n",
    "    \n",
    "        extincted_stars['A_G'] = 0.789*extinctions * u.mag\n",
    "        extincted_stars['A_BP'] = 1.002*extinctions * u.mag\n",
    "        extincted_stars['A_RP'] = 0.589*extinctions * u.mag\n",
    "    \n",
    "        #extincted_stars['A_J'] = 0.243*extinctions * u.mag\n",
    "        #extincted_stars['A_H'] = 0.131*extinctions * u.mag\n",
    "        #extincted_stars['A_J'] = 0.078*extinctions * u.mag\n",
    "        #extincted_stars['A_JK'] = (0.243*extinctions - 0.078*extinctions)* u.mag\n",
    "    \n",
    "        # Mean\n",
    "        #print(extinctions)\n",
    "        mean_A_G = np.mean(0.789*extinctions) * u.mag\n",
    "        mean_A_BP = np.mean(1.002*extinctions) * u.mag\n",
    "        mean_A_RP = np.mean(0.589*extinctions) * u.mag\n",
    "    \n",
    "        mean_A_J = np.mean(0.243*extinctions) * u.mag\n",
    "        mean_A_H = np.mean(0.131*extinctions) * u.mag\n",
    "        mean_A_K = np.mean(0.078*extinctions) * u.mag\n",
    "        mean_A_JK = mean_A_J-mean_A_K\n",
    "    \n",
    "        left_stars['A_G'] = mean_A_G\n",
    "        left_stars['A_BP'] = mean_A_BP\n",
    "        left_stars['A_RP'] = mean_A_RP\n",
    "    \n",
    "        left_stars['A_J'] = mean_A_J\n",
    "        left_stars['A_H'] = mean_A_H\n",
    "        left_stars['A_K'] = mean_A_K\n",
    "        #left_stars['A_JK'] = mean_A_JK\n",
    "    \n",
    "        left_stars['J'] = (left_stars['J'].value - left_stars['A_J'].value)*u.mag\n",
    "        left_stars['H'] = (left_stars['H'].value - left_stars['A_H'].value)*u.mag\n",
    "        left_stars['K'] = (left_stars['K'].value - left_stars['A_K'].value)*u.mag\n",
    "        #left_stars['J-K'] = (left_stars['J'].value - left_stars['K'].value)*u.mag\n",
    "        left_stars['J-H'] = (left_stars['J'].value - left_stars['H'].value)*u.mag\n",
    "        left_stars['H-K'] = (left_stars['H'].value - left_stars['K'].value)*u.mag\n",
    "\n",
    "    \n",
    "    \n",
    "        right_stars['A_G'] = mean_A_G\n",
    "        right_stars['A_BP'] = mean_A_BP\n",
    "        right_stars['A_RP'] = mean_A_RP\n",
    "        \n",
    "        right_stars['A_J'] = mean_A_J\n",
    "        right_stars['A_H'] = mean_A_H\n",
    "        right_stars['A_K'] = mean_A_K\n",
    "        #right_stars['A_JK'] = mean_A_JK\n",
    "    \n",
    "        right_stars['J'] = (right_stars['J'].value - right_stars['A_J'].value)*u.mag\n",
    "        right_stars['H'] = (right_stars['H'].value - right_stars['A_H'].value)*u.mag\n",
    "        right_stars['K'] = (right_stars['K'].value - right_stars['A_K'].value)*u.mag\n",
    "        #right_stars['J-K'] = (right_stars['J'].value - right_stars['K'].value)*u.mag\n",
    "        right_stars['J-H'] = (right_stars['J'].value - right_stars['H'].value)*u.mag\n",
    "        right_stars['H-K'] = (right_stars['H'].value - right_stars['K'].value)*u.mag\n",
    "        \n",
    "        \n",
    "        # Replacing all extincted stars' values with the corrected values\n",
    "        cluster_data[extincted_stars_mask] = extincted_stars\n",
    "    \n",
    "        cluster_data[left_stars_mask] = left_stars\n",
    "        cluster_data[right_stars_mask] = right_stars\n",
    "    \n",
    "        ######################################################################################################\n",
    "        \n",
    "        #ax[1].scatter(cluster_data['H-K'], cluster_data['J-H'], c='b', s=10, alpha=0.5)\n",
    "        #ax[1].plot(x_range, k_iso_fit*x_range + m_iso_fit, linestyle='dashed', color='g')\n",
    "        #ax[1].plot(x_range, k_ext_vector*x_range + m_upper_line, linestyle='dashed', color='m')\n",
    "        #ax[1].plot(x_range, k_ext_vector*x_range + m_lower_line, linestyle='dashed', color='m')\n",
    "        \n",
    "        #ax[1].grid()\n",
    "        #ax[1].set_xlim(-2, 3)\n",
    "        #ax[1].set_ylim(-2, 5)\n",
    "        \n",
    "        #plt.tight_layout()\n",
    "        #plt.show\n",
    "        ######################################################################################################\n",
    "    \n",
    "        return cluster_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c5370e-b348-48f9-b950-29bca9ee60e8",
   "metadata": {},
   "source": [
    "## Calculating extinction values for the different passbands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b27c046-387d-4882-b8ad-027a9cb326a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Av_calc(Rv):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "    -------\n",
    "    Array with extinction parameters for the colour filters\n",
    "    \"\"\"\n",
    "    # J, H, K\n",
    "    a = np.array([0.4008, 0.2693, 0.1615])\n",
    "    b = np.array([-0.3679, -0.2473, -0.1483])\n",
    "    A_Av = a + b/Rv\n",
    "    return np.round(A_Av, decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d9d402-8955-4e1d-97e3-8c234817039e",
   "metadata": {},
   "source": [
    "## Extinction coefficient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c657e216-3012-4500-947d-5361acd44c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extinction_per_band(band, X, Av):\n",
    "    coefficients = QTable.read('Data/Extinction_law_coeff/Fitz19_EDR3_MainSequence.csv', \n",
    "                               format='csv', delimiter=',', \n",
    "                               names=['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'a10', \n",
    "                                      'Xname', 'Band'])\n",
    "    \n",
    "    coefficients_mask = coefficients['Xname']=='BPRP'\n",
    "    \n",
    "    coefficients = coefficients[coefficients_mask]\n",
    "    \n",
    "    if band=='G':\n",
    "        coeff = coefficients[coefficients['Band']=='kG']\n",
    "        \n",
    "    elif band=='BP':\n",
    "        coeff = coefficients[coefficients['Band']=='kBP']\n",
    "        \n",
    "    elif band=='RP':\n",
    "        coeff = coefficients[coefficients['Band']=='kRP']\n",
    "        \n",
    "    \n",
    "    k = coeff['a1'] + coeff['a2']*X + coeff['a3']*X**2 + coeff['a4']*X**3 + \\\n",
    "        coeff['a5']*Av + coeff['a6']*Av**2 + coeff['a7']*Av**3 + \\\n",
    "        coeff['a8']*Av*X + coeff['a9']*Av*X**2 + coeff['a10']*X*Av**2\n",
    "    \n",
    "    extinction = k*Av\n",
    "    \n",
    "    return extinction*u.mag\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc2742f-7870-4ae0-b54e-5208a7d3b608",
   "metadata": {},
   "source": [
    "## Estimating density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5a777c59-1629-4f44-9abd-2598745428cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density(ra, dec, cluster_distance, cluster_number, \n",
    "            plot_centre=True, save_plot_centre=False):\n",
    "    \n",
    "    ra = ra[:, np.newaxis]\n",
    "    dec = dec[:, np.newaxis]\n",
    "    pos = np.concatenate([ra, dec], axis=1)\n",
    "    \n",
    "    d_cl = cluster_distance[0]\n",
    "    \n",
    "    estimate = KMeans(1, n_init=100) # Only want centroid of one cluster\n",
    "    estimate.fit(pos)\n",
    "    col_kmeans = estimate.predict(pos) # Predicts closest cluster that each sample in pos belongs to\n",
    "    centroid_x = estimate.cluster_centers_[0][0]\n",
    "    centroid_y = estimate.cluster_centers_[0][1]\n",
    "    centroid = SkyCoord(ra=centroid_x, dec=centroid_y, frame='icrs', unit='deg')\n",
    "    pos_stars = SkyCoord(ra=pos[:, 0], dec=pos[:, 1], frame='icrs', unit='deg')\n",
    "        \n",
    "    \n",
    "    diffs_x = np.abs(pos[:, 0] - centroid_x*u.deg)\n",
    "    diffs_y = np.abs(pos[:, 1] - centroid_y*u.deg)\n",
    "    r_diffs = np.sqrt(diffs_x**2 + diffs_y**2) # deg\n",
    "    max_r = np.max(r_diffs) # deg\n",
    "    max_r_rad = max_r.value * np.pi/180 * u.rad\n",
    "    max_r_pc = cluster_distance*np.tan(max_r_rad)\n",
    "    \n",
    "    r_range = np.linspace(0, max_r, 1000) # deg\n",
    "    \n",
    "    n_stars = len(ra)\n",
    "    \n",
    "    n_90percent = np.round(0.90*n_stars)\n",
    "    n_75percent = np.round(0.75*n_stars)\n",
    "    n_50percent = np.round(0.50*n_stars)\n",
    "    \n",
    "    n_stars_per_radius = np.empty(len(r_range))\n",
    "    \n",
    "    for i, r in enumerate(r_range):\n",
    "        n_stars_mask = r_diffs<r\n",
    "        n_stars_per_radius[i] = len(r_diffs[n_stars_mask])\n",
    "        \n",
    "    \n",
    "    # 90%\n",
    "    _90_diff = np.abs(n_stars_per_radius - n_90percent)\n",
    "    closest_90_percent = np.min(_90_diff)\n",
    "    _90_percent_pos = np.where(_90_diff==closest_90_percent)[0]\n",
    "    \n",
    "    if len(_90_percent_pos)>1:\n",
    "        _90_percent_pos = _90_percent_pos[-1]\n",
    "    \n",
    "    _90_n = n_stars_per_radius[_90_percent_pos]\n",
    "    r_90 = r_range[_90_percent_pos] #deg\n",
    "    r_90_pc = d_cl*np.tan(r_90.value * np.pi/180 * u.rad)\n",
    "    \n",
    "    \n",
    "    # 75%\n",
    "    _75_diff = np.abs(n_stars_per_radius - n_75percent)\n",
    "    closest_75_percent = np.min(_75_diff)\n",
    "    _75_percent_pos = np.where(_75_diff==closest_75_percent)[0]\n",
    "    \n",
    "    if len(_75_percent_pos)>1:\n",
    "        _75_percent_pos = _75_percent_pos[-1]\n",
    "    \n",
    "    _75_n = n_stars_per_radius[_75_percent_pos]\n",
    "    r_75 = r_range[_75_percent_pos] #deg\n",
    "    r_75_pc = d_cl*np.tan(r_75.value * np.pi/180 * u.rad)\n",
    "    \n",
    "    \n",
    "    # 50%\n",
    "    _50_diff = np.abs(n_stars_per_radius - n_50percent)\n",
    "    closest_50_percent = np.min(_50_diff)\n",
    "    _50_percent_pos = np.where(_50_diff==closest_50_percent)[0]\n",
    "    \n",
    "    if len(_50_percent_pos)>1:\n",
    "        _50_percent_pos = _50_percent_pos[-1]\n",
    "    \n",
    "    _50_n = n_stars_per_radius[_50_percent_pos]\n",
    "    r_50 = r_range[_50_percent_pos] #deg\n",
    "    r_50_pc = d_cl*np.tan(r_50.value * np.pi/180 * u.rad)\n",
    "    \n",
    "    #print(r_90_pc, r_75_pc, r_50_pc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Whole radius\n",
    "    _90percent_area = np.pi*r_90_pc**2 # pc**2\n",
    "    _90percent_density = _90_n/_90percent_area\n",
    "    \n",
    "    \n",
    "    _75percent_area = np.pi*r_75_pc**2\n",
    "    _75percent_density = _75_n/_75percent_area\n",
    "    \n",
    "    \n",
    "    # 1/2 half radius\n",
    "    _50percent_area = np.pi*r_50_pc**2 # pc**2\n",
    "    _50percent_density = _50_n/_50percent_area\n",
    "    \n",
    "    \n",
    "    if plot_centre:        \n",
    "        fig, ax = plt.subplots(figsize=(7, 7))\n",
    "        \n",
    "        plt.minorticks_on()\n",
    "        \n",
    "        ax.scatter(pos[:, 0], pos[:, 1], c=col_kmeans, cmap='rainbow', s=10, alpha=0.5, \n",
    "                   label='Cluster stars')\n",
    "        \n",
    "        ax.scatter(centroid_x, centroid_y, c='r', marker='+', s=40, label='Centroid')\n",
    "        full_circle = plt.Circle((centroid_x, centroid_y), radius=r_90.value, fill=False, \n",
    "                                 lw=2, color='darkgreen', label='90% radius')\n",
    "        ax.add_artist(full_circle)\n",
    "        \n",
    "        circle_3_4 = plt.Circle((centroid_x, centroid_y), radius=r_75.value, fill=False, \n",
    "                                 lw=2, color='limegreen', label='75% radius')\n",
    "        ax.add_artist(circle_3_4)\n",
    "        \n",
    "        half_circle = plt.Circle((centroid_x, centroid_y), radius=r_50.value, fill=False, \n",
    "                                 lw=2, color='lime', label='50% radius')\n",
    "        ax.add_artist(half_circle)\n",
    "        \n",
    "        ax.set_xlabel('Ra [deg]')\n",
    "        ax.set_ylabel('Dec [deg]')\n",
    "        ax.set_title(f'Cluster {cluster_number} with centroid')\n",
    "        \n",
    "        ax.set_xlim(xmin=centroid_x-max_r.value-1, xmax=centroid_x+max_r.value+1)\n",
    "        ax.set_ylim(ymin=centroid_y-max_r.value-1, ymax=centroid_y+max_r.value+1)\n",
    "        ax.grid(True, which='both')\n",
    "        \n",
    "        ax.legend()\n",
    "        \n",
    "        if save_plot_centre:\n",
    "            plt.savefig(f'Plots/Finding_cluster_centre_{cluster_number}.png', bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    #if (tot_cluster_density.unit==1/u.pc**2)&(density_3_4.unit==1/u.pc**2)&(half_radius_cluster_density.unit==1/u.pc**2):\n",
    "    #    return np.array([tot_cluster_density.value, density_3_4.value, half_radius_cluster_density.value])\n",
    "    #\n",
    "    #else:\n",
    "    #    print('Not right and/or same unit!')\n",
    "    \n",
    "    densities_array = np.array([_90percent_density.value, \n",
    "                                _75percent_density.value,\n",
    "                                _50percent_density.value], dtype=object)\n",
    "    \n",
    "    return densities_array.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522090c8-3d7b-45d5-91c0-1ddfb1b054b2",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d6908",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06058390-36e3-4903-b06b-eb271e9fcbff",
   "metadata": {},
   "source": [
    "## Query testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5282c-f8d9-435a-8f7b-7e3e478fbab9",
   "metadata": {},
   "source": [
    "from astroquery.vizier import Vizier\n",
    "\n",
    "catalog = 'J/A+A/664/A175/table4'\n",
    "columns = ['Plx', 'e_Plx', 'Gmag', 'BPmag', 'RPmag']\n",
    "Vizier.ROW_LIMIT = -1\n",
    "catalogue = Vizier.get_catalogs(catalog='J/A+A/664/A175/table4')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef975ed4-0290-45eb-9384-f272891282eb",
   "metadata": {},
   "source": [
    "cluster_table = QTable([catalogue['GaiaEDR3'], catalogue['Plx'], catalogue['e_Plx'], catalogue['Gmag'], \n",
    "                        catalogue['BPmag'], catalogue['RPmag'], catalogue['Cluster'], catalogue['_RA.icrs'], \n",
    "                        catalogue['_DE.icrs']], \n",
    "                        names = ['GaiaID', 'Parallax', 'Parallax_error', 'M_apparent', 'G_bp', 'G_rp', \n",
    "                               'Cluster_number', 'RA_ICRS', 'DE_ICRS'])\n",
    "\n",
    "cluster_table['bp_rp'] = cluster_table['G_bp'] - cluster_table['G_rp'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533a576b-0fa3-443d-9474-6ff890f5ccc7",
   "metadata": {},
   "source": [
    "cluster_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6324e96e-204a-4c7d-b5cd-dbf052588c5f",
   "metadata": {},
   "source": [
    "error_sizes = cluster_table['Parallax_error']/cluster_table['Parallax']\n",
    "\n",
    "bigger_errors_mask = error_sizes>0.2\n",
    "\n",
    "big_errors = error_sizes[bigger_errors_mask]\n",
    "\n",
    "print(len(big_errors)/len(error_sizes) * 100)\n",
    "print(len(big_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344248b2-e219-4d85-bbee-4f8acd9728ec",
   "metadata": {},
   "source": [
    "clusters_sep, clusters_names = cluster_list(cluster_table, 1, 'gaia', None, 5000)\n",
    "print(len(clusters_sep))\n",
    "print(len(clusters_names))\n",
    "\n",
    "#del [clusters_sep[499]]\n",
    "#del [clusters_names[499]]\n",
    "\n",
    "#del [clusters_sep[310]] # Problems for MIST\n",
    "#del [clusters_names[310]]\n",
    "\n",
    "#del [clusters_sep[76]] # Problems for MIST\n",
    "#del [clusters_names[76]]\n",
    "\n",
    "#del [clusters_sep[71]] # Problems for Baraffe\n",
    "#del [clusters_names[71]]\n",
    "clusters_names = np.array([float(name) for name in clusters_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546b0ca-3492-4ac1-9a62-78ec8e18e733",
   "metadata": {},
   "source": [
    "print(clusters_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67179e58-d542-4591-88b1-b4e29ec9990d",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "test_log_counts, test_log_edges, test_masses, test_ages, same_as_first_iso, cluster_names_new = final_IMFs(cluster_data=clusters_sep[181:182], cluster_names=clusters_names[181:182], model='Baraffe', \n",
    "                                                                                                         metallicity='0.00', bin_width=0.2, age_fit_plot=False, \n",
    "                                                                                                         chi_plot=False, save_chi_plot=False, plot_hists=False, save_plot_hists=False) \n",
    "\n",
    "print('Done')\n",
    "\n",
    "#cluster_tmass_data=tmass_clusters_sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a466f-6adc-4fbc-82a2-997ba27b621e",
   "metadata": {},
   "source": [
    "%%time\n",
    "tmass_cluster_data = QTable.read('Filtered_tmass_cluster_data.csv', format='csv', delimiter=',')\n",
    "\n",
    "print(len(tmass_cluster_data))\n",
    "\n",
    "tmass_sorted_data, cluster_data_short = sorting_2mass_data(tmass_cluster_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0224d1-1f71-4901-81e0-9c346d811cb8",
   "metadata": {},
   "source": [
    "tmass_clusters_sep, tmass_cluster_names = cluster_list(tmass_sorted_data, 1, '2mass', None, 5000)\n",
    "\n",
    "\n",
    "#del [tmass_clusters_sep[310]] # Problems for MIST\n",
    "\n",
    "#del [tmass_clusters_sep[76]] # Problems for MIST\n",
    "\n",
    "#del [tmass_clusters_sep[71]] # Problems for Baraffe\n",
    "\n",
    "lupus_tmass_data = tmass_clusters_sep[181]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ba516-08a7-4a01-be4b-6eacb3bd448f",
   "metadata": {},
   "source": [
    "test_iso_sep, test_iso_ages = separate_isochrones('Baraffe', metallicity='0.00', survey='2mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb05f59-9225-451f-8554-1036b6cc0574",
   "metadata": {},
   "source": [
    "# Best fitting isochrone for Lupus\n",
    "iso_j_h = test_iso_sep[7][:, 2] - test_iso_sep[7][:, 3]\n",
    "iso_h_k = test_iso_sep[7][:, 3] - test_iso_sep[7][:, 4]\n",
    "\n",
    "iso_hk_mask = (0.18<=iso_h_k)&(iso_h_k<=0.28)\n",
    "\n",
    "iso_hk = iso_h_k[iso_hk_mask]\n",
    "iso_jh = iso_j_h[iso_hk_mask]\n",
    "\n",
    "k_fit, m_fit = np.polyfit(iso_hk, iso_jh, deg=1)\n",
    "\n",
    "# Crooked line\n",
    "\n",
    "def iso_line(x, k, m):\n",
    "    #m=1.085\n",
    "    #k=-1.9\n",
    "    return k*x+m\n",
    "\n",
    "x_vals = np.linspace(-1, 2, 1000)\n",
    "y_vals = iso_line(x_vals, k_fit, m_fit)\n",
    "\n",
    "A_J = 0.282\n",
    "A_H = 0.190\n",
    "A_K = 0.114\n",
    "\n",
    "j_h_ext = A_J - A_H\n",
    "h_k_ext = A_H - A_K\n",
    "#print(j_h_ext)\n",
    "#print(h_k_ext)\n",
    "\n",
    "len_ext_vector = np.sqrt(j_h_ext**2 + h_k_ext**2)\n",
    "\n",
    "k_vec, m_vec = np.polyfit(np.array([0, h_k_ext]), np.array([0, j_h_ext]), deg=1)\n",
    "\n",
    "m_upper_line = (k_fit*0.16 + m_fit) - k_vec*0.16\n",
    "m_lower_line = (k_fit*0.33 + m_fit) - k_vec*0.33\n",
    "\n",
    "#x_vec_vals = np.linspace(0.18, 1, 100)\n",
    "\n",
    "#ext_vector_1magn = k_vec*x_vec_vals + m_vec\n",
    "\n",
    "upper_line = x_vals*k_vec + m_upper_line\n",
    "\n",
    "lower_line = x_vals*k_vec + m_lower_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b20884-2d95-48cc-a3c8-c36016f27060",
   "metadata": {},
   "source": [
    "print(tmass_clusters_sep[181].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa82b2-4ca1-4b30-93a9-ffe6781caeb2",
   "metadata": {},
   "source": [
    "lupus_corrected = extinction(k_fit, m_fit, lupus_tmass_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52e44b-b104-4e18-8339-f673888a2cb4",
   "metadata": {},
   "source": [
    "print(len(lupus_corrected))\n",
    "print(len(tmass_clusters_sep[181]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893955d-abba-457b-ae34-4571ff15ffd2",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "plt.minorticks_on()\n",
    "\n",
    "#ax.scatter(lupus_corrected['H-K'], lupus_corrected['J-H'], c='b', s=10, alpha=0.5, \n",
    "#           label='Cluster data')\n",
    "\n",
    "ax.scatter(lupus_tmass_data['H-K'], lupus_tmass_data['J-H'], c='b', s=10, alpha=0.5, \n",
    "           label='Cluster data')\n",
    "\n",
    "ax.plot(iso_h_k, iso_j_h, color='r', label='Best isochrone', lw=2, marker='*')\n",
    "\n",
    "ax.plot(x_vals, y_vals, color='g', label='Extinction line', lw=2, linestyle='dashed')\n",
    "\n",
    "ax.plot(x_vals, upper_line, color='m', lw=2, linestyle='dashed')\n",
    "ax.plot(x_vals, lower_line, color='m', lw=2, linestyle='dashed')\n",
    "\n",
    "ax.arrow(0.18, 0.78, h_k_ext, j_h_ext, color='orange', width=0.01, label=r'$A_V$=1 magn')\n",
    "\n",
    "#ax.scatter(exts_lupus['H-K'], exts_lupus['J-H'], c='m', s=20, alpha=0.5, label='Corrected stars')\n",
    "\n",
    "ax.set_xlabel('H - K')\n",
    "ax.set_ylabel('J - H')\n",
    "ax.set_title('Extinction Correction After')\n",
    "\n",
    "ax.grid(True, which='both')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlim(-1, 2) # -1, 2\n",
    "ax.set_ylim(-0.5, 2) # -0.5, 2\n",
    "\n",
    "#plt.savefig('Plots/Extinction_correction_demonstration_After.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabca4f7-cea0-45eb-8061-b0f62ad4494b",
   "metadata": {},
   "source": [
    "print(cluster_names_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8cac1-5245-42b0-8792-753d8b521c8c",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb9f39-ce03-4be0-9abf-ff49d314baf5",
   "metadata": {},
   "source": [
    "%%time\n",
    "densities = np.empty((len(clusters_sep), 3))\n",
    "\n",
    "for i, cluster in enumerate(clusters_sep):\n",
    "    print(i)\n",
    "    densities_i = density(clusters_sep[i]['RA_ICRS'], clusters_sep[i]['DE_ICRS'],\n",
    "                              clusters_sep[i]['dist'], clusters_names[i], False, False)\n",
    "    \n",
    "    \n",
    "    #print(type(densities_i))\n",
    "    #print(densities_i)\n",
    "    densities[i, :] = densities_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b825dfe-f9ac-4430-987c-328f6b891dc1",
   "metadata": {},
   "source": [
    "print(densities[13, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d10b64-4f43-4718-ac4a-ae7bb45eb8ae",
   "metadata": {},
   "source": [
    "densities_test = density(clusters_sep[181]['RA_ICRS'], clusters_sep[181]['DE_ICRS'], clusters_sep[181]['dist'], \n",
    "                         clusters_names[0], plot_centre=True, save_plot_centre=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44117c5-332e-48a6-bd10-db08b14e8808",
   "metadata": {},
   "source": [
    "print(densities_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2ce25-d3df-43c8-bb08-e5304c74328e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18ffc0df-e6e6-46ce-8f30-c549b14925d6",
   "metadata": {},
   "source": [
    "print(len(clusters_sep))\n",
    "#print(clusters_sep[181]['dist'][0])\n",
    "#print(clusters_sep[181]['dist_error'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414d796-38f3-4f02-b3f5-f03538a86edb",
   "metadata": {},
   "source": [
    "cluster1_dist = clusters_sep[603]['dist']\n",
    "mean_cl1_dist = np.mean(clusters_sep[603]['dist'])\n",
    "\n",
    "\n",
    "#print(cluster1_dist[cluster1_dist.argsort()])\n",
    "print(mean_cl1_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aebd962-0171-4852-b5f6-b3b25176d32a",
   "metadata": {},
   "source": [
    "### Testing first function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "876ed51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#times_str = ['0_0005', '0_0010', '0_0020', '0_0030', '0_0040', '0_0050', '0_0080', '0_01', '0_02', \n",
    "#         '0_03', '0_04', '0_05', '0_08', '0_1', '0_2', '0_3', '0_4', '0_5', '0_625', '0_8', \n",
    "#         '1', '2', '3', '4', '5', '8', '10']\n",
    "#\n",
    "#times_num = [0.0005, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0080, 0.01, 0.02, 0.03, 0.04, 0.05, \n",
    "#             0.08, 0.1, 0.2, 0.3, 0.4, 0.5, 0.625, 0.8, 1, 2, 3, 4, 5, 8, 10]\n",
    "#\n",
    "#isochrones = []\n",
    "#for i, time in enumerate(times_str):\n",
    "#    isochrones.append(isochrone_import(f'Isochrone_Baraffe_{time}.txt', 'Baraffe'))\n",
    "#    \n",
    "#\n",
    "#print(len(isochrones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb5cdfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lupus_data = cluster_import('Lupus_data')\n",
    "#NGC2264_data = cluster_import('NGC2264_data.txt', 'Clusters')\n",
    "#\n",
    "#data_tot = [lupus_data, NGC2264_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9b0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting_iso_and_data(data_tot, isochrones[5:7], times_num[5:7], ['Lupus','NGC2264'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b744c-fac1-4bd5-97c9-ac963b1df7c7",
   "metadata": {},
   "source": [
    "### Testing IMF from interpolation of colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c352305-09c2-4162-8148-727c7a3f3db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lupus_data = cluster_import('Lupus_data')\n",
    "\n",
    "\n",
    "#times_str = ['0_0005', '0_0010', '0_0020', '0_0030', '0_0040', '0_0050', '0_0080', '0_01', '0_02', \n",
    "#         '0_03', '0_04', '0_05', '0_08', '0_1', '0_2', '0_3', '0_4', '0_5', '0_625', '0_8', \n",
    "#         '1', '2', '3', '4', '5', '8', '10']\n",
    "\n",
    "#times_num = [0.0005, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0080, 0.01, 0.02, 0.03, 0.04, 0.05, \n",
    "#             0.08, 0.1, 0.2, 0.3, 0.4, 0.5, 0.625, 0.8, 1, 2, 3, 4, 5, 8, 10]\n",
    "\n",
    "#isochrones = []\n",
    "#for i, time in enumerate(times_str):\n",
    "#    isochrones.append(isochrone_import(f'Isochrone_Baraffe_{time}.txt', 'Baraffe'))\n",
    "#    \n",
    "#fit_params = iso_fit(isochrones)\n",
    "#print(fit_params.shape)\n",
    "#print(len(isochrones))\n",
    "#print(isochrones[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9276200-a075-40c8-ae90-0c870c2d485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isochrone_parameters = isochrone_params(times_str, 'Baraffe')\n",
    "\n",
    "#print(isochrone_parameters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58ea893d-4d6c-4e62-99ce-049434a1e519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#to_interpolate = lupus_data['bp_rp'].value\n",
    "\n",
    "#masses = IMF(to_interpolate, isochrones[6], cluster_name='Lupus', model_name='Baraffe', \n",
    "#             check=True, save_plot=False)\n",
    "\n",
    "#min_mass = np.min(masses)\n",
    "#max_mass = np.max(masses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9156b679-9650-42ea-a05e-567fce15419f",
   "metadata": {},
   "source": [
    "## Trying to fit the IMF and get parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "394549a9-1a25-4ff2-9a8e-8b1e57df09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lupus has number 181\n",
    "#test_data = clusters_sep[0:10] #cluster_import('Lupus_data') \n",
    "#test_names = clusters_names[0:10]\n",
    "\n",
    "#print(type(clusters_sep[0:2]))\n",
    "#print(test_data)\n",
    "\n",
    "#print(test_data[0]['Cluster_number']) # Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a59eda-4d13-4cd4-bf8d-e49c12222d13",
   "metadata": {},
   "source": [
    "%%time\n",
    "tmass_cluster_data = QTable.read('Filtered_tmass_cluster_data.csv', format='csv', delimiter=',')\n",
    "\n",
    "print(len(tmass_cluster_data))\n",
    "\n",
    "tmass_sorted_data, cluster_data_short = sorting_2mass_data(tmass_cluster_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5b1ee-2139-424f-8f26-413aef22b562",
   "metadata": {},
   "source": [
    "tmass_clusters_sep, tmass_cluster_names = cluster_list(tmass_sorted_data, 1, '2mass', None, 5000)\n",
    "\n",
    "\n",
    "#del [tmass_clusters_sep[310]] # Problems for MIST\n",
    "\n",
    "#del [tmass_clusters_sep[76]] # Problems for MIST\n",
    "\n",
    "#del [tmass_clusters_sep[71]] # Problems for Baraffe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed851d4b-72ef-476f-a704-e988634a076d",
   "metadata": {},
   "source": [
    "print(len(tmass_clusters_sep))\n",
    "print(len(clusters_sep))\n",
    "\n",
    "print(len(tmass_clusters_sep[17]))\n",
    "print(len(clusters_sep[17]))\n",
    "#print(tmass_clusters_sep[17].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be749f-8cde-416b-82ef-d2eba37dd961",
   "metadata": {},
   "source": [
    "inters, gids, tids = np.intersect1d(clusters_sep[17]['GaiaID'].value, tmass_clusters_sep[17]['GaiaID'].value,\n",
    "                                   return_indices=True)\n",
    "\n",
    "print(len(gids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8f017-b8ea-4c4b-8bf1-d1b9e8de853c",
   "metadata": {},
   "source": [
    "for i in range(len(clusters_sep)):\n",
    "    #print(i)\n",
    "    num_g = clusters_sep[i]['Cluster_number'][0]\n",
    "    num_t = tmass_clusters_sep[i]['Cluster_number'][0]\n",
    "    if num_g!=num_t:\n",
    "        print('Not aligned')\n",
    "        \n",
    "    intersection, ginds, tinds = np.intersect1d(clusters_sep[i]['GaiaID'].value, \n",
    "                                              tmass_clusters_sep[i]['GaiaID'].value,\n",
    "                                              return_indices=True)\n",
    "    \n",
    "    g_ids = clusters_sep[i]['GaiaID'][ginds]\n",
    "    t_ids = tmass_clusters_sep[i]['GaiaID'][tinds]\n",
    "    \n",
    "    if all(g_ids==t_ids):\n",
    "        #print(f'It is fine: cluster {i+1}')\n",
    "        continue\n",
    "    else:\n",
    "        print(f'Something is wrong: cluster {i+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f83a9-80d1-406d-ae49-1060bc2257b1",
   "metadata": {},
   "source": [
    "print(len(clusters_sep))\n",
    "print(len(clusters_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f99a1fa-938b-4968-badf-cd3d12b3bf6c",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "test_log_counts, test_log_edges, test_masses, test_ages, same_as_first_iso, cluster_names = final_IMFs(cluster_data=clusters_sep, cluster_names=clusters_names, model='MIST', \n",
    "                                                                                                         metallicity='0.00', bin_width=0.2, age_fit_plot=False, \n",
    "                                                                                                         chi_plot=False, save_chi_plot=False, plot_hists=False, save_plot_hists=False) \n",
    "\n",
    "print('Done')\n",
    "\n",
    "#cluster_tmass_data=tmass_clusters_sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f69c73-0782-4eee-8a57-7c45bc0d9e37",
   "metadata": {},
   "source": [
    "print(len(test_masses))\n",
    "print(len(test_log_counts))\n",
    "print(len(test_log_edges))\n",
    "print(len(test_ages))\n",
    "print()\n",
    "\n",
    "print(test_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d7731-082c-4ce8-b0a8-abaa0296cfd3",
   "metadata": {},
   "source": [
    "extinctions_data = QTable.read('Extinctions_file.csv', format='csv', delimiter=',')\n",
    "\n",
    "extinctions_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a05fbb5-b7e8-46ec-8a13-77ed3d976d9d",
   "metadata": {},
   "source": [
    "#print(test_ages) # Baraffe isochrone number 7\n",
    "print(len(same_as_first_iso))\n",
    "#print(same_as_first_iso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e4f70-da15-4116-a226-d6df752ac47c",
   "metadata": {},
   "source": [
    "## IMPORTANT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f9b0d-43f5-4587-ae68-ef624013fd19",
   "metadata": {},
   "source": [
    "extinctions_data = extinctions_data[extinctions_data['source_id'].argsort()]\n",
    "cluster_table = cluster_table[cluster_table['GaiaID'].argsort()]\n",
    "\n",
    "same_stars, gaia_inds, ext_inds = np.intersect1d(cluster_table['GaiaID'].value, \n",
    "                                               extinctions_data['source_id'].value, \n",
    "                                               return_indices=True)\n",
    "\n",
    "\n",
    "extinctions_data['Cluster_number'] = cluster_table[gaia_inds]['Cluster_number']\n",
    "\n",
    "unique_numbers = np.unique(extinctions_data['Cluster_number'].value)\n",
    "#print(unique_numbers)\n",
    "print(len(unique_numbers))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb2f1fd-30a8-45cb-8b35-cb1bab9cfe02",
   "metadata": {},
   "source": [
    "extinctions_data_sep, names = cluster_list(extinctions_data, 1, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294968c0-5d85-405c-95f9-b2906473af50",
   "metadata": {},
   "source": [
    "#print(tmass_clusters_sep[405].columns)\n",
    "\n",
    "print(len(extinctions_data_sep))\n",
    "\n",
    "clusters = []\n",
    "\n",
    "for extinction_stars in extinctions_data_sep:\n",
    "    clusters.append(extinction_stars['Cluster_number'][0])\n",
    "    \n",
    "    \n",
    "#print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "793276b2-f110-466d-b8c0-49d77c0f2513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del [tmass_clusters_sep[405]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b14a65-01fc-4af7-98b9-96cdd2cbadac",
   "metadata": {},
   "source": [
    "## IMPORTANT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b69bc3-268c-4e25-bb2d-a90289b4caed",
   "metadata": {},
   "source": [
    "A_G_diffs = []\n",
    "A_BP_diffs = []\n",
    "A_RP_diffs = []\n",
    "\n",
    "for i, cluster in enumerate(tmass_clusters_sep):\n",
    "    #print(i)\n",
    "    which_cluster = cluster['Cluster_number'][0]\n",
    "    pos = np.where(clusters==which_cluster)[0][0]\n",
    "    \n",
    "    extinction_data = extinctions_data_sep[pos]\n",
    "    \n",
    "    #if cluster['Cluster_number'][0]==extinctions_data_sep[i]['Cluster_number'][0]:\n",
    "    common_stars, gaia_inds, ext_inds = np.intersect1d(cluster['GaiaID'].value, \n",
    "                                                       extinctions_data['source_id'].value, \n",
    "                                                       return_indices=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    A_G_diffs.append(cluster[gaia_inds]['A_G'] - extinctions_data[ext_inds]['ag50'])\n",
    "    A_BP_diffs.append(cluster[gaia_inds]['A_BP'] - extinctions_data[ext_inds]['abp50'])\n",
    "    A_RP_diffs.append(cluster[gaia_inds]['A_RP'] - extinctions_data[ext_inds]['arp50'])\n",
    "    #print(len(gaia_inds))\n",
    "    #else:\n",
    "     #   print('Something is wrong')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4339f4e6-73c7-4d85-9e6e-b235c2146708",
   "metadata": {},
   "source": [
    "print(len(A_G_diffs[200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41897c6-001e-403b-8489-28187a214d60",
   "metadata": {},
   "source": [
    "clusters_names_float = [float(x) for x in clusters_names]\n",
    "\n",
    "#print(clusters_names_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d1b69-52ac-4bc9-b24c-9c886c5ad6bd",
   "metadata": {},
   "source": [
    "fig10, ax10 = plt.subplots(3, 1, figsize=(15, 15))\n",
    "\n",
    "\n",
    "ax10[0].set_xlabel('Cluster name/number')\n",
    "ax10[0].set_ylabel('Extinction difference')\n",
    "ax10[0].set_title(r'Extinction difference $A_G$')\n",
    "\n",
    "ax10[0].grid(True)\n",
    "ax10[0].set_xlim(-5, 680)\n",
    "\n",
    "\n",
    "\n",
    "ax10[1].set_xlabel('Cluster name/number')\n",
    "ax10[1].set_ylabel('Extinction difference')\n",
    "ax10[1].set_title(r'Extinction difference $A_{BP}$')\n",
    "\n",
    "ax10[1].grid(True)\n",
    "ax10[1].set_xlim(-5, 680)\n",
    "\n",
    "\n",
    "\n",
    "ax10[2].set_xlabel('Cluster name/number')\n",
    "ax10[2].set_ylabel('Extinction difference')\n",
    "ax10[2].set_title(r'Extinction difference $A_{RP}$')\n",
    "\n",
    "ax10[2].grid(True)\n",
    "ax10[2].set_xlim(-5, 680)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(672):\n",
    "    #print(i)\n",
    "    #print(len(A_G_diffs[i]))\n",
    "    name_array = np.empty((len(A_G_diffs[i])))\n",
    "    name_array[:] = clusters_names_float[i]\n",
    "    #print(name_array)\n",
    "    \n",
    "    ax10[0].scatter(name_array, A_G_diffs[i], s=20, alpha=0.5)\n",
    "    \n",
    "    ax10[1].scatter(name_array, A_BP_diffs[i], s=20, alpha=0.5)\n",
    "    \n",
    "    ax10[2].scatter(name_array, A_RP_diffs[i], s=20, alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1b0d503c-c627-4a2a-8e4c-25cb81462105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(A_G_diffs[0])\n",
    "#print(np.min(A_G_diffs[0]))\n",
    "#print('-----------------------------------------------------------------------')\n",
    "#print(A_BP_diffs[0])\n",
    "#print(np.min(A_BP_diffs[0]))\n",
    "#print('-----------------------------------------------------------------------')\n",
    "#print(A_RP_diffs[0])\n",
    "#print(np.min(A_RP_diffs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393304b0-1853-40fe-835f-d055e2b495c4",
   "metadata": {},
   "source": [
    "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "ind = np.linspace(0, len(arr)-1, len(arr), dtype=int)\n",
    "\n",
    "print(arr)\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe48b06f-8562-4085-bbfe-67feb9fbddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(lupus_masses)):\n",
    "#    print(len(lupus_masses[i]))\n",
    "\n",
    "#print(test_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "8232becc-a8ff-478e-9523-86b78fd88b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(log_lupus_edges[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b873d-f82e-410d-90c3-ad3bc96c5b83",
   "metadata": {},
   "source": [
    "### Saving files for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "26e50b5d-1f90-47e4-b591-a95e3017dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('failed_cluster_counts', log_lupus_counts[:, 2])\n",
    "#np.save('failed_cluster_edges', log_lupus_edges[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "7b9dbdcd-1ecb-4a4b-98c7-9b0933eb08b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.shape(log_lupus_counts))\n",
    "\n",
    "#print(type(log_lupus_counts[:, -1]))\n",
    "\n",
    "#if any(log_lupus_counts[:, -1]==0.):\n",
    "#    print('Yes')\n",
    "    \n",
    "#new_log_counts = [counts for counts in log_lupus_counts[:, -1] if counts!=0.]\n",
    "\n",
    "#print(new_log_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9705a27-570c-4391-a0ed-a281f39cdbc8",
   "metadata": {},
   "source": [
    "## IMPORTANT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5d244-2349-445d-94fd-70488f836cbe",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "bin_widths_test, all_cluster_params_test, kroupa_diff_test, counter = IMF_slopes(test_log_edges, test_log_counts, \n",
    "                                                                         test_masses, model='Baraffe', intervals='Kroupa', \n",
    "                                                                         plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c7865b-6f3f-447b-ac3a-5fea30a3aa2a",
   "metadata": {},
   "source": [
    "print(kroupa_diff_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28f2aed8-8707-47e8-aef3-45cea969fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(bin_widths_test))\n",
    "#print(len(all_cluster_params_test))\n",
    "#print(len(kroupa_diff_test))\n",
    "#print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7028bfa3-20be-468f-b594-97ee8311e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print()\n",
    "#print(f'Widths = {bin_widths_test}')\n",
    "#print()\n",
    "#print(f'Slopes for all clusters for all intervals = {all_cluster_params_test[:, 0, :]}')\n",
    "#print()\n",
    "#print(f'Difference from Kroupa = {kroupa_diff_test}')\n",
    "#print()\n",
    "#print(f'Number of clusters that had to cut interval bc of zero-bins = {counter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ebec6-f242-48ab-9aff-2d2adb0dea82",
   "metadata": {},
   "source": [
    "### Setting up middle of bins and checking bin widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "415e4099-4708-4f50-a45c-8c3fc3cf6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculting the widths without a for-loop\n",
    "\n",
    "#arr1 = np.array([1, 2, 3, 4, 5])\n",
    "#arr2 = np.roll(arr1, shift=1)\n",
    "#arr = arr2-arr1\n",
    "#arr_tot = np.delete(arr, arr==arr[0])\n",
    "\n",
    "#if all(arr_tot==-1):\n",
    "#    print('yes')\n",
    "\n",
    "#print(arr)\n",
    "#print(arr_tot)\n",
    "\n",
    "\n",
    "\n",
    "# Method for finding true values in mask:\n",
    "\n",
    "#arr1 = np.array([1, 2, 2, 3, 4, 5, 2, 2, 6, 7])\n",
    "\n",
    "#arr_mask = arr1==2\n",
    "\n",
    "#if len(arr_mask[arr_mask==True])==4:\n",
    "#    print('Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40755199-61a1-4774-ac0a-44b341ebaff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_bins = len(log_lupus_edges) - 1 \n",
    "\n",
    "#bin_width = np.empty((n_bins)) # In log(solar_masses)\n",
    "#bin_pos = np.empty((n_bins)) # In solar_masses\n",
    "\n",
    "#for i in range(n_bins):\n",
    "#    bin_pos[i] = (log_lupus_edges[i] + log_lupus_edges[i+1])/2\n",
    "#    bin_width[i] = np.abs(np.log(log_lupus_edges[i]) - np.log(log_lupus_edges[i+1]))\n",
    "\n",
    "\n",
    "\n",
    "#print(bin_pos, 'solMass')\n",
    "#print()\n",
    "#print(bin_width, 'dex')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12ede6-b33a-4dd9-aebe-4c9632163a2e",
   "metadata": {},
   "source": [
    "### Dividing up into mass intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "f3ae801a-8563-4c11-be90-028a69028cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interval1_mask = (0.01<=bin_pos)&(bin_pos<=0.08) # bin_pos<=0.1\n",
    "#interval2_mask = (0.08<=bin_pos)&(bin_pos<=0.5) #0.1<=bin_pos  \n",
    "#interval3_mask = (0.5<=bin_pos)#&(bin_pos<1)\n",
    "#interval4_mask = 1<=bin_pos\n",
    "\n",
    "#mass_int1 = bin_pos[interval1_mask]\n",
    "#mass_int2 = bin_pos[interval2_mask]\n",
    "#mass_int3 = bin_pos[interval3_mask]\n",
    "#mass_int4 = bin_pos[interval4_mask]\n",
    "\n",
    "#print(mass_int2)\n",
    "\n",
    "#count_int1 = log_lupus_counts[interval1_mask]\n",
    "#count_int2 = log_lupus_counts[interval2_mask]\n",
    "#count_int3 = log_lupus_counts[interval3_mask]\n",
    "#count_int4 = log_lupus_counts[interval4_mask]\n",
    "\n",
    "\n",
    "#int_masses = [mass_int1, mass_int2, mass_int3]#, mass_int4] #  \n",
    "#int_counts = [count_int1, count_int2, count_int3]#, count_int4] # \n",
    "\n",
    "#print(len(bin_pos))\n",
    "#print(len(mass_int1) + len(mass_int2) )\n",
    "#print(len(count_int1) + len(count_int2) )\n",
    "\n",
    "#print(int_masses[0])\n",
    "#print(type(int_masses[0][0]))\n",
    "#print()\n",
    "#print(np.shape(int_counts[0]))\n",
    "\n",
    "#flat_arr = int_counts[0].flatten()\n",
    "#print(flat_arr)\n",
    "#print(type(flat_arr[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab7d64-e11b-4622-8dd1-3bdd403c2c1c",
   "metadata": {},
   "source": [
    "### Making fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "529ddbf6-a528-4698-a8fa-8db4cc2a8684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def fcn(x, a, C):\n",
    "#    return C*x**a\n",
    "\n",
    "\n",
    "#params = np.empty((2, len(int_counts))) # (parameters, intervals)\n",
    "#covariance = []\n",
    "#x_fit_vals = np.empty((500, len(int_counts)))\n",
    "#fit_vals = np.empty((500, len(int_counts)))\n",
    "#fit_vals_kroupa = np.empty((500, len(int_counts)))\n",
    "#a_kroupa = np.array([0.3, 1.3, -2.3, -2.3])\n",
    "#c_kroupa = np.array([20, 600, 50, 50])\n",
    "#for i, masses in enumerate(int_masses):\n",
    "#    flat_counts = int_counts[i].flatten()\n",
    "#    p, c = scopt.curve_fit(fcn, xdata=masses, ydata=flat_counts)\n",
    "#    params[:, i] = p\n",
    "#    covariance.append(c)\n",
    "    \n",
    "#    a_fit, C_fit = p\n",
    "#    x_fit_vals[:, i] = np.linspace(np.min(masses), np.max(masses), 500)\n",
    "#    fit_vals[:, i] = fcn(x_fit_vals[:, i], a_fit, C_fit)\n",
    "#    fit_vals_kroupa[:, i] = fcn(x_fit_vals[:, i], a_kroupa[i], c_kroupa[i])\n",
    "\n",
    "    \n",
    "#print(np.log10(np.abs(params[0, :]))) # Prints all a-values\n",
    "#print(params[0, :])\n",
    "#print(params[1, :]) # Prints all C-values\n",
    "\n",
    "#print(np.shape(fit_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "8b94a690-8056-4c68-a681-53ae4c4856a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig1, ax1 = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "#min_mass = np.min(lupus_masses)\n",
    "#max_mass = np.max(lupus_masses)\n",
    "\n",
    "#ax1[0].hist(lupus_masses, bins=n_bins, histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5, \n",
    "#            label='IMF hist')\n",
    "#ax1[0].plot(x_fit_vals[:, 0], fit_vals[:, 0], color='r', label='Fitted Interval 1')\n",
    "#ax1[0].plot(x_fit_vals[:, 1], fit_vals[:, 1], color='orange', label='Fitted Interval 2')\n",
    "#ax1[0].plot(x_fit_vals[:, 2], fit_vals[:, 2], color='g', label='Fitted Interval 3')\n",
    "#ax1[0].plot(x_fit_vals[:, 3], fit_vals[:, 3], color='m', label='Fitted Interval 4')\n",
    "\n",
    "#ax1[0].set_xlabel(r'Mass [M$_{\\odot}$]')\n",
    "#ax1[0].set_ylabel('Counts')\n",
    "#ax1[0].set_title(f'Baraffe IMF for Lupus: normal scale')\n",
    "#ax1[0].grid(True)\n",
    "#ax1[0].set_xscale('log')\n",
    "\n",
    "\n",
    "\n",
    "#ax1[1].hist(lupus_masses, range=(np.log10(min_mass), np.log10(max_mass)), \n",
    "#            bins=np.logspace(np.log10(min_mass), np.log10(max_mass), n_bins+1), \n",
    "#            histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5, \n",
    "#            label='IMF hist')\n",
    "#ax1[1].plot(x_fit_vals[:, 0], fit_vals[:, 0], color='r', label='Fitted Interval 1')\n",
    "#ax1[1].plot(x_fit_vals[:, 1], fit_vals[:, 1], color='orange', label='Fitted Interval 2')\n",
    "#ax1[1].plot(x_fit_vals[:, 2], fit_vals[:, 2], color='g', label='Fitted Interval 3')\n",
    "#ax1[1].plot(x_fit_vals[:, 3], fit_vals[:, 3], color='m', label='Fitted Interval 4')\n",
    "\n",
    "#ax1[1].plot(x_fit_vals[:, 0], fit_vals_kroupa[:, 0], color='r', linestyle='dashed', label='Kroupa Interval 1')\n",
    "#ax1[1].plot(x_fit_vals[:, 1], fit_vals_kroupa[:, 1], color='orange', linestyle='dashed', label='Kroupa Interval 2')\n",
    "#ax1[1].plot(x_fit_vals[:, 2], fit_vals_kroupa[:, 2], color='g', linestyle='dashed', label='Kroupa Interval 3')\n",
    "#ax1[1].plot(x_fit_vals[:, 3], fit_vals_kroupa[:, 3], color='m', linestyle='dashed', label='Kroupa Interval 4')\n",
    "\n",
    "#ax1[1].set_xlabel(r'Mass [M$_{\\odot}$]')\n",
    "#ax1[1].set_ylabel('Counts')\n",
    "#ax1[1].set_title(f'Baraffe IMF for Lupus: log scale')\n",
    "\n",
    "#ax1[1].set_xscale('log')\n",
    "#ax1[1].set_yscale('log')\n",
    "#ax1[1].set_ylim(ymin=0)\n",
    "#ax1[1].grid(True)\n",
    "#ax1[1].legend()\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e948a2-76da-41cd-8768-81a9ed61d0c5",
   "metadata": {},
   "source": [
    "### Fitting isochrones test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cca4894c-6645-4340-92db-11751c881fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isos = isochrones[7][isochrones[7][:, 0].argsort()] # Sort according to magnitude\n",
    "\n",
    "#magnitude_mask = isos[:, 0]<16\n",
    "\n",
    "#iso_x = isos[:, 1][magnitude_mask]\n",
    "#iso_y = isos[:, 0][magnitude_mask]\n",
    "\n",
    "#print(iso_x)\n",
    "#print()\n",
    "\n",
    "#results, cov = np.polyfit(iso_x, iso_y, 5, cov=True)\n",
    "#print(results)\n",
    "#print()\n",
    "#print(cov)\n",
    "\n",
    "#k5, k4, k3, k2, k1, c = results\n",
    "\n",
    "#def iso_fit(x):\n",
    "#    return k5*x**5 + k4*x**4 + k3*x**3 +k2*x**2 + k1*x**1 + c\n",
    "\n",
    "#x_vals = np.linspace(np.min(iso_x), np.max(iso_x), 1000)\n",
    "#y_vals = iso_fit(x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "814d1e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig2, ax2 = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "#ax2.scatter(iso_x, iso_y, c='r', s=10, label='Isochrone data')\n",
    "#ax2.scatter(lupus_data['bp_rp'], lupus_data['M_V'], c='g', s=5, label='Lupus data')\n",
    "#ax2.plot(isochrones[6][:, 1], isochrones[6][:, 0], color='orange')\n",
    "#ax2.scatter(isochrones[0][:, 1], isochrones[0][:, 0], c='m', s=10)\n",
    "#ax2.plot(x_vals, y_vals, 'b', label='Fitted isochrone')\n",
    "\n",
    "#ax2.set_xlabel('Colour')\n",
    "#ax2.set_ylabel('Magnitude')\n",
    "\n",
    "#ax2.axhline(16.5, color='k', linestyle='dashed')\n",
    "#ax2.legend()\n",
    "\n",
    "#ax2.grid(True)\n",
    "\n",
    "#ax2.invert_yaxis()\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a81e85c-5cba-447d-af55-56dbc290bacc",
   "metadata": {},
   "source": [
    "### Testing chi-square estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a55fde46-5f10-4bb8-b00c-29d358e58773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chis = chi_fitting(fit_fcn, lupus_data, isochrone_parameters)\n",
    "\n",
    "#min_chi = np.min(chis)\n",
    "#min_pos = np.where(chis==min_chi)[0]\n",
    "\n",
    "#print(chis)\n",
    "#print(min_chi)\n",
    "#print(min_pos)\n",
    "#print(times_num[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6cca8c47-952c-42fe-8f85-450c4c3f293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig5, ax5 = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "#ax5.scatter(np.array(times_num), chis, color='b')\n",
    "\n",
    "#ax5.set_xlabel('Ages [Myr]')\n",
    "#ax5.set_ylabel(r' $\\chi^2$ values')\n",
    "#ax5.grid()\n",
    "#ax5.set_xscale('log')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "18d87403-9dfa-4988-a230-6fd3fadbf510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy.stats as scstat\n",
    "\n",
    "# x-axis is the colour\n",
    "#isochrone_x = np.linspace(np.min(lupus_data['bp_rp'].value), \n",
    "#                          np.max(lupus_data['bp_rp'].value), 846)\n",
    "\n",
    "#params = fit_params[:, 10]\n",
    "#isochrone_y = fit_fcn(isochrone_x, args=params) \n",
    "\n",
    "#iso_y = isochrone_y/np.sum(isochrone_y)\n",
    "\n",
    "# Normalized absolute magnitude\n",
    "#normalized_lupus_data = lupus_data['M_V'].value/(np.sum(lupus_data['M_V'].value))\n",
    "\n",
    "#chi_vals = np.empty((27))\n",
    "\n",
    "#for i in range(27):\n",
    "#    params = fit_params[:, i]\n",
    "    \n",
    "    # y-axis is the absolute magnitude, getting absolute magnitude from colour\n",
    "#    isochrone_y = fit_fcn(isochrone_x, args=params) \n",
    "#    iso_y = isochrone_y/np.sum(isochrone_y) # normalize model data\n",
    "    \n",
    "    # Chi-square made for absolute magnitude\n",
    "#    chi_vals[i], p_value = scstat.chisquare(normalized_lupus_data, iso_y)\n",
    "\n",
    "\n",
    "    \n",
    "#min_chi = np.min(chi_vals)\n",
    "#min_pos = np.where(chi_vals==min_chi)[0]\n",
    "\n",
    "#print(chi_vals)\n",
    "#print(min_chi)\n",
    "#print(min_pos)\n",
    "#print(chi_vals[6])\n",
    "#result, p_val = scstat.chisquare(normalized_lupus_data, iso_y)\n",
    "\n",
    "#print(result)\n",
    "#print(p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e72ba99-25a0-44da-9731-5195d055c158",
   "metadata": {},
   "source": [
    "Columns in the Vizier tables and their units\n",
    "\n",
    "GLON, GLAT, Plx, e_Plx, pmRA, e_pmRA, pmDE, e_pmDE, Gmag, BPmag, RPmag, Flag, Cluster, _RA.icrs, _DE.icrs\n",
    "deg, deg, mas, mas, mas/yr, mas/yr, mas/yr, mas/yr, mag, mag, mag, , , deg, deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d0fc8-71f3-49dc-b099-1c6942886031",
   "metadata": {},
   "source": [
    "### Testing final IMF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa11fa92-c902-41fc-ac5a-5ac78e175e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#times_str = ['0_0005', '0_0010', '0_0020', '0_0030', '0_0040', '0_0050', '0_0080', '0_01', '0_02', \n",
    "#         '0_03', '0_04', '0_05', '0_08', '0_1', '0_2', '0_3', '0_4', '0_5', '0_625', '0_8', \n",
    "#         '1', '2', '3', '4', '5', '8', '10']\n",
    "#\n",
    "#times_num = [0.0005, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0080, 0.01, 0.02, 0.03, 0.04, 0.05, \n",
    "#             0.08, 0.1, 0.2, 0.3, 0.4, 0.5, 0.625, 0.8, 1, 2, 3, 4, 5, 8, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "14a5264e-3025-483b-b40d-0cb8b2839c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal_cluster_counts, normal_cluster_edges, log_cluster_counts, log_cluster_edges = final_IMFs(cluster_data=clusters_sep[181:182], cluster_names=clusters_names[181:182], \n",
    "#                                                                                                model='Baraffe', metallicity='0.00', nbins=15, age_fit_plot=True, \n",
    "#                                                                                                chi_plot=True, save_chi_plot=False) \n",
    "# check_interp=True, save_check_interp=False, plot_hists=True, save_plot_hists=False,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb5ee15-1c5b-418d-a214-2122d5e97c90",
   "metadata": {},
   "source": [
    "### Testing new interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "d5bfdc1a-59aa-4cc9-a30a-6320bb210c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iso_data, iso_ages = separate_isochrones('Baraffe', '0.00')\n",
    "#iso_ages = iso_ages.flatten()\n",
    "#iso_params = isochrone_params(iso_data, 'Baraffe')\n",
    "#print(len(iso_data))\n",
    "\n",
    "#lupus_data = cluster_import('Lupus_data')\n",
    "#print(len(lupus_data['M_V']))\n",
    "#lupus_magn_mask = lupus_data['M_V'].value>0\n",
    "\n",
    "#lupus_magn_data = lupus_data[lupus_magn_mask]\n",
    "\n",
    "#print(len(lupus_magn_data['M_V']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "8f502874-f052-41b0-8efa-cd0b12ed43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi_values_lupus = chi_fitting(fit_fcn, lupus_data, iso_params, iso_data)\n",
    "\n",
    "# Considering age interpolation correct!\n",
    "#new_lupus_age, younger_iso, younger_age, older_iso, older_age = new_age_interpolation(chi_values_lupus, iso_data, iso_ages, 'Lupus', plot=True)\n",
    "\n",
    "\n",
    "#lupus_stellar_masses = interpolated_mass(lupus_data, 'Lupus', new_lupus_age[0], younger_iso, \n",
    "#                                         older_iso, younger_age, older_age, 'Baraffe')\n",
    "\n",
    "#print(len(lupus_stellar_masses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "eed5fa42-a3ae-4e75-9e0e-96d6e2b14cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig10, ax10 = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "#ax10[0].hist(lupus_stellar_masses, 15, fc=(0, 0, 1, 0.25), ec='b', histtype='stepfilled')\n",
    "\n",
    "#ax10[0].grid(True)\n",
    "\n",
    "\n",
    "#min_mass = np.min(lupus_stellar_masses)\n",
    "#max_mass = np.max(lupus_stellar_masses)\n",
    "\n",
    "#ax10[1].hist(lupus_stellar_masses, range=(np.log10(min_mass), np.log10(max_mass)), \n",
    "#                     bins=np.logspace(np.log10(min_mass), np.log10(max_mass), 15+1),\n",
    "#                     histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "\n",
    "#ax10[1].grid(True)\n",
    "#ax10[1].set_xscale('log')\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60485025-2687-4fc1-94a0-3ef2450a98be",
   "metadata": {},
   "source": [
    "## Test: dividing up isochrones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa58684-9889-4ef5-b353-0f8044936eea",
   "metadata": {},
   "source": [
    "How to structure the code?\n",
    "\n",
    "- loop over all lines in file\n",
    "- gather all lines with same age into a list\n",
    "- extract list and make into one array with important data like with Baraffe isochrones\n",
    "- return a list of arrays for every isochrone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4112df8f-48f2-4f09-a177-636e9c708cf6",
   "metadata": {},
   "source": [
    "test_iso_sep, test_iso_ages = separate_isochrones('Baraffe', metallicity='0.00', survey='2mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838a52d6-c851-4f56-af2a-3f820213c972",
   "metadata": {},
   "source": [
    "print(test_iso_sep[7])\n",
    "print(len(test_iso_sep))\n",
    "#print(test_iso_sep[0].shape)\n",
    "#print(test_iso_sep[0][:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be958902-5769-43ac-84c1-41619b5810b2",
   "metadata": {},
   "source": [
    "test_iso_sep_Baraffe = separate_isochrones('Baraffe', metallicity='0.00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "7c90db46-976d-4b38-8aa8-c408143eddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(test_iso_sep_Baraffe))\n",
    "#print(test_iso_sep_Baraffe[-1].shape)\n",
    "#print(test_iso_sep_Baraffe[0][:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14c502-8805-4510-9ec2-5c018804fa60",
   "metadata": {},
   "source": [
    "### Testing extinction analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac4029-2a41-4b98-b947-6035c3a293fc",
   "metadata": {},
   "source": [
    "from astroquery.vizier import Vizier\n",
    "\n",
    "catalog = 'J/A+A/664/A175/table4'\n",
    "columns = ['Plx', 'e_Plx', 'Gmag', 'BPmag', 'RPmag']\n",
    "Vizier.ROW_LIMIT = -1\n",
    "catalogue = Vizier.get_catalogs(catalog='J/A+A/664/A175/table4')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e5fe24-74d0-435d-980f-896ceb844f74",
   "metadata": {},
   "source": [
    "cluster_table = QTable([catalogue['GaiaEDR3'], catalogue['Plx'], catalogue['e_Plx'], catalogue['Gmag'], \n",
    "                        catalogue['BPmag'], catalogue['RPmag'], catalogue['Cluster'], catalogue['_RA.icrs'], \n",
    "                        catalogue['_DE.icrs']], \n",
    "                        names = ['GaiaID', 'Parallax', 'Parallax_error', 'M_apparent', 'G_bp', 'G_rp', \n",
    "                               'Cluster_number', 'RA_ICRS', 'DE_ICRS'])\n",
    "\n",
    "cluster_table['bp_rp'] = cluster_table['G_bp'] - cluster_table['G_rp'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca417d-037d-4f01-afbb-35163eb202dc",
   "metadata": {},
   "source": [
    "clusters_sep, clusters_names = cluster_list(cluster_table, 1, 'gaia')\n",
    "#print(len(clusters_sep))\n",
    "\n",
    "lupus_data = clusters_sep[603]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013805c7-cf2a-41f3-8af8-3ba255988851",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "test_log_counts, test_log_edges, test_masses, test_ages = final_IMFs(cluster_data=[lupus_data], cluster_names=['Lupus'], model='Baraffe', \n",
    "                                                                     metallicity='0.00', bin_width=0.2, age_fit_plot=False, \n",
    "                                                                     chi_plot=True, save_chi_plot=False, plot_hists=True, save_plot_hists=False) \n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e6d9a-4b15-423d-b805-c5e097d6b429",
   "metadata": {},
   "source": [
    "print(test_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1627d-6295-49c6-bb22-a5b992c998d4",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "bin_widths_test, all_cluster_params_test, kroupa_diff_test, counter = IMF_slopes(test_log_edges, test_log_counts, \n",
    "                                                                         test_masses, model='MIST', intervals='Kroupa', \n",
    "                                                                         plot=False)\n",
    "\n",
    "print(kroupa_diff_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94de5ad-c68d-43c3-bfe6-8a6c27554e98",
   "metadata": {},
   "source": [
    "tmass_cluster_data = QTable.read('Filtered_tmass_cluster_data.csv', format='csv', delimiter=',')\n",
    "\n",
    "%%time\n",
    "\n",
    "tmass_sorted_data, cluster_data_short = sorting_2mass_data(tmass_cluster_data)\n",
    "\n",
    "tmass_clusters_sep, cluster_names = cluster_list(tmass_sorted_data, 1, '2mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad933bb-c968-4ea0-802e-baeaa0c42789",
   "metadata": {},
   "source": [
    "un_arr, counts = np.unique(tmass_cluster_data['tmass_oid'], return_counts=True)\n",
    "\n",
    "#print(len(tmass_cluster_data))\n",
    "#print(len(un_arr))\n",
    "#print(len(counts))\n",
    "\n",
    "duplicates_mask = counts>1\n",
    "duplicates = un_arr[duplicates_mask]\n",
    "\n",
    "\n",
    "\n",
    "#print(len(duplicates))\n",
    "#print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb5abc-cd05-4a36-ac63-b54e3c185b6e",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "tmass_sep_data, cluster_data_short = sorting_2mass_data(tmass_cluster_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096d737-6781-44c3-bc9a-b24faef384b3",
   "metadata": {},
   "source": [
    "print(tmass_sep_data.columns)\n",
    "print()\n",
    "print(cluster_data_short.columns)\n",
    "print()\n",
    "\n",
    "#print(tmass_sep_data['GaiaID'])\n",
    "#print(cluster_data_short['GaiaID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047f72e-40a4-410d-a464-d36b9b0a0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_intersection = np.intersect(cluster_table, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0818f1e-7f3b-4453-8318-7e27b4f2bea9",
   "metadata": {},
   "source": [
    "#tmass_sep_data = tmass_sep_data[tmass_sep_data['Cluster_number'].argsort()]\n",
    "\n",
    "tmass_clusters_sep, cluster_names = cluster_list(tmass_sorted_data, 1, '2mass')\n",
    "\n",
    "lupus_tmass_data = tmass_clusters_sep[603]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e1cf6-16f8-4abc-ac01-edac172c26c5",
   "metadata": {},
   "source": [
    "print(len(tmass_clusters_sep))\n",
    "print(len(cluster_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89021eb2-02c6-46b9-bc41-79808f03db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def extinction_ratio(x, Rv):\n",
    "    \n",
    "#    if (0.3<=np.min(x))&(np.max(x)<1.1):\n",
    "#        a = 0.574*x**1.61\n",
    "#        b = -0.527*x**1.61\n",
    "        \n",
    "#        return a + b/Rv\n",
    "        \n",
    "#    elif (1.1<=np.min(x))&(np.max(x)<=3.3):\n",
    "#        y = x - 1.82\n",
    "#        a = 1 + 0.17699*y - 0.50447*y**2 - 0.02427*y**3 + 0.72085*y**4 \\\n",
    "#            + 0.01979*y**5 - 0.77530*y**6 + 0.32999*y**7\n",
    "#        b = 1.41338*y + 2.28305*y**2 + 1.07233*y**3 - 5.38434*y**4 \\\n",
    "#            - 0.62251*y**5 + 5.30260*y**6 - 2.09002*y**7\n",
    "        \n",
    "#        return a + b/Rv\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5374b276-d763-4e94-bd32-583320fd72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#J_wavelength = np.linspace(1.1, 1.4, 1000) # micro meters\n",
    "#J_mid = 1.25 # micro meters\n",
    "#H_wavelength = np.linspace(1.5, 1.8, 1000) # micro meters\n",
    "#H_mid = \n",
    "#K_wavelength = np.linspace(2.0, 2.4, 1000) # micro meters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93328c-1c98-4e3f-9c7b-371f1fb75363",
   "metadata": {},
   "source": [
    "test_iso_sep, test_iso_ages = separate_isochrones('Baraffe', metallicity='0.00', survey='2mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98673274-4e9f-4ad2-9f67-d28cf1d14c92",
   "metadata": {},
   "source": [
    "# Best fitting isochrone for Lupus\n",
    "iso_j_h = test_iso_sep[7][:, 2] - test_iso_sep[7][:, 3]\n",
    "iso_h_k = test_iso_sep[7][:, 3] - test_iso_sep[7][:, 4]\n",
    "\n",
    "iso_hk_mask = (0.18<=iso_h_k)&(iso_h_k<=0.28)\n",
    "\n",
    "iso_hk = iso_h_k[iso_hk_mask]\n",
    "iso_jh = iso_j_h[iso_hk_mask]\n",
    "\n",
    "k_fit, m_fit = np.polyfit(iso_hk, iso_jh, deg=1)\n",
    "\n",
    "# Crooked line\n",
    "\n",
    "def iso_line(x, k, m):\n",
    "    #m=1.085\n",
    "    #k=-1.9\n",
    "    return k*x+m\n",
    "\n",
    "x_vals = np.linspace(-1, 2, 1000)\n",
    "y_vals = iso_line(x_vals, k_fit, m_fit)\n",
    "\n",
    "A_J = 0.282\n",
    "A_H = 0.190\n",
    "A_K = 0.114\n",
    "\n",
    "j_h_ext = A_J - A_H\n",
    "h_k_ext = A_H - A_K\n",
    "#print(j_h_ext)\n",
    "#print(h_k_ext)\n",
    "\n",
    "len_ext_vector = np.sqrt(j_h_ext**2 + h_k_ext**2)\n",
    "\n",
    "k_vec, m_vec = np.polyfit(np.array([h_k_ext]), np.array([j_h_ext]), deg=1)\n",
    "\n",
    "#x_vec_vals = np.linspace(0.18, 1, 100)\n",
    "\n",
    "#ext_vector_1magn = k_vec*x_vec_vals + m_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ddd84e-6836-432e-b549-cc7507e9dc29",
   "metadata": {},
   "source": [
    "print(tmass_clusters_sep[181].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f5c30-4a28-46e7-8999-3462e3156244",
   "metadata": {},
   "source": [
    "lupus_corrected = extinction(k_fit, m_fit, tmass_clusters_sep[181])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb12a1c-26ae-4d32-93bf-04a7fe76a086",
   "metadata": {},
   "source": [
    "print(len(lupus_corrected))\n",
    "print(len(tmass_clusters_sep[181]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0b500-3940-4429-b3a8-5fc9dec7956b",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "plt.minorticks_on()\n",
    "\n",
    "ax.scatter(lupus_corrected['H-K'], lupus_corrected['J-H'], c='m', s=10, alpha=0.5, \n",
    "           label='Cluster data')\n",
    "\n",
    "#ax.scatter(lupus_tmass_data['H-K'], lupus_tmass_data['J-H'], c='b', s=10, alpha=0.5, \n",
    "#           label='Cluster data')\n",
    "\n",
    "ax.plot(iso_h_k, iso_j_h, color='r', label='Best isochrone', lw=2, marker='*')\n",
    "\n",
    "ax.plot(x_vals, y_vals, color='g', label='Extinction line', lw=2, linestyle='dashed')\n",
    "\n",
    "ax.arrow(0.18, 0.78, h_k_ext, j_h_ext, color='orange', width=0.01, label=r'$A_V$=1 magn')\n",
    "\n",
    "#ax.scatter(exts_lupus['H-K'], exts_lupus['J-H'], c='m', s=20, alpha=0.5, label='Corrected stars')\n",
    "\n",
    "ax.set_xlabel('H - K')\n",
    "ax.set_ylabel('J - H')\n",
    "ax.set_title('Extinction Correction After')\n",
    "\n",
    "ax.grid(True, which='both')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_xlim(-1, 2) # -1, 2\n",
    "ax.set_ylim(-0.5, 2) # -0.5, 2\n",
    "\n",
    "#plt.savefig('Plots/Extinction_correction_demonstration_After.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbac44ef-3ffa-4b7c-bf4e-381b515f1770",
   "metadata": {},
   "source": [
    "#cluster_table\n",
    "#cluster_data_short\n",
    "print(len(lupus_data))\n",
    "print(len(lupus_tmass_data))\n",
    "\n",
    "# Intersections between full vizier table and crossmatch table\n",
    "intersections, intersections_arr1, intersections_arr2 = np.intersect1d(lupus_data['GaiaID'].value, \n",
    "                                                                       lupus_tmass_data['GaiaID'].value, \n",
    "                                                                       return_indices=True)\n",
    "\n",
    "#print(intersections)\n",
    "print(len(intersections_arr1))\n",
    "print(len(intersections_arr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf94501-7a44-4199-8ed9-68c5178c1eb2",
   "metadata": {},
   "source": [
    "lupus_data['Extinction'] = np.zeros((len(lupus_data)))\n",
    "\n",
    "lupus_data['Extinction'][intersections_arr1] = lupus_tmass_data['Extinction']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc1796-9446-458b-919a-ae34b02d4283",
   "metadata": {},
   "source": [
    "print(lupus_data['Extinction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50293566-b16b-4472-996e-eb901db3a3e2",
   "metadata": {},
   "source": [
    "indices = np.linspace(0, len(lupus_data), len(lupus_data), dtype=int)\n",
    "\n",
    "pos_left = np.delete(indices, intersections_arr1)\n",
    "\n",
    "print(len(indices))\n",
    "print(len(intersections_arr1))\n",
    "print(len(pos_left))\n",
    "\n",
    "mean_extinction = np.mean(lupus_tmass_data['Extinction'].value)\n",
    "print(mean_extinction)\n",
    "#print(lupus_data['Extinction'][pos_left])\n",
    "lupus_data['Extinction'][pos_left] = mean_extinction\n",
    "\n",
    "#print(lupus_data['Extinction'][pos_left])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f98a2e-d0d1-45ae-acc0-86e2571f3b45",
   "metadata": {},
   "source": [
    "lupus_data['M_V'] = (lupus_data['M_apparent'].value - 5*np.log10(lupus_data['dist'].value) + 5 - lupus_data['Extinction'].value)*u.mag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908a12f-ba21-4770-bd8b-7c1aa894e13e",
   "metadata": {},
   "source": [
    "#lupus_data['M_V'] = lupus_data['M_V']/u.mag\n",
    "print(lupus_data['M_V'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07643d8-c21a-4cf5-bb60-c8c942bf9f3a",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "new_log_counts, new_log_edges, new_masses, new_ages = \\\n",
    "    final_IMFs(cluster_data=[lupus_data], cluster_names=['Lupus'], model='Baraffe', \n",
    "    metallicity='0.00', bin_width=0.2, age_fit_plot=False, \n",
    "    chi_plot=True, save_chi_plot=False, plot_hists=True, save_plot_hists=False) \n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fa4684-61db-4187-88d8-ca63fff24775",
   "metadata": {},
   "source": [
    "print(new_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a3e7c9-f083-4bb4-a8a3-effd273d391b",
   "metadata": {},
   "source": [
    "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "indexes = [2, 4, 6]\n",
    "\n",
    "\n",
    "print(arr[indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab99f708-e6dc-4eb3-b696-1c35c1a66abd",
   "metadata": {},
   "source": [
    "ext_stars_mask = (lupus_data['Extinction']!=0)&(lupus_data['Extinction']!=mean_extinction)\n",
    "\n",
    "ext_stars = lupus_data[ext_stars_mask]\n",
    "\n",
    "print(len(ext_stars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9232dd-f9b8-4a6b-91b4-4ce03a648f56",
   "metadata": {},
   "source": [
    "new_log_counts, new_log_edges, new_masses, new_ages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb056d7a-234b-423d-8bf9-37de545cdcba",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "bin_widths_test, all_cluster_params_test, kroupa_diff_test, counter = IMF_slopes(new_log_edges, new_log_counts, \n",
    "                                                                         new_masses, model='Baraffe', intervals='Kroupa', \n",
    "                                                                         plot=True)\n",
    "\n",
    "\n",
    "print(all_cluster_params_test)\n",
    "print(kroupa_diff_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe359f91-e6a3-4495-9c65-6c0ebd3d9a03",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956db6e-93ac-4181-89ce-4b6c840406ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ee4c7-b71e-40e4-9f99-607d249c5136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be23c2-5d03-497c-ab37-2a5465c23835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab63bf0-bc55-4e7a-8a32-9a723fbcb7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "142b25c4-b4c3-490c-a2a4-60de651bab60",
   "metadata": {},
   "source": [
    "# Best fitting isochrone for Lupus\n",
    "iso_j_h_new = test_iso_sep[1][:, 2] - test_iso_sep[1][:, 3]\n",
    "iso_h_k_new = test_iso_sep[1][:, 3] - test_iso_sep[1][:, 4]\n",
    "\n",
    "iso_hk_mask = (0.18<=iso_h_k)&(iso_h_k<=0.28)\n",
    "\n",
    "iso_hk_new = iso_h_k_new[iso_hk_mask]\n",
    "iso_jh_new = iso_j_h_new[iso_hk_mask]\n",
    "\n",
    "k_fit_new, m_fit_new = np.polyfit(iso_hk_new, iso_jh_new, deg=1)\n",
    "\n",
    "# Crooked line\n",
    "\n",
    "def iso_line(x, k, m):\n",
    "    #m=1.085\n",
    "    #k=-1.9\n",
    "    return k*x+m\n",
    "\n",
    "x_vals_new = np.linspace(-1, 2, 1000)\n",
    "y_vals_new = iso_line(x_vals, k_fit, m_fit)\n",
    "\n",
    "A_J_new = 0.282\n",
    "A_H_new = 0.190\n",
    "A_K_new = 0.114\n",
    "\n",
    "j_h_ext_new = A_J_new - A_H_new\n",
    "h_k_ext_new = A_H_new - A_K_new\n",
    "#print(j_h_ext)\n",
    "#print(h_k_ext)\n",
    "\n",
    "len_ext_vector_new = np.sqrt(j_h_ext_new**2 + h_k_ext_new**2)\n",
    "\n",
    "k_vec_new, m_vec_new = np.polyfit(np.array([h_k_ext_new]), np.array([j_h_ext_new]), deg=1)\n",
    "\n",
    "#x_vec_vals = np.linspace(0.18, 1, 100)\n",
    "\n",
    "#ext_vector_1magn = k_vec*x_vec_vals + m_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bba4c8-195b-4a5c-a6cf-fffdfc43b5f9",
   "metadata": {},
   "source": [
    "lupus_corrected = extinction(k_fit_new, m_fit_new, k_vec_new, len_ext_vector_new, lupus_tmass_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e963aa-2a54-4d8f-a0f5-aa18461945fd",
   "metadata": {},
   "source": [
    "print(len(lupus_corrected))\n",
    "print(len(tmass_clusters_sep[181]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ef57dc-00e0-4750-9900-76593d674124",
   "metadata": {},
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "plt.minorticks_on()\n",
    "\n",
    "ax1.scatter(lupus_corrected['H-K'], lupus_corrected['J-H'], c='m', s=20, alpha=0.5, \n",
    "           label='Cluster data')\n",
    "\n",
    "ax1.scatter(lupus_tmass_data['H-K'], lupus_tmass_data['J-H'], c='b', s=10, alpha=0.5, \n",
    "           label='Cluster data')\n",
    "\n",
    "ax1.plot(iso_h_k_new, iso_j_h_new, color='r', label='Best isochrone', lw=2, marker='*')\n",
    "\n",
    "ax1.plot(x_vals_new, y_vals_new, color='g', label='Extinction line', lw=2, linestyle='dashed')\n",
    "\n",
    "ax1.arrow(0.18, 0.78, h_k_ext_new, j_h_ext_new, color='orange', width=0.01, label=r'$A_V$=1 magn')\n",
    "\n",
    "#ax1.scatter(exts_lupus['H-K'], exts_lupus['J-H'], c='m', s=20, alpha=0.5, label='Corrected stars')\n",
    "\n",
    "ax1.set_xlabel('H - K')\n",
    "ax1.set_ylabel('J - H')\n",
    "ax1.set_title('Color-Color Diagram Lupus')\n",
    "\n",
    "ax1.grid(True, which='both')\n",
    "ax1.legend()\n",
    "\n",
    "ax1.set_xlim(-1, 2) # -1, 2\n",
    "ax1.set_ylim(-0.5, 2) # -0.5, 2\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b404f-4822-4818-a8c6-c386cb51b0a1",
   "metadata": {},
   "source": [
    "#cluster_table\n",
    "#cluster_data_short\n",
    "print(len(lupus_data))\n",
    "print(len(lupus_tmass_data))\n",
    "\n",
    "# Intersections between full vizier table and crossmatch table\n",
    "intersections, intersections_arr1, intersections_arr2 = np.intersect1d(lupus_data['GaiaID'].value, \n",
    "                                                                       lupus_tmass_data['GaiaID'].value, \n",
    "                                                                       return_indices=True)\n",
    "\n",
    "#print(intersections)\n",
    "print(len(intersections_arr1))\n",
    "print(len(intersections_arr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112cc92f-36b5-4d46-a666-8af212f5e770",
   "metadata": {},
   "source": [
    "lupus_data['Extinction'] = np.zeros((len(lupus_data)))\n",
    "\n",
    "lupus_data['Extinction'][intersections_arr1] = lupus_tmass_data['Extinction']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b485b-a83c-4385-90eb-f93856ee655d",
   "metadata": {},
   "source": [
    "print(lupus_data['Extinction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c9f29-9c37-4379-bd26-c96f974f9c26",
   "metadata": {},
   "source": [
    "indices = np.linspace(0, len(lupus_data), len(lupus_data), dtype=int)\n",
    "\n",
    "pos_left = np.delete(indices, intersections_arr1)\n",
    "\n",
    "print(len(indices))\n",
    "print(len(intersections_arr1))\n",
    "print(len(pos_left))\n",
    "\n",
    "mean_extinction = np.mean(lupus_tmass_data['Extinction'].value)\n",
    "print(mean_extinction)\n",
    "#print(lupus_data['Extinction'][pos_left])\n",
    "lupus_data['Extinction'][pos_left] = mean_extinction\n",
    "\n",
    "#print(lupus_data['Extinction'][pos_left])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd1e03-f47e-4c7b-98ca-a1fc6f7603a3",
   "metadata": {},
   "source": [
    "lupus_data['M_V'] = (lupus_data['M_apparent'].value - 5*np.log10(lupus_data['dist'].value) + 5 - lupus_data['Extinction'].value)*u.mag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc949b-1923-43f8-9bbe-1a782e2ae47e",
   "metadata": {},
   "source": [
    "#lupus_data['M_V'] = lupus_data['M_V']/u.mag\n",
    "print(lupus_data['M_V'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9797469-8a5a-45a0-9c3f-9970541e959b",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "new_log_counts, new_log_edges, new_masses, new_ages = \\\n",
    "    final_IMFs(cluster_data=[lupus_data], cluster_names=['Lupus'], model='Baraffe', \n",
    "    metallicity='0.00', bin_width=0.2, age_fit_plot=False, \n",
    "    chi_plot=True, save_chi_plot=False, plot_hists=True, save_plot_hists=False) \n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62e18f-6792-4a37-bc78-d66fdc4f385f",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "bin_widths_test, all_cluster_params_test, kroupa_diff_test, counter = IMF_slopes(new_log_edges, new_log_counts, \n",
    "                                                                         new_masses, model='Baraffe', intervals='Kroupa', \n",
    "                                                                         plot=True)\n",
    "\n",
    "\n",
    "print(all_cluster_params_test)\n",
    "print(kroupa_diff_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19601af4-6368-4285-8c7d-2447f6bf5017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
