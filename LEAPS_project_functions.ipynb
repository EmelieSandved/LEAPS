{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36d7fd1-5829-4f4f-9535-874ac61639aa",
   "metadata": {},
   "source": [
    "This notebook contains the functions I created for the analysis in my LEAPS project at ESA. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f6e771-d8ae-45bc-ab66-363d1d71b527",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b1737f89-68af-4fea-8dd9-a5a71147028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as scopt\n",
    "from scipy import stats\n",
    "import sympy as sp\n",
    "\n",
    "\n",
    "# Astropy imports\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "from astropy.table import QTable\n",
    "from astropy.coordinates import Distance\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import votable\n",
    "\n",
    "# Special import\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4911244e-b3b4-4ae5-85f9-9295571544d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'xtick.labelsize':15, 'ytick.labelsize':15, 'axes.titlesize':18, \n",
    "                     'axes.grid':True, 'axes.labelsize':14, 'legend.fontsize':14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e75be-901c-48d2-876b-259bdf6d20b8",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0a652-705b-4f9e-b7f8-2476b4100e42",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb5a4f-1447-4dc6-b7bd-da857861012d",
   "metadata": {},
   "source": [
    "The distance modulus is calculated through \\textit{distance.distmod} and it is mathematically given by\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mu = 5 \\log_{10} d - 5 = m - M \\iff M = m - \\mu.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e94c6da-a3d1-47b2-8da9-081b1b4de919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_import(file_name):\n",
    "    \"\"\"\n",
    "    Imports the cluster data file and adds a distance column, an absolute magnitude column\n",
    "    and a G_BP-G_RP column\n",
    "    ---------------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    \n",
    "    file_name: str\n",
    "        The name of the data file that contains the data\n",
    "        \n",
    "    ---------------------------------------------------------------------------------------\n",
    "    Output:\n",
    "    \n",
    "    data: astropy QTable\n",
    "        Returns an astropy QTable with all the data including the units\n",
    "    \"\"\"\n",
    "    \n",
    "    data = QTable.read(f'Data/Clusters/{file_name}.txt', \n",
    "                         names=['GaiaID', 'gal_long', 'gal_lat', 'parallax', 'e_parallax', 'RA_pm', \n",
    "                                'e_RA_pm', 'DE_pm', 'e_DE_pm', 'M_apparent', 'G_BP', 'G_RP', \n",
    "                                'Flag', 'Cluster_id', 'RA_icrs', 'DE_icrs'], \n",
    "                         units = [u.m/u.m, u.deg, u.deg, u.mas, u.mas, u.mas/u.yr, u.mas/u.yr, \n",
    "                                  u.mas/u.yr, u.mas/u.yr, u.mag, u.mag, u.mag, u.m/u.m, u.m/u.m, \n",
    "                                  u.deg, u.deg], delimiter=' ', format = 'ascii')\n",
    "    \n",
    "    # Adds a distance column and converts the parallaxes to distance in pc\n",
    "    data['dist'] = Distance(parallax=data['parallax'])\n",
    "\n",
    "\n",
    "    # Calculates and adds an absolute magnitude column calculated from the photometric mean magnitude \n",
    "    # and the distance modulus, described above\n",
    "    data['M_V'] = data['M_apparent'] - data['dist'].distmod\n",
    "\n",
    "    # Calculating and adding G_bp - G_rp\n",
    "    data['bp_rp'] = data['G_BP'] - data['G_RP']\n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887724c4-400c-4b0e-b2fb-d7d74e2006a0",
   "metadata": {},
   "source": [
    "## Importing and separating isochrones from one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f505e84-649e-4455-87b6-d34c99fe4e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def separate_isochrones(model, metallicity, survey):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model: str\n",
    "        Name of isochrone model\n",
    "        \n",
    "    metallicity: str\n",
    "        String with metallicity value\n",
    "        \n",
    "    survey: str\n",
    "        Which survey was used, which affects the magnitude units\n",
    "    \"\"\"\n",
    "    all_iso = [] # List to gather all data for all isochrones in\n",
    "    models = ['Baraffe', 'MIST', 'Marigo'] # List of models\n",
    "    # List of filenames\n",
    "    file_names = [f'Baraffe_{survey}.txt', \n",
    "                  f'MIST_v1.2_feh_{metallicity}_vvcrit0.00.txt']\n",
    "    \n",
    "    list_position = models.index(model) # Finding list position for model\n",
    "    file_name = file_names[list_position] # Extracting filename\n",
    "    \n",
    "    # Opens file to read content\n",
    "    with open(f'Data/Isochrones/{model}/{file_name}', \"r\") as iso_file: \n",
    "        age = [] # List to put isochrone data divided by age (final output of function)\n",
    "        lines = [] # List to put all the line information into\n",
    "        \n",
    "        # Loops over every line and stores the data for all lines (all isochrones) in a list\n",
    "        for line in iso_file: # loop through each line\n",
    "            if line.startswith('#'): # do not add lines that don't contain any data\n",
    "                continue\n",
    "            elif line.startswith('!'):\n",
    "                continue\n",
    "            elif line.startswith(' !'):\n",
    "                continue\n",
    "            elif len(line)<2:\n",
    "                continue\n",
    "            else: # If it contains data, add it to list\n",
    "                val = line.split() # split each line and store them in a list\n",
    "                lines.append(val) # Store list of line values in another list\n",
    "        \n",
    "        \n",
    "        if model=='Baraffe':\n",
    "            iso_data_list = [] # List to fill with isochrone data points\n",
    "            iso_ages_list= []\n",
    "            # Looping over all lines and adding interesting ones to data lists\n",
    "            for i, l_vals in enumerate(lines, start=1): # l_vals = list of line/column values\n",
    "                #print(l_vals)\n",
    "                # if equal to 1 means new age\n",
    "                \n",
    "                if len(l_vals)==1: # means old list is finished\n",
    "                    if iso_data_list != []:\n",
    "                        # Want to add finished list to list with all isochrones\n",
    "                        # converting to array with shape:(n_points, parameters)\n",
    "                        iso_data_array = np.array(iso_data_list) \n",
    "                    \n",
    "                        # adding isochrone's data to isochrone list\n",
    "                        all_iso.append(iso_data_array.astype(float))\n",
    "            \n",
    "                    # making new list\n",
    "                    iso_data_list = []\n",
    "                    iso_ages_list.append(l_vals)\n",
    "                    \n",
    "            \n",
    "                else: # if the age is the same \n",
    "                    iso_data_list.append(l_vals) # filling old list\n",
    "            \n",
    "                if i==len(lines): # appends the last isochrone\n",
    "                    iso_data_list.append(l_vals)\n",
    "                    # converting to array with shape:(n_points, parameters)\n",
    "                    iso_data_array = np.array(iso_data_list)\n",
    "                    # adding isochrone's data to isochrone list\n",
    "                    all_iso.append(iso_data_array.astype(float)) \n",
    "            \n",
    "            iso_ages_array = np.array(iso_ages_list, dtype=float)\n",
    "            \n",
    "              \n",
    "        if model=='MIST':\n",
    "            iso_data_list = [] # List to fill with isichrone data points\n",
    "            iso_ages_list = []\n",
    "            iso_age = lines[0][1]\n",
    "            iso_ages_list.append(iso_age) # setting first iso_age\n",
    "            iso_data_list.append(lines[0]) # Adding first data line to list\n",
    "            # Looping over all lines and adding interesting ones to data lists\n",
    "            for i, l_vals in enumerate(lines, start=1): # l_vals = list of line/column values\n",
    "                \n",
    "                line_age = l_vals[1]\n",
    "                \n",
    "                # checking if isochrone age is same as before, is same\n",
    "                # If True, then this means that the old list is finished\n",
    "                if line_age!=iso_age: \n",
    "                    # Want to add finished list to list with all isochrones\n",
    "                    # converting to array with shape:(n_points, parameters)\n",
    "                    iso_data_array = np.array(iso_data_list) \n",
    "                    # adding isochrone's data to isochrone list\n",
    "                    all_iso.append(iso_data_array.astype(float)) \n",
    "            \n",
    "                    # Starting new list with new age\n",
    "                    iso_age = l_vals[1] # Otherwise replacing it with the new value\n",
    "                    iso_ages_list.append(iso_age)\n",
    "                    \n",
    "                    # making new list\n",
    "                    iso_data_list = []\n",
    "                    iso_data_list.append(l_vals)\n",
    "            \n",
    "                else: # if the age is the same   \n",
    "                    iso_data_list.append(l_vals) # filling old list\n",
    "            \n",
    "                if i==len(lines): # appends the last isochrone\n",
    "                    iso_data_list.append(l_vals)\n",
    "                    # converting to array with shape:(n_points, parameters)\n",
    "                    iso_data_array = np.array(iso_data_list) \n",
    "                    # adding isochrone's data to isochrone list\n",
    "                    all_iso.append(iso_data_array.astype(float)) \n",
    "                    \n",
    "                iso_ages_arr = np.array(iso_ages_list, dtype=float) # in MIST unit\n",
    "                iso_ages_array = 10**(iso_ages_arr)*10**(-9) # Converts to Gyr\n",
    "                \n",
    "    iso_file.close()   \n",
    "    \n",
    "    # Only keeping the relevant information from the isochrones\n",
    "    for i, iso in enumerate(all_iso):\n",
    "        \n",
    "        if survey=='gaia':\n",
    "            new_iso_array = np.empty((len(iso), 4)) # Contains: time, mass, M_V, bp_rp\n",
    "            \n",
    "            if model=='Baraffe':\n",
    "                # Adding the age to the new array\n",
    "                new_iso_array[:, 0] = iso_ages_array[i]\n",
    "                new_iso_array[:, 1] = iso[:, 0] # Adding the mass to the new array \n",
    "                new_iso_array[:, 2] = iso[:, 22] # Adding M_V\n",
    "                    \n",
    "                bp = iso[:, 23]\n",
    "                rp = iso[:, 24]\n",
    "                new_iso_array[:, 3] = bp-rp # Adding bp_rp\n",
    "                \n",
    "            elif model=='MIST':\n",
    "                # Adding the age to the new array and converting to Gyr\n",
    "                new_iso_array[:, 0] = 10**(iso[:, 1])*10**(-9) \n",
    "                new_iso_array[:, 1] = iso[:, 3] # Adding the mass to the new array (initial mass vs star mass???)\n",
    "                new_iso_array[:, 2] = iso[:, 30] # Adding M_V\n",
    "                \n",
    "                bp = iso[:, 31]\n",
    "                rp = iso[:, 32]\n",
    "                new_iso_array[:, 3] = bp-rp # Adding bp_rp to array\n",
    "                #new_iso_array = new_iso_array[new_iso_array[:, 3].argsort()] # sort after colour\n",
    "                magnitude_mask = 0<new_iso_array[:, 2]\n",
    "                new_iso_array = new_iso_array[magnitude_mask]\n",
    "                \n",
    "                \n",
    "        elif survey=='2mass':\n",
    "            new_iso_array = np.empty((len(iso), 5)) # Contains: time, mass, J, H, K\n",
    "            \n",
    "            if model=='Baraffe':\n",
    "                # Adding the age to the new array\n",
    "                new_iso_array[:, 0] = iso_ages_array[i]\n",
    "                new_iso_array[:, 1] = iso[:, 0] # Adding the mass to the new array \n",
    "                new_iso_array[:, 2] = iso[:, 6] # Adding J\n",
    "                new_iso_array[:, 3] = iso[:, 7] # Adding H\n",
    "                new_iso_array[:, 4] = iso[:, 8] # Adding K\n",
    "                \n",
    "            elif model=='MIST':\n",
    "                # Adding the age to the new array and converting to Gyr\n",
    "                new_iso_array[:, 0] = 10**(iso[:, 1])*10**(-9) \n",
    "                new_iso_array[:, 1] = iso[:, 3] # Adding the mass to the new array (initial mass vs star mass???)\n",
    "                new_iso_array[:, 2] = iso[:, 14] # Adding J\n",
    "                new_iso_array[:, 3] = iso[:, 15] # Adding H\n",
    "                new_iso_array[:, 4] = iso[:, 16] # Adding K\n",
    "                \n",
    "                #magnitude_mask = 0<new_iso_array[:, 2]\n",
    "                #new_iso_array = new_iso_array[magnitude_mask]\n",
    "                \n",
    "        all_iso[i] = new_iso_array\n",
    "    \n",
    "    return all_iso, iso_ages_array\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dddee4d-8726-438c-a7c8-11b922fa2397",
   "metadata": {},
   "source": [
    "## Importing the isochrone data and extracting fitting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853cee24-1d36-43cc-852a-75736c5b8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isochrone_params(isos_data, model, survey):\n",
    "    \"\"\"\n",
    "    Imports the isochrone data file\n",
    "    ---------------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    \n",
    "    file_names: lst\n",
    "        List of the file names of the data files that contains each isochrone's data\n",
    "        \n",
    "    model: str or list\n",
    "        The name of the model isochrone to use\n",
    "        \n",
    "    ---------------------------------------------------------------------------------------\n",
    "    Output:\n",
    "    \n",
    "    data: array\n",
    "        Returns an array with all the isochrone data for plotting with [G, G_BP-G_RP]\n",
    "    \"\"\"\n",
    "    # Useful lists\n",
    "    #models = ['Baraffe'] # List of model names\n",
    "    \n",
    "    #column_names = [['Mass', 'Teff', 'Luminosity', 'g', 'Radius', 'Li', 'F33', 'F33B', 'F41', 'F45B', \n",
    "    #                 'F47', 'F51', 'FHa', 'F57', 'F63B', 'F67', 'F75', 'F78', 'F82', 'F82B', 'F89', \n",
    "    #                 'G_RSV', 'M_V', 'G_BP', 'G_RP']] # List of column names for each model\n",
    "    \n",
    "    #units = [[u.Msun, u.K, u.Lsun, u.m/u.m, u.Rsun, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, \n",
    "    #          u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, u.m/u.m, \n",
    "    #          u.m/u.m, u.m/u.m, u.m/u.m, u.mag, u.mag, u.mag]] # List of units for the columns for each model\n",
    "    \n",
    "    #Useful parameter for the loop\n",
    "    #i = models.index(model)\n",
    "    \n",
    "    #all_iso_data = []\n",
    "    \n",
    "    fit_params = np.empty((6, len(isos_data)))\n",
    "    \n",
    "    for j, isochrone in enumerate(isos_data):\n",
    "        \n",
    "        #iso_data = QTable.read(f'Data/Isochrones/{model}/Isochrone_{model}_{isochrone}.txt', \n",
    "        #                       names=column_names[i], units = units[i], delimiter=' ', \n",
    "        #                       format = 'ascii')\n",
    "        \n",
    "        #iso_data['bp_rp'] = iso_data['G_BP'] - iso_data['G_RP'] # Calculating colour\n",
    "        \n",
    "        #data = np.empty((len(iso_data), 3))\n",
    "        #data[:, 0] = iso_data['M_V']\n",
    "        #data[:, 1] = iso_data['bp_rp']\n",
    "        #data[:, 2] = iso_data['Mass']\n",
    "        \n",
    "        #all_iso_data.append(data)\n",
    "        \n",
    "        if survey=='gaia':\n",
    "        \n",
    "            magn_mask = (isochrone[:, 2]<16) & (isochrone[:, 2]>0)# Magnitude mask\n",
    "        \n",
    "            iso_x = isochrone[:, 3][magn_mask] # Colour\n",
    "            iso_y = isochrone[:, 2][magn_mask] # Magnitude\n",
    "        \n",
    "            k5, k4, k3, k2, k1, c = np.polyfit(iso_x, iso_y, 5)\n",
    "            \n",
    "            \n",
    "        elif survey=='2mass':\n",
    "        \n",
    "            magn_mask = (isochrone[:, 2]<16) & (isochrone[:, 2]>0)# J mask\n",
    "        \n",
    "            iso_x = isochrone[:, 2][magn_mask] - isochrone[:, 4][magn_mask] # Colour, J-K\n",
    "            iso_y = isochrone[:, 2][magn_mask] # J\n",
    "        \n",
    "            k5, k4, k3, k2, k1, c = np.polyfit(iso_x, iso_y, 5)\n",
    "        \n",
    "        \n",
    "        fit_params[0, j] = k5\n",
    "        fit_params[1, j] = k4 \n",
    "        fit_params[2, j] = k3 \n",
    "        fit_params[3, j] = k2 \n",
    "        fit_params[4, j] = k1 \n",
    "        fit_params[5, j] = c\n",
    "    \n",
    "    return fit_params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f0c3c-5067-4a54-b1a8-5c7cb270185e",
   "metadata": {},
   "source": [
    "## Plotting isochrones with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcd87c0-5644-4912-80ed-5cb7717ddd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_iso_and_data(all_data, all_iso_data, cluster_names, model, survey, data_alpha=0.5,\n",
    "                          CMD_or_mass='CMD'): # n_plots=1\n",
    "    \"\"\"\n",
    "    Plots the data and/or isochrones\n",
    "    ----------------------------------\n",
    "    Parameters:\n",
    "    \n",
    "    all_data: list of arrays\n",
    "        List of data for different clusters\n",
    "        \n",
    "    all_iso_data: list of arrays\n",
    "        List of data from one or several different isochrones\n",
    "        \n",
    "    cluster_names: list\n",
    "        List or string with names of the used clusters\n",
    "        \n",
    "    n_plots: int\n",
    "        The number of plots to plot\n",
    "        \n",
    "    Output:\n",
    "    --------\n",
    "    Plot\n",
    "    \"\"\"\n",
    "    # 16 different colours to plot\n",
    "    colours = ['b', 'r', 'deepskyblue', 'firebrick', 'cyan', 'crimson', 'teal', 'peru', 'orange',  \n",
    "               'blueviolet', 'silver', 'purple', 'dimgray', 'magenta', 'g', 'lawngreen']\n",
    "    \n",
    "    rev_colours = colours[::-1]\n",
    "    \n",
    "    if all_data==None: # Only plotting isochrones\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        if survey=='gaia':\n",
    "            if CMD_or_mass == 'CMD':\n",
    "                for i, iso in enumerate(all_iso_data):\n",
    "                        ax.plot(iso[:, 3], iso[:, 2], color=colours[i], label=f't = {iso[i, 0]:.1e} Gyr')\n",
    "            \n",
    "                ax.set_xlabel(r'G$_{BP}$ - G$_{RP}$ [mag]')\n",
    "                ax.set_ylabel(r'M$_{V}$ [mag]')\n",
    "                ax.set_title(f'CMD for {len(all_iso_data)} {model} isochrones')\n",
    "                ax.invert_yaxis()\n",
    "            \n",
    "            elif CMD_or_mass == 'mass':\n",
    "                for i, iso in enumerate(all_iso):\n",
    "                    ax.plot(iso[:, 3], iso[:, 1], color=colours[i], label=f't = {iso[i, 0]:.1e} Gyr')\n",
    "            \n",
    "                ax.set_xlabel(r'G$_{BP}$ - G$_{RP}$ [mag]')\n",
    "                ax.set_ylabel(r'Mass [M$_{\\odot}$]')\n",
    "                ax.set_title(f'Mass vs colour for {len(all_iso_data)} {model} isochrones')\n",
    "                \n",
    "        if survey=='2mass':\n",
    "            if CMD_or_mass == 'CMD':\n",
    "                for i, iso in enumerate(all_iso_data):\n",
    "                    iso_colour = iso[:, 2] - iso[:, 4]\n",
    "                    ax.plot(iso_colour, iso[:, 2], color=colours[i], label=f't = {iso[i, 0]:.1e} Gyr')\n",
    "            \n",
    "                ax.set_xlabel(r'J - K [mag]')\n",
    "                ax.set_ylabel(r'J [mag]')\n",
    "                ax.set_title(f'CMD for {len(all_iso_data)} {model} isochrones')\n",
    "                ax.invert_yaxis()\n",
    "            \n",
    "            elif CMD_or_mass == 'mass':\n",
    "                for i, iso in enumerate(all_iso):\n",
    "                    iso_colour = iso[:, 2] - iso[:, 4]\n",
    "                    ax.plot(iso_colour, iso[:, 1], color=colours[i], label=f't = {iso[i, 0]:.1e} Gyr')\n",
    "            \n",
    "                ax.set_xlabel(r'J - K [mag]')\n",
    "                ax.set_ylabel(r'Mass [M$_{\\odot}$]')\n",
    "                ax.set_title(f'Mass vs colour for {len(all_iso_data)} {model} isochrones')\n",
    "            \n",
    "        ax.legend()\n",
    "            \n",
    "        ax.grid(True)\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "    elif all_iso_data==None: # Only plotting data\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        for i, data in enumerate(all_data):\n",
    "            ax.scatter(data['bp_rp'].value, data['M_V'].value, c=rev_colours[i], \n",
    "                       alpha=data_alpha, s=10, label=f'Cluster {cluster_names[i]}')\n",
    "        \n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel(r'G$_{BP}$ - G$_{RP}$ [mag]')\n",
    "        ax.set_ylabel(r'M$_{V}$ [mag]')\n",
    "        ax.set_title(f'Cluster data for {len(all_data)} clusters')\n",
    "        ax.legend()\n",
    "            \n",
    "        ax.grid(True)\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    elif (all_data!=None) and (all_iso_data!=None): # Plotting both\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "            \n",
    "        # Plotting data\n",
    "        for i, data in enumerate(all_data):\n",
    "            ax.scatter(data['bp_rp'].value, data['M_V'].value, c=rev_colours[i], \n",
    "                   alpha=data_alpha, s=10, label=f'Cluster {cluster_names[i]}')\n",
    "            \n",
    "        # Plotting isochrones\n",
    "        for i, iso in enumerate(all_iso_data):\n",
    "            ax.plot(iso[:, 3], iso[:, 2], color=colours[i], label=f't = {iso[i, 0]} Gyr')\n",
    "                \n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel(r'G$_{BP}$ - G$_{RP}$ [mag]')\n",
    "        ax.set_ylabel(r'M$_{V}$ [mag]')\n",
    "        ax.set_title(f'Cluster data for {len(all_data)} clusters and isochrones')\n",
    "        ax.legend()\n",
    "            \n",
    "        ax.grid(True)\n",
    "            \n",
    "        plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8cfe7-8243-40d2-b6b8-d251e06e3cb3",
   "metadata": {},
   "source": [
    "## Fitting function for isochrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a2b0c3-1e25-4c9c-bc5a-3b4d67755a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_fcn(x, args):\n",
    "    k5, k4, k3, k2, k1, c = args\n",
    "    return k5*x**5 + k4*x**4 + k3*x**3 + k2*x**2 + k1*x + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6470ed-06b5-4f69-bda9-82560bced129",
   "metadata": {},
   "source": [
    "## Chi-square fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c7e877-fb87-4cc7-8dce-cf530551cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_fitting(model_fcn, data, iso_params, isochrones, survey):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_fcn: fcn\n",
    "        The model function for the isochrone fit\n",
    "        \n",
    "    data: astropy QTable\n",
    "        The cluster data\n",
    "        \n",
    "    iso_params: array\n",
    "        The fitted isochrone parameters\n",
    "        \n",
    "    isochrones: array\n",
    "        Isochrone data\n",
    "    ----------------------------------------------\n",
    "    Output:\n",
    "    -------\n",
    "    chisq_value: array\n",
    "        The sum of all differences for each star for every isochrone shape:(len(isochrones))\n",
    "    \"\"\"\n",
    "    n_isochrones = np.shape(iso_params)[1]\n",
    "    #diff = np.empty((len(data), n_isochrones)) # shape (data_points,isochrones)\n",
    "    chisq_value = np.empty((n_isochrones))\n",
    "    for i in range(n_isochrones):\n",
    "        if survey=='gaia':\n",
    "            min_col = np.min(isochrones[i][:, 3])\n",
    "            max_col = np.max(isochrones[i][:, 3])\n",
    "            colour_mask = (min_col<=data['bp_rp'].value)&(data['bp_rp'].value<=max_col)\n",
    "            data = data[colour_mask]\n",
    "            #magnitude_mask = (0<=data['M_V'].value)&(data['M_V'].value<=16)\n",
    "            #data = data[magnitude_mask]\n",
    "        \n",
    "            sigma=np.ones((len(data)))\n",
    "        \n",
    "            params = iso_params[:, i]\n",
    "        \n",
    "            # Absolute magnitudes for data according to isochrone\n",
    "            model_data = model_fcn(data['bp_rp'].value, params)\n",
    "        \n",
    "            diff = ((data['M_V'].value - model_data)**2 /sigma) # diff[:, i]\n",
    "            chisq_value[i] = np.nansum(diff, axis=0)\n",
    "            \n",
    "            \n",
    "        if survey=='2mass':\n",
    "            # J - K\n",
    "            iso_col = isochrones[i][:, 2] - isochrones[i][:, 4]\n",
    "            min_col = np.min(iso_col)\n",
    "            max_col = np.max(iso_col)\n",
    "            colour_mask = (min_col<=data['J-K'].value)&(data['J-K'].value<=max_col)\n",
    "            data = data[colour_mask]\n",
    "            #magnitude_mask = (0<=data['M_V'].value)&(data['M_V'].value<=16)\n",
    "            #data = data[magnitude_mask]\n",
    "        \n",
    "            sigma=np.ones((len(data)))\n",
    "        \n",
    "            params = iso_params[:, i]\n",
    "        \n",
    "            # Absolute magnitudes for data according to isochrone\n",
    "            model_data = model_fcn(data['J-K'].value, params)\n",
    "        \n",
    "            diff = ((data['J'].value - model_data)**2 /sigma) # diff[:, i]\n",
    "            chisq_value[i] = np.nansum(diff, axis=0)\n",
    "    \n",
    "    return chisq_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f241f5-52d6-4834-8a74-a6a1d478ec90",
   "metadata": {},
   "source": [
    "## Getting IMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da181951-b0ad-48aa-a89a-9f083cdfc510",
   "metadata": {},
   "source": [
    "Maybe make possible for many clusters at the same time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dfc60ab1-4cc5-4db3-aa9d-e3f202034dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMF(colour_data, model_data, cluster_name, model_name, nbins, time, check=True, \n",
    "        save_check=False, plot=True, save_plot=True):\n",
    "    \"\"\"\n",
    "    Interpolates the stellar masses from isochrone colours\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    colour_data: array\n",
    "        Colour from cluster stars\n",
    "        \n",
    "    model_data: array\n",
    "        Isochrone data containing time, mass, M_V, bp_rp\n",
    "        \n",
    "    cluster_name: str\n",
    "        name of cluster for plots\n",
    "        \n",
    "    model_name: str\n",
    "        Name of ispchrone models\n",
    "        \n",
    "    nbins:\n",
    "    \n",
    "    time:\n",
    "        \n",
    "    check: bool\n",
    "        True if you want to check the interpolation\n",
    "        \n",
    "    save_check: bool\n",
    "        True if the plot of the interpolation is supposed to be saved\n",
    "        \n",
    "    plot: bool\n",
    "        True if the histograms should be plotted\n",
    "        \n",
    "    save_plot: bool\n",
    "        True if the plots of the histograms should be saved\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sorting all columns in data according to the colour\n",
    "    sorted_model_data = model_data[model_data[:, 3].argsort()]\n",
    "    \n",
    "    stellar_masses = np.array(np.interp(colour_data, sorted_model_data[:, 3], sorted_model_data[:, 1]))\n",
    "    \n",
    "    if check:\n",
    "        fig1, ax1 = plt.subplots(figsize=(5, 4))\n",
    "    \n",
    "        ax1.plot(sorted_model_data[:, 3], sorted_model_data[:, 1], color='b', label='Model data')\n",
    "        ax1.scatter(colour_data, stellar_masses, c='r', s=5, label='Interpolation', zorder=20)\n",
    "        \n",
    "        ax1.set_xlabel(r'G$_{BP}$ - G$_{RP}$ [mag]')\n",
    "        ax1.set_ylabel(r'Mass [M$_{\\odot}$]')\n",
    "        ax1.set_title(f'Interpolation check, {model_name} model, age = {time:.1e} Gyr')\n",
    "        \n",
    "        ax1.legend()\n",
    "        \n",
    "        if save_check:\n",
    "            plt.savefig(f'Plots/Interpolation_check_{cluster_name}_{model_name}_model.png', bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    if plot:\n",
    "        # Plotting histogram in normal scale\n",
    "        min_mass = np.min(stellar_masses)\n",
    "        max_mass = np.max(stellar_masses)\n",
    "        \n",
    "        fig2, ax2 = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        ax2[0].hist(stellar_masses, bins=nbins,\n",
    "                     histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "\n",
    "        ax2[0].set_xlabel(r'Mass [M$_{\\odot}$]')\n",
    "        ax2[0].set_ylabel('Counts')\n",
    "        ax2[0].set_title(f'{model_name} IMF for {cluster_name}, age = {time:.1e} Gyr: normal scale')\n",
    "        \n",
    "        \n",
    "        # Plotting histogram in log scale\n",
    "        ax2[1].hist(stellar_masses, range=(np.log10(min_mass), np.log10(max_mass)), \n",
    "                     bins=np.logspace(np.log10(min_mass), np.log10(max_mass), nbins+1),\n",
    "                     histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "\n",
    "        ax2[1].set_xlabel(r'Log Mass [M$_{\\odot}$]')\n",
    "        ax2[1].set_ylabel('Counts')\n",
    "        ax2[1].set_title(f'{model_name} IMF for {cluster_name}, age = {time:.1e} Gyr: log scale')\n",
    "\n",
    "        ax2[1].set_xscale('log')\n",
    "        \n",
    "        if save_plot:\n",
    "            plt.savefig(f'Plots/{cluster_name}_{model_name}_IMF_log_and_normal.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    return stellar_masses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b8341-3119-45ff-8eed-0500199069c4",
   "metadata": {},
   "source": [
    "## Age interpolation from in between isochrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e43f8b10-28aa-46c6-b01a-6d2594d08a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_age_interpolation(chi_values, isochrone_data, iso_ages, cluster_name, plot=True):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    chi_values: int\n",
    "        Values of sum(chi**2) for each isochrone\n",
    "        \n",
    "    isochrone_data: array\n",
    "        The data from all isochrones\n",
    "        \n",
    "    iso_ages: array/list\n",
    "        list/array of isochrone ages\n",
    "    \"\"\"\n",
    "    min_chi = np.min(chi_values)\n",
    "    pos_min_chi = np.where(chi_values==min_chi)[0][0]\n",
    "    \n",
    "    \n",
    "    if pos_min_chi==0:\n",
    "        new_cluster_age = iso_ages[pos_min_chi] # Find new age based on new minimum chi value\n",
    "        \n",
    "        younger_isochrone = isochrone_data[pos_min_chi]\n",
    "        younger_age = iso_ages[pos_min_chi]\n",
    "        older_isochrone = isochrone_data[pos_min_chi]  \n",
    "        older_age = iso_ages[pos_min_chi]\n",
    "        \n",
    "        plot=False\n",
    "        \n",
    "        print(f'Could not interpolate age for cluster {cluster_name}.')\n",
    "        \n",
    "    else:\n",
    "        # Limiting data to desired range\n",
    "        pnt_below = int(pos_min_chi-1)\n",
    "        pnt_above = int(pos_min_chi+2)\n",
    "    \n",
    "        #print(pnt_below)\n",
    "        #print(pnt_above)\n",
    "        # data for min chi, one above and one below\n",
    "        closest_isos = isochrone_data[pnt_below : pnt_above] # isochrone data for points \n",
    "        closest_ages = iso_ages[pnt_below : pnt_above] # isochrone ages for points\n",
    "        closest_chis = chi_values[pnt_below : pnt_above] # chi values for points\n",
    "    \n",
    "        #print(closest_ages)\n",
    "        #print(closest_chis)\n",
    "        # Fitting a quadratic function to interval\n",
    "        k2, k1, c = np.polyfit(closest_ages, closest_chis, deg=2)\n",
    "    \n",
    "        # Makes 1000 points within age interval\n",
    "        ages = np.linspace(np.min(closest_ages), np.max(closest_ages), 10000)\n",
    "        chis = k2*ages**2 + k1*ages + c # Calculates corresponding chi values from fit\n",
    "        new_min_chi = np.min(chis) # Find minimum chi value in interval\n",
    "        pos_new_min_chi = np.where(chis==new_min_chi)[0] # Find position of minimum chi value\n",
    "        new_cluster_age = ages[pos_new_min_chi][0] # Find new age based on new minimum chi value\n",
    "    \n",
    "        # Finding masses\n",
    "        if new_cluster_age<iso_ages[pos_min_chi]:\n",
    "            younger_isochrone = isochrone_data[int(pos_min_chi-1)]\n",
    "            younger_age = iso_ages[int(pos_min_chi-1)]\n",
    "            older_isochrone = isochrone_data[pos_min_chi]\n",
    "            older_age = iso_ages[pos_min_chi]\n",
    "            \n",
    "        elif new_cluster_age>iso_ages[pos_min_chi]:\n",
    "            younger_isochrone = isochrone_data[pos_min_chi]\n",
    "            younger_age = iso_ages[pos_min_chi]\n",
    "            older_isochrone = isochrone_data[int(pos_min_chi+1)]  \n",
    "            older_age = iso_ages[int(pos_min_chi+1)]\n",
    "        \n",
    "    if plot:\n",
    "        # Fixing data to plot\n",
    "        ages_fit = np.linspace(np.min(closest_ages), np.max(closest_ages), 100)\n",
    "        chi_vals_fit = k2*ages_fit**2 + k1*ages_fit + c\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(7, 6))\n",
    "        \n",
    "        # Plotting chi for each isochrone\n",
    "        ax.scatter(iso_ages, chi_values, c='b', s=10, label=r'$\\chi^2$ per isoc.')\n",
    "        # Plotting minimum chi from isochrones\n",
    "        ax.scatter(iso_ages[pos_min_chi], min_chi, c='r', s=20, label=r'Age$_{min}$ isoc.')\n",
    "        # Plotting chi-age fit\n",
    "        ax.plot(ages_fit, chi_vals_fit, color='orange', label=r'Age fit')\n",
    "        \n",
    "        # Marking the newly determined age\n",
    "        ax.axvline(new_cluster_age, linestyle='dashed', color='g', \n",
    "                   label=f'Age={new_cluster_age:.3} Gyr')\n",
    "        \n",
    "        ax.set_xlabel('Ages [Gyr]')\n",
    "        ax.set_ylabel(r'$\\chi^2$')\n",
    "        ax.set_title(f'Age fit {cluster_name}')\n",
    "        \n",
    "        ax.set_xlim(xmin=np.min(closest_ages)-0.005, xmax=np.max(closest_ages)+0.005)\n",
    "        ax.set_ylim(ymin=np.min(chi_vals_fit)-50, ymax=np.max(chi_vals_fit)+50)\n",
    "        \n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_xticks(np.linspace(np.min(closest_ages)-0.005, np.max(closest_ages)+0.005, 6))\n",
    "        #plt.savefig('Plots/Age_fit_plot.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    return new_cluster_age, younger_isochrone, younger_age, older_isochrone, older_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595eb9d-f211-4ca1-8d5f-ec2ec9e7ed52",
   "metadata": {},
   "source": [
    "## Interpolated mass from in between isochrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5789d1e2-1030-40fd-91b1-6c038a50ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolated_mass(cluster_data, cluster_name, new_cluster_age, younger_data, older_data, \n",
    "                      younger_age, older_age, model_name, bin_width, plot=True, save_plot=False):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ------------\n",
    "    cluster_data:\n",
    "    \n",
    "    cluster_names:\n",
    "    \n",
    "    younger_data: array\n",
    "        data for younger isochrone\n",
    "        \n",
    "    older_data: array\n",
    "        data for older isochrone\n",
    "        \n",
    "    younger_age: array\n",
    "        age for younger isochrone\n",
    "        \n",
    "    older_age: array\n",
    "        age for older isochrone\n",
    "        \n",
    "    model_name:\n",
    "    \"\"\"\n",
    "    #print(np.min(younger_data[:, 3]))\n",
    "    #print(np.min(younger_data[:, 3]))\n",
    "    colour_mask = (np.min(younger_data[:, 3])<=cluster_data['bp_rp'].value)&(cluster_data['bp_rp'].value<=np.max(older_data[:, 3]))\n",
    "    \n",
    "    cluster_data = cluster_data[colour_mask]\n",
    "    #print(cluster_data)\n",
    "    \n",
    "    # Interpolating masses from model isochrones above and below new age\n",
    "    young_stellar_masses = IMF(cluster_data['bp_rp'].value, younger_data, cluster_name, \n",
    "                               model_name, 15, younger_age, check=False, save_check=False, \n",
    "                               plot=False, save_plot=False)[:, np.newaxis]\n",
    "    \n",
    "    old_stellar_masses = IMF(cluster_data['bp_rp'].value, older_data, cluster_name, \n",
    "                               model_name, 15, older_age, check=False, save_check=False, \n",
    "                               plot=False, save_plot=False)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    # Putting masses into same array, shape: (n_stars, age=2)\n",
    "    model_masses = np.concatenate([young_stellar_masses, old_stellar_masses], axis=1)\n",
    "    # Sort for the interpolation\n",
    "    #sorted_model_masses = model_masses[model_masses[:, 0].argsort()] # Sort according to young masses\n",
    "    \n",
    "    # Creating arrays of ages from model isochrones above and below new age\n",
    "    # Fills entire array with same age as is it constant for each isochrone\n",
    "    young_age_array = np.empty(len(cluster_data))\n",
    "    young_age_array[:] = younger_age \n",
    "    young_age_array = young_age_array[:, np.newaxis]\n",
    "    \n",
    "    old_age_array = np.empty(len(cluster_data))\n",
    "    old_age_array[:] = older_age # Fills entire array with same age\n",
    "    old_age_array = old_age_array[:, np.newaxis]\n",
    "    \n",
    "    # Putting ages into same array, shape: (n_stars, models=2)\n",
    "    model_ages = np.concatenate((young_age_array, old_age_array), axis=1)\n",
    "    \n",
    "    \n",
    "    cluster_stellar_masses = np.empty(len(cluster_data))\n",
    "    \n",
    "    # Want to loop over each star => loop over each row. Gives 2 model points for each star\n",
    "    for i in range(len(cluster_data)):\n",
    "        cluster_stellar_masses[i] = np.interp(new_cluster_age, model_ages[i, :], \n",
    "                                              model_masses[i, :])\n",
    "        \n",
    "        \n",
    "        \n",
    "    if plot:\n",
    "        # Plotting histogram in normal scale\n",
    "        min_mass = np.min(cluster_stellar_masses)\n",
    "        max_mass = np.max(cluster_stellar_masses)\n",
    "        \n",
    "        nbins = int(np.round(2*(np.log10(max_mass) - np.log10(min_mass))/bin_width))\n",
    "        \n",
    "        \n",
    "        fig2, ax2 = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        \n",
    "        #ax2[0].hist(cluster_stellar_masses, bins=nbins,\n",
    "        #             histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "\n",
    "        #ax2[0].set_xlabel(r'Mass [M$_{\\odot}$]')\n",
    "        #ax2[0].set_ylabel('Counts')\n",
    "        #ax2[0].set_title(f'{model_name} IMF for {cluster_name}, age = {new_cluster_age:.2e} Gyr: normal scale')\n",
    "        #\n",
    "        #if model_name=='MIST':\n",
    "        #    ax2[0].set_xlim(xmin=0, xmax=5)\n",
    "        #        \n",
    "        #elif model_name=='Baraffe':\n",
    "        #    ax2[0].set_xlim(xmin=0, xmax=1.5)\n",
    "        \n",
    "        \n",
    "        # Plotting histogram in log scale\n",
    "        ax2.hist(cluster_stellar_masses, range=(np.log10(min_mass), np.log10(max_mass)), \n",
    "                     bins=np.logspace(np.log10(min_mass), np.log10(max_mass), nbins+1),\n",
    "                     histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "\n",
    "        ax2.set_xlabel(r'Log Mass [M$_{\\odot}$]')\n",
    "        ax2.set_ylabel('Counts')\n",
    "        ax2.set_title(f'{model_name} IMF for {cluster_name}, age = {new_cluster_age:.2e} Gyr: log scale')\n",
    "\n",
    "        ax2.set_xscale('log')\n",
    "        ax2.set_yscale('log')\n",
    "        if model_name=='MIST':\n",
    "            ax2.set_xlim(xmin=0.08, xmax=5)\n",
    "                \n",
    "        elif model_name=='Baraffe':\n",
    "            ax2.set_xlim(xmin=0.01, xmax=1.5)\n",
    "        \n",
    "        if save_plot:\n",
    "            plt.savefig(f'Plots/{cluster_name}_{model_name}_IMF_log_and_normal.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    return cluster_stellar_masses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e3d89-518c-4867-834e-0cbbc9722208",
   "metadata": {},
   "source": [
    "## All in one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd6e042-565c-4416-956e-5ce66eadb64b",
   "metadata": {},
   "source": [
    "**Check** if it is better to have varying numbers of bins for each cluster. Then nbins has to be a list of number of bins which is looped over for each cluster. The counts and edges arrays also have to be converted into lists instead of arrays because they will then vary in size. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef2cff-9783-40f6-b917-9bb49819e51a",
   "metadata": {},
   "source": [
    "**Fix!!!** Interpolation when data is outside interpolation interval!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a98a1650-5229-480b-929d-124419167f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_IMFs(cluster_data, cluster_names, model, metallicity, bin_width, age_fit_plot=True, \n",
    "               chi_plot=True, save_chi_plot=False, plot_hists=True, save_plot_hists=True): \n",
    "    #check_interp=True, save_check_interp=False,  cluster_tmass_data, \n",
    "    \"\"\"\n",
    "    Finds the best fitting isochrone to the data\n",
    "    ---------------------------------------------\n",
    "    Parameters:\n",
    "    -----------\n",
    "    cluster_data: list\n",
    "        List of cluster data for different clusters\n",
    "        \n",
    "    cluster_names: list\n",
    "        List of the names of all clusters\n",
    "        \n",
    "    iso_file_names: list\n",
    "        List of possible isochrones\n",
    "        \n",
    "    model: str\n",
    "        Isochrone model\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    # Extracting isochrone data for the Gaia magnitudes\n",
    "    iso_data, iso_ages = separate_isochrones(model, metallicity, 'gaia')\n",
    "    # FLattening the isochrone ages\n",
    "    iso_ages = iso_ages.flatten()\n",
    "    # Extracting the isochrone parameters\n",
    "    isochrone_parameters_gaia = isochrone_params(iso_data, model, 'gaia') # A (6, n_isochsones) array\n",
    "    \n",
    "    # Extracting the isochrone data for the 2MASS magnitudes\n",
    "    #iso_tmass_data, iso_tmass_ages = separate_isochrones(model, metallicity, '2mass')\n",
    "    \n",
    "    \n",
    "    # Initiating outputlists\n",
    "    log_counts = [] #np.empty((nbins, len(cluster_data)))\n",
    "    log_edges = [] #np.empty((nbins+1, len(cluster_data)))\n",
    "    all_masses = []\n",
    "    all_ages = []\n",
    "    same_as_first_iso = []\n",
    "    \n",
    "    all_cluster_names = cluster_names.copy() #np.array([float(name) for name in cluster_names])\n",
    "    \n",
    "    for i, cl_data in enumerate(cluster_data): # Loops over all clusters in list\n",
    "        print(f'i new = {i}')\n",
    "        \n",
    "        # Removing stars with missing colour values in both datasets\n",
    "        data_mask = cl_data['bp_rp'].mask==False # \n",
    "        cl_data = cl_data[data_mask]\n",
    "        #cl_tmass_data = cluster_tmass_data[i]\n",
    "        \n",
    "        \n",
    "        # Finding common stars for Gaia and 2MASS data \n",
    "        #gaia_2mass_inters, gaia_indices, tmass_indices = np.intersect1d(cl_data['GaiaID'].value, \n",
    "        #                                                                cl_tmass_data['GaiaID'].value,\n",
    "        #                                                                return_indices=True)\n",
    "        #\n",
    "        \n",
    "       # if len(gaia_indices)!=len(cl_tmass_data):\n",
    "       #     cl_member_indices = np.linspace(0, len(cl_tmass_data)-1, len(cl_tmass_data), dtype=int)\n",
    "       #     cl_member_indices = np.delete(cl_member_indices, tmass_indices)\n",
    "       #     cl_tmass_data.remove_rows(cl_member_indices)\n",
    "            \n",
    "        \n",
    "        # Finding best fitting isochrone \n",
    "        chi_values = chi_fitting(fit_fcn, cl_data, isochrone_parameters_gaia, iso_data, 'gaia')\n",
    "        min_chi = np.min(chi_values)\n",
    "        pos_min_chi = np.where(chi_values==min_chi)[0][0]\n",
    "        \n",
    "        min_chis = np.array([0., pos_min_chi])\n",
    "        \n",
    "        first_iso = pos_min_chi\n",
    "        \n",
    "        ##################################################################################\n",
    "        #min_col = np.min(cl_data[])\n",
    "        #nbins = int(np.round(2*(np.log10(max_mass) - np.log10(min_mass))/bin_width))\n",
    "        #cl_name = cluster_names[i]\n",
    "        #best_isochrone = iso_tmass_data[pos_min_chi]\n",
    "        #best_iso_col = best_isochrone[:, 2]-best_isochrone[:, 4]\n",
    "        #best_iso_mag = best_isochrone[:, 2]\n",
    "        #fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        \n",
    "        #ax.hist(np.array(cl_data['bp_rp'].value), bins=15,\n",
    "        #        align='left', histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "        #ax[0].plot(best_iso_col, best_iso_mag, 'r')\n",
    "        #ax[0].scatter(cl_tmass_data['J-K'], cl_tmass_data['J'], c='b', s=10, alpha=0.5)\n",
    "        #ax[0].set_xlim(-5, 6)\n",
    "        #ax[0].set_ylim(-5, 15)\n",
    "        #ax[0].set_title(f'CMD Beforecluster  {i}')\n",
    "        #ax[0].invert_yaxis()\n",
    "        #ax[0].grid(True)\n",
    "        \n",
    "        #ax.grid(True)\n",
    "        #plt.show()\n",
    "        ######################################################################################\n",
    "        \n",
    "        #while min_chis[0]!=min_chis[1]:\n",
    "        #    \n",
    "        #    #print(min_chis)\n",
    "        #    min_chis[0] = pos_min_chi\n",
    "        #    \n",
    "        #    best_isochrone = iso_tmass_data[pos_min_chi]\n",
    "        #    \n",
    "        #    iso_jh = best_isochrone[:, 2] - best_isochrone[:, 3] # Isochrone CCD values\n",
    "        #    iso_hk = best_isochrone[:, 3] - best_isochrone[:, 4] # Isochrone CCD values\n",
    "        #    \n",
    "        #    iso_interval_fit_mask = (0.18<=iso_hk)&(iso_hk<=0.28) \n",
    "        #    \n",
    "        #    iso_hk_interval = iso_hk[iso_interval_fit_mask]\n",
    "        #    iso_jh_interval = iso_jh[iso_interval_fit_mask]\n",
    "        #    \n",
    "        #    k_iso_fit, m_iso_fit = np.polyfit(iso_hk_interval, iso_jh_interval, deg=1)\n",
    "        #    \n",
    "        #    \n",
    "        #    # Correcting 2MASS data\n",
    "        #    cl_tmass_data = extinction(k_iso_fit, m_iso_fit, cl_tmass_data)\n",
    "        #    #print(cl_tmass_data)\n",
    "        #    mean_A_G = np.mean(cl_tmass_data['A_G'].value)*u.mag\n",
    "        #    mean_A_BP = np.mean(cl_tmass_data['A_BP'].value)*u.mag\n",
    "        #    mean_A_RP = np.mean(cl_tmass_data['A_RP'].value)*u.mag\n",
    "        #    #print(mean_extinction)\n",
    "        #    #print(np.min(cl_tmass_data['Extinction'].value), np.max(cl_tmass_data['Extinction'].value))\n",
    "        #    \n",
    "        #    # Adding extinction column to Gaia data\n",
    "        #    cl_data['A_G'] = np.zeros((len(cl_data)))\n",
    "        #    cl_data['A_BP'] = np.zeros((len(cl_data)))\n",
    "        #    cl_data['A_RP'] = np.zeros((len(cl_data)))\n",
    "        #    \n",
    "        #    # Adds extracted values from 2MASS data\n",
    "        #    cl_data['A_G'][gaia_indices] = cl_tmass_data['A_G']\n",
    "        #    cl_data['A_BP'][gaia_indices] = cl_tmass_data['A_BP']\n",
    "        #    cl_data['A_RP'][gaia_indices] = cl_tmass_data['A_RP']\n",
    "        #    \n",
    "        #    # Finding the non-xmatched star positions\n",
    "        #    star_positions = np.linspace(0, len(cl_data)-1, len(cl_data), dtype=int)\n",
    "        #    non_xmatched_pos = np.delete(star_positions, gaia_indices)\n",
    "        #    \n",
    "        #    # Assigning mean extintion to the non-xmatched stars in the Gaia data\n",
    "        #    cl_data['A_G'][non_xmatched_pos] = mean_A_G\n",
    "        #    cl_data['A_BP'][non_xmatched_pos] = mean_A_BP\n",
    "        #    cl_data['A_RP'][non_xmatched_pos] = mean_A_RP\n",
    "        #    \n",
    "        #    ########### Change according to table in paper!!!!!!!!####################\n",
    "        #    #extinction_G = 0.789*cl_data['Extinction']*u.mag #(+-0.005) #extinction_per_band('G', cl_data['bp_rp'].value, cl_data['Extinction'].value)\n",
    "        #    #extinction_BP = 1.002*cl_data['Extinction']*u.mag #(+-0.007) #extinction_per_band('BP', cl_data['bp_rp'].value, cl_data['Extinction'].value)\n",
    "        #    #extinction_RP = 0.589*cl_data['Extinction']*u.mag #(+-0.004) #extinction_per_band('RP', cl_data['bp_rp'].value, cl_data['Extinction'].value)\n",
    "        #    \n",
    "        #    extinction_bp_rp = cl_data['A_BP'].value - cl_data['A_RP'].value\n",
    "        #    \n",
    "        #    # Correcting the absolute magnitude in Gaia data\n",
    "        #    cl_data['M_V'] = (cl_data['M_V'].value - cl_data['A_G'].value)*u.mag #(cl_data['M_apparent'].value - 5*np.log10(cl_data['dist'].value) + 5 - cl_data['Extinction'].value)*u.mag\n",
    "        #    cl_data['bp_rp'] = (cl_data['bp_rp'].value - extinction_bp_rp)*u.mag\n",
    "        #    #print(cl_data['M_V'])\n",
    "        #\n",
    "        #    \n",
    "        #    chi_values = chi_fitting(fit_fcn, cl_data, isochrone_parameters_gaia, iso_data, 'gaia')\n",
    "        #    #print(chi_values)\n",
    "        #    min_chi = np.min(chi_values)\n",
    "        #    #print(min_chi)\n",
    "        #    pos_min_chi = np.where(chi_values==min_chi)[0][0]\n",
    "        #    \n",
    "        #    min_chis[1] =pos_min_chi\n",
    "        #    #print(min_chis)\n",
    "        #    #print()\n",
    "        \n",
    "        #best_isochrone = iso_tmass_data[pos_min_chi]\n",
    "        \n",
    "        #ax[1].plot(best_isochrone[:, 2] - best_isochrone[:, 4], best_isochrone[:, 2], 'r')\n",
    "        #ax[1].scatter(cl_tmass_data['J-K'], cl_tmass_data['J'], c='b', s=10, alpha=0.5)\n",
    "        #ax[1].set_xlim(-5, 6)\n",
    "        #ax[1].set_ylim(-5, 15)\n",
    "        #ax[1].set_title('CMD After')\n",
    "        #ax[1].invert_yaxis()\n",
    "        #ax[1].grid(True)\n",
    "        \n",
    "        #plt.tight_layout()\n",
    "        #plt.show()\n",
    "        #fig2, ax2 = plt.subplots(figsize=(5, 4))\n",
    "        \n",
    "        #ax2.hist(np.array(cl_data['bp_rp'].value), bins=80,\n",
    "        #        align='left', histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5)\n",
    "            #ax.scatter(cl_data['bp_rp'], cl_data['M_V'], s=10, alpha=0.5)\n",
    "        #ax2.set_xlim(xmin=0)\n",
    "        #ax.set_ylim(-5, 15)\n",
    "        #ax.set_title('Initially')\n",
    "        #ax.set_xscale('log')\n",
    "        #ax.set_yscale('log')\n",
    "        #ax2.grid(True)\n",
    "        #ax.invert_yaxis()\n",
    "        #plt.show()\n",
    "        \n",
    "        \n",
    "        if first_iso == pos_min_chi:\n",
    "            same_as_first_iso.append(cl_data['Cluster_number'][0])\n",
    "        \n",
    "        cl_age, iso_young, age_young, iso_old, age_old = new_age_interpolation(chi_values, iso_data, \n",
    "                                                                            iso_ages, cluster_names[i],\n",
    "                                                                            plot=age_fit_plot)\n",
    "        \n",
    "        all_ages.append(cl_age)\n",
    "        #min_chi = np.min(chi_values)\n",
    "        #min_iso_pos = int(np.where(chi_values==min_chi)[0])\n",
    "        \n",
    "        if chi_plot:\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            \n",
    "            ax.scatter(iso_ages, chi_values, c='b', s=10, label=r'$\\chi^2$ values')\n",
    "            #ax.scatter(iso_ages[min_iso_pos], min_chi, c='r', s=15, label=r'Minimum $\\chi^2$')\n",
    "            \n",
    "            ax.axvline(cl_age, linestyle='dashed', c='g')\n",
    "            \n",
    "            ax.set_xlabel('Age [Gyr]')\n",
    "            ax.set_ylabel(r'$\\chi^2$ values')\n",
    "            ax.set_title(r'$\\chi^2$ values for isochrone ages')\n",
    "            ax.set_xscale('log')\n",
    "            ax.legend()\n",
    "            \n",
    "            if save_chi_plot:\n",
    "                plt.savefig(f'Plots/Chi_plot_{cluster_names[i]}.png', bbox_inches='tight')\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        # \n",
    "        #best_iso_params = isochrone_parameters[:, min_iso_pos]\n",
    "        #best_iso_data = iso_data[min_iso_pos] # Contains (time, M_V, bp_rp, Mass)\n",
    "        \n",
    "        #colour_cluster_mask = (np.min(best_iso_data[:, 3])<=cl_data['bp_rp'].value)&(cl_data['bp_rp'].value<=np.max(best_iso_data[:, 3]))\n",
    "        \n",
    "        #cl_data = cl_data[colour_cluster_mask]\n",
    "        \n",
    "        #cluster_masses = IMF(cl_data['bp_rp'].value, best_iso_data, cluster_names[i], model, \n",
    "        #                     nbins=nbins, time=iso_ages[min_iso_pos], check=check_interp, \n",
    "        #                     save_check=save_check_interp, plot=plot_hists, \n",
    "        #                     save_plot=save_plot_hists)\n",
    "        \n",
    "        cluster_masses = interpolated_mass(cl_data, cluster_names[i], cl_age, iso_young, iso_old,\n",
    "                                           age_young, age_old, model, bin_width, plot_hists, \n",
    "                                           save_plot_hists)\n",
    "        \n",
    "        \n",
    "        mass_mask = cluster_masses>0.3\n",
    "        \n",
    "        cluster_masses = cluster_masses[mass_mask]\n",
    "        cl_name = cluster_names[i]\n",
    "        #print(f'{len(cluster_names) = }')\n",
    "        #print(f'{i = }')\n",
    "        \n",
    "        if len(cluster_masses)<10:\n",
    "            del [all_ages[-1]]\n",
    "            name_pos = np.where(all_cluster_names==cl_name)[0]\n",
    "            all_cluster_names = np.delete(all_cluster_names, name_pos)\n",
    "            continue\n",
    "            \n",
    "        #print(f'{len(cluster_names) = }')\n",
    "        #print(f'{i = }')\n",
    "        #print()\n",
    "        \n",
    "        all_masses.append(cluster_masses)\n",
    "        \n",
    "        min_mass = np.min(cluster_masses)\n",
    "        max_mass = np.max(cluster_masses)\n",
    "        \n",
    "        nbins = int(np.round(2*(np.log10(max_mass)-np.log10(min_mass))/(bin_width)))\n",
    "        \n",
    "        #normal_counts[:, i], normal_edges[:, i] = np.histogram(cluster_masses, nbins, \n",
    "        #                                                       range=(np.min(cluster_masses), \n",
    "        #                                                       np.max(cluster_masses)))\n",
    "        \n",
    "        l_counts, l_edges = np.histogram(cluster_masses, \n",
    "                                         bins=np.logspace(np.log10(np.min(cluster_masses)), \n",
    "                                                          np.log10(np.max(cluster_masses)), \n",
    "                                                          nbins+1),\n",
    "                                         range=(np.log10(np.min(cluster_masses)), \n",
    "                                                np.log10(np.max(cluster_masses))))\n",
    "        log_counts.append(l_counts)\n",
    "        log_edges.append(l_edges)\n",
    "    return log_counts, log_edges, all_masses, all_ages, same_as_first_iso, all_cluster_names\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f50f8ee-6bff-442f-9646-15ba072009ba",
   "metadata": {},
   "source": [
    "## Separating cluster data into separate arrays for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd65e01b-ae6c-49a4-a601-3e6c60d609cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_list(cluster_table, N_limit, survey, check_effect, dist_cut=600):\n",
    "    \n",
    "    clusters = []\n",
    "    names = []\n",
    "    \n",
    "    cluster_table = cluster_table[cluster_table['Cluster_number'].argsort()]\n",
    "    cluster_table['dist'] = np.zeros((len(cluster_table))) * u.pc\n",
    "    cluster_table['dist_error'] = np.zeros((len(cluster_table))) * u.pc\n",
    "    \n",
    "    for i in range(1, cluster_table['Cluster_number'][-1]+1):\n",
    "        # Creates a mask that only leaves one cluster\n",
    "        cluster_mask = cluster_table['Cluster_number']==i\n",
    "        \n",
    "        # Creates a table with only one cluster\n",
    "        cluster = cluster_table[cluster_mask]\n",
    "        \n",
    "        # Checking that the cluster is not too small\n",
    "        if len(cluster)<N_limit:\n",
    "            continue\n",
    "        \n",
    "        else:        \n",
    "            if survey=='gaia':\n",
    "        \n",
    "                cluster['bp_rp'] = cluster['G_bp'] - cluster['G_rp']\n",
    "            \n",
    "                # Sorting cluster according to brightest stars\n",
    "                cluster = cluster[cluster['M_apparent'].argsort()]\n",
    "                # 10 brightest stars in the cluster have the lowest magnitudes\n",
    "                brightest_stars = cluster[:10]\n",
    "                # Distances of brightest stars\n",
    "                distance = 1/(brightest_stars['Parallax'].value*1e-3) * u.pc\n",
    "                # Mean distance of the cluster based on the 10 brightest stars\n",
    "                mean_distance = np.mean(distance)\n",
    "                #print(mean_distance)\n",
    "                #print(type(mean_distance))\n",
    "                \n",
    "                if mean_distance>dist_cut*u.pc:\n",
    "                    continue\n",
    "                \n",
    "                cluster['dist'] = mean_distance #Distance(parallax=cluster['Parallax'])\n",
    "                \n",
    "                expr = -((brightest_stars['Parallax_error'].value * 1e-3)/(brightest_stars['Parallax'].value * 1e-3)**2)\n",
    "                #print(expr)\n",
    "                distance_error = np.sqrt((1/10)*np.sum(expr**2)) * u.pc\n",
    "                #print(distance_error)\n",
    "                cluster['dist_error'] = distance_error\n",
    "                \n",
    "                if check_effect=='+':\n",
    "                    cluster['dist'] = cluster['dist'] + cluster['dist_error']\n",
    "                    \n",
    "                elif check_effect=='-':\n",
    "                    cluster['dist'] = cluster['dist'] - cluster['dist_error']\n",
    "                \n",
    "                # Calculates and adds an absolute magnitude column calculated from the photometric mean magnitude \n",
    "                # and the distance modulus, described above\n",
    "                cluster['M_V'] = (cluster['M_apparent'].value - 5*np.log10(cluster['dist'].value) + 5)*u.mag\n",
    "            \n",
    "            \n",
    "            elif survey=='2mass':\n",
    "                cluster['J-H'] = (cluster['j_m'].value - cluster['h_m'].value)*u.mag\n",
    "                cluster['H-K'] = (cluster['h_m'].value - cluster['k_m'].value)*u.mag\n",
    "            \n",
    "                cluster['J'] = cluster['j_m'].value * u.mag\n",
    "                cluster['H'] = cluster['h_m'].value * u.mag\n",
    "                cluster['K'] = cluster['k_m'].value * u.mag\n",
    "                cluster['J-K'] = (cluster['j_m'].value - cluster['k_m'].value)*u.mag\n",
    "        \n",
    "                # Sorting cluster according to brightest stars\n",
    "                cluster = cluster[cluster['M_apparent'].argsort()]\n",
    "                # 10 brightest stars in the cluster have the lowest magnitudes\n",
    "                brightest_stars = cluster[:10]\n",
    "                # Distances of brightest stars\n",
    "                distance = 1/(brightest_stars['Parallax'].value*1e-3) * u.pc\n",
    "                # Mean distance of the cluster based on the 10 brightest stars\n",
    "                mean_distance = np.mean(distance)\n",
    "                #print(mean_distance)\n",
    "                #print(type(mean_distance))\n",
    "            \n",
    "                cluster['dist'] = mean_distance #Distance(parallax=cluster['Parallax'])\n",
    "            \n",
    "                if mean_distance>dist_cut*u.pc:\n",
    "                    continue\n",
    "            \n",
    "            \n",
    "            clusters.append(cluster)\n",
    "            names.append(f\"{cluster['Cluster_number'][0]}\")\n",
    "            \n",
    "    return clusters, names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f80cdb8-f8c6-4b31-8069-4851f68b2b0f",
   "metadata": {},
   "source": [
    "## Fitting IMF slopes function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4c5fbb28-b8b5-470e-bbb9-05c37fb218c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMF_fit_fcn(x, a, C):\n",
    "    return C*x**a\n",
    "\n",
    "def IMF_slopes(log_edges, log_counts, all_cluster_masses, model, intervals='Kroupa', \n",
    "               plot=True):\n",
    "    # Want to plot, give a list of all slopes, chose if I want to use all intervals\n",
    "    # Comparison with Kroupa\n",
    "    # Plot fits with histograms\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    log_edges: list\n",
    "        List with edges of the logarithmic bins\n",
    "        \n",
    "    log_counts: list\n",
    "        List with logarithmic bin counts\n",
    "        \n",
    "    all_cluster_masses: list\n",
    "        List of all clusters' stellar mass arrays\n",
    "        \n",
    "    Output:\n",
    "    -------\n",
    "    bin_widths:\n",
    "    \n",
    "    slopes:\n",
    "    \"\"\"\n",
    "    \n",
    "    bin_widths = np.zeros((len(all_cluster_masses)))\n",
    "    \n",
    "    # shape(n_clusters, 2 parameters, 4 intervals)\n",
    "    all_cluster_params = np.full((len(all_cluster_masses), 2, 4), fill_value=np.nan) \n",
    "    \n",
    "    kroupa_diff = np.full((len(all_cluster_masses), 4), fill_value=np.nan)\n",
    "    \n",
    "    it=0\n",
    "    # Loops over each cluster\n",
    "    for i, cluster_masses in enumerate(all_cluster_masses):\n",
    "        print(i)\n",
    "        #print()\n",
    "        min_masses = np.min(cluster_masses)\n",
    "        max_masses = np.max(cluster_masses)\n",
    "        edges = log_edges[i]#.flatten()\n",
    "        \n",
    "        # Rolling edges array such that for-loop is not needed\n",
    "        rolled_edges = np.roll(edges, shift=1)\n",
    "        \n",
    "        n_bins = len(edges)-1\n",
    "        \n",
    "        # Getting bin widths and bin positions\n",
    "        bin_mid = np.exp((np.log(edges) + np.log(rolled_edges))/2)\n",
    "        bin_mid = bin_mid[1:]\n",
    "        \n",
    "        bin_width = np.abs(np.log(edges) - np.log(rolled_edges))\n",
    "        bin_width = bin_width[1:]\n",
    "        bin_width_diff = np.round(np.abs(bin_width - np.roll(bin_width, shift=1)), decimals=0)\n",
    "        if all(bin_width_diff==0):\n",
    "            bin_widths[i] = bin_width[0]\n",
    "        \n",
    "        else:\n",
    "            print('Not constant bin width!')\n",
    "        \n",
    "        \n",
    "        cluster_counts = log_counts[i]\n",
    "        \n",
    "        if intervals=='Kroupa':\n",
    "            # Creating interval mass masks\n",
    "            interval_1_mask = (0.01<=bin_mid)&(bin_mid<=0.08)\n",
    "            interval_2_mask = (0.3<=bin_mid)&(bin_mid<=0.5) #0.08\n",
    "            interval_3_mask = (0.5<=bin_mid)&(bin_mid<=1.0)\n",
    "            interval_4_mask = (1.0<=bin_mid)\n",
    "            \n",
    "            all_intervals = np.array([1, 2, 3, 4])\n",
    "            \n",
    "            interval_masks = [interval_1_mask, interval_2_mask, interval_3_mask, interval_4_mask]\n",
    "            interval_edges = [(0.01, 0.08), (0.3, 0.5), (0.5, 1.0), (1.0, np.max(cluster_masses))]\n",
    "            \n",
    "            all_interval_masses = [bin_mid[mask] for mask in interval_masks]\n",
    "            all_interval_counts = [cluster_counts[mask] for mask in interval_masks]\n",
    "            \n",
    "            model_slopes = np.array([0.3, 1.3, -2.3, -2.3])\n",
    "            model_slope_errors = np.array([0.7, 0.5, 0.3, 0.7])\n",
    "            \n",
    "            lengths = np.array([len(int_mask[int_mask==True]) for int_mask in interval_masks])# Works! Use this in the if-statement!\n",
    "            \n",
    "            \n",
    "            if any(length<=1 for length in lengths):\n",
    "                short_len_positions = [k for k,length in enumerate(lengths) if length<=1]\n",
    "                short_len_mask = lengths>1\n",
    "                \n",
    "                remove_pos = short_len_positions[0]\n",
    "                    \n",
    "                interval_masks = [mask for k, mask in enumerate(interval_masks) if len(mask[mask==True])>1]\n",
    "                interval_edges.remove(interval_edges[remove_pos])\n",
    "                \n",
    "                all_intervals = all_intervals[short_len_mask]\n",
    "                \n",
    "                all_interval_masses = [masses for k, masses in enumerate(all_interval_masses) if len(masses)>1]\n",
    "                all_interval_counts = [counts for k, counts in enumerate(all_interval_counts) if len(counts)>1]\n",
    "                \n",
    "                model_slopes = np.delete(model_slopes, short_len_positions)\n",
    "                model_slope_errors = np.delete(model_slope_errors, short_len_positions)\n",
    "            \n",
    "            counter = 0\n",
    "            # Ignoring intervals with only one non-zero bin\n",
    "            while any([len(int_counts[int_counts>0])<=1 for int_counts in all_interval_counts]):\n",
    "                counter = counter +1\n",
    "                # Finds indices for intervals for which there is only one non-zero bin\n",
    "                failed_int_pos = np.array([index for index, int_counts in enumerate(all_interval_counts) if len(int_counts[int_counts>0])<=1])\n",
    "                \n",
    "                del interval_masks[failed_int_pos[0]]                \n",
    "                del interval_edges[failed_int_pos[0]]\n",
    "                \n",
    "                all_intervals = np.delete(all_intervals, failed_int_pos[0])\n",
    "                \n",
    "                del all_interval_masses[failed_int_pos[0]]\n",
    "                del all_interval_counts[failed_int_pos[0]]\n",
    "                \n",
    "                model_slopes = np.delete(model_slopes, failed_int_pos[0])\n",
    "                model_slope_errors = np.delete(model_slope_errors, failed_int_pos[0])\n",
    "                \n",
    "            \n",
    "            # shape(fit_length, n intervals)\n",
    "            x_fit_values = np.empty((500, len(interval_masks))) \n",
    "            y_fit_values = np.empty((500, len(interval_masks)))\n",
    "            \n",
    "            # shape(2 params, n intervals)\n",
    "            #cluster_params = np.zeros((2, 4))  #len(interval_masks)\n",
    "               \n",
    "            it = it+1\n",
    "        \n",
    "        #print(it)\n",
    "        #print(interval_edges)\n",
    "        # Loop over mass intervals to fit parameters\n",
    "        for j, interval_masses in enumerate(all_interval_masses):\n",
    "            #print(j)\n",
    "            interval_counts = all_interval_counts[j].flatten()\n",
    "            #print(interval_edges[j])\n",
    "            #print(interval_counts)\n",
    "            #print(interval_masses)\n",
    "            \n",
    "            fitted_params, covariance = scopt.curve_fit(IMF_fit_fcn, xdata=interval_masses, \n",
    "                                                        ydata=interval_counts, p0=[model_slopes[j], 30],\n",
    "                                                        maxfev=5000) # , full_output=True\n",
    "            \n",
    "            #print(covariance)\n",
    "            # Adding to final list/array\n",
    "            all_cluster_params[i, :, all_intervals[j]-1] = fitted_params\n",
    "            kroupa_diff[i, all_intervals[j]-1] = (fitted_params[0] - model_slopes[j]) # all_cluster_params[i, :, intervals[j]]\n",
    "            \n",
    "            # Dividing up\n",
    "            slope_fit, C_fit = fitted_params\n",
    "            \n",
    "            x_fit_values[:, j] = np.linspace(interval_edges[j][0], interval_edges[j][1], 500)\n",
    "            y_fit_values[:, j] = IMF_fit_fcn(x_fit_values[:, j], slope_fit, C_fit)\n",
    "        \n",
    "        \n",
    "        if plot:\n",
    "            colours = ['r', 'orange', 'g', 'm', 'skyblue', 'limegreen']\n",
    "            #min_masses = np.min(cluster_masses)\n",
    "            #max_masses = np.max(cluster_masses)\n",
    "            \n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(7, 6))\n",
    "            \n",
    "            ax.hist(cluster_masses, range=(np.log10(min_masses), np.log10(max_masses)), \n",
    "                    bins=np.logspace(np.log10(min_masses), np.log10(max_masses), n_bins),\n",
    "                    histtype='stepfilled', fc=(0, 0, 1, 0.25), ec='b', lw=1.5, \n",
    "                    label='IMF histogram')\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Loop over mass intervals to fit parameters\n",
    "            for j, interval_masses in enumerate(all_interval_masses):\n",
    "                ax.plot(x_fit_values[:, j], y_fit_values[:, j], color=colours[j], \n",
    "                        label=f'{interval_edges[j][0]}'+r'$\\leq$m/'+r'M$_{\\odot}$<'+f'{interval_edges[j][1]:.3}')\n",
    "                \n",
    "            ax.set_xlabel(r'Mass [M$_{\\odot}$]')\n",
    "            ax.set_ylabel(r'Counts')\n",
    "            ax.set_title('Histogram with fitted IMF slopes')\n",
    "            \n",
    "            ax.legend(loc='lower right')\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_yscale('log')\n",
    "            \n",
    "            if model=='MIST':\n",
    "                ax.set_xlim(xmin=0.08, xmax=5)\n",
    "                \n",
    "            elif model=='Baraffe':\n",
    "                ax.set_xlim(xmin=1e-2, xmax=2)\n",
    "                ax.set_ylim(ymin=8e-1, ymax=2e2)\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "    \n",
    "    \n",
    "    return bin_widths, all_cluster_params, kroupa_diff, counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd5c802-7f21-4010-95d7-24074ef6e688",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assigning cluster numbers to 2MASS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3633f28-bc55-4611-988b-2bd741df95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_2mass_data(tmass_data):\n",
    "    \"\"\"\n",
    "    Assigns cluster numbers to the 2MASS data\n",
    "    \"\"\"\n",
    "    tmass_data_new = tmass_data\n",
    "    \n",
    "    star_ids_data = votable.parse_single_table('Filter_containing_tmassID.vot').to_table()\n",
    "    cluster_data = votable.parse_single_table('Vizier_data_filtered.vot').to_table()\n",
    "    \n",
    "    cluster_data.rename_column('cluster_number', 'Cluster_number')\n",
    "    cluster_data.rename_column('gaiaid', 'GaiaID')\n",
    "    cluster_data.rename_column('g_bp', 'G_bp')\n",
    "    cluster_data.rename_column('g_rp', 'G_rp')\n",
    "    cluster_data.rename_column('parallax', 'Parallax')\n",
    "    cluster_data.rename_column('parallax_error', 'Parallax_error')\n",
    "    cluster_data.rename_column('m_apparent', 'M_apparent')\n",
    "   \n",
    "    \n",
    "    # Sorting data according to Gaia ID\n",
    "    cluster_order = cluster_data['GaiaID'].argsort()\n",
    "    cluster_data = cluster_data[cluster_order]\n",
    "    \n",
    "    id_order = star_ids_data['source_id'].argsort()\n",
    "    star_ids_data = star_ids_data[id_order]\n",
    "    tmass_data_new = tmass_data_new[id_order]\n",
    "    \n",
    "    km_mask = tmass_data_new['k_m']!='NULL'\n",
    "    \n",
    "    tmass_data_new = tmass_data_new[km_mask]\n",
    "    tmass_data_new['k_m'] = tmass_data_new['k_m'].astype(float)\n",
    "    \n",
    "    cluster_data = cluster_data[km_mask]\n",
    "    star_ids_data = star_ids_data[km_mask]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Assigning cluster numbers and the Gaia IDs\n",
    "    tmass_data_new['Cluster_number'] = cluster_data['Cluster_number']\n",
    "    tmass_data_new['GaiaID'] = cluster_data['GaiaID']\n",
    "    tmass_data_new['Parallax'] = cluster_data['Parallax']\n",
    "    tmass_data_new['Parallax_error'] = cluster_data['Parallax_error']\n",
    "    tmass_data_new['M_apparent'] = cluster_data['M_apparent']\n",
    "    \n",
    "    unique_tmass_ids, n_id_occurances = np.unique(tmass_data_new['tmass_oid'], return_counts=True)\n",
    "    \n",
    "    duplicates = unique_tmass_ids[n_id_occurances>1]\n",
    "    \n",
    "    for duplicate in duplicates:\n",
    "        duplicate_pos = np.where(tmass_data_new['tmass_oid']==duplicate)\n",
    "        \n",
    "        tmass_data_new.remove_rows(duplicate_pos)\n",
    "        np.delete(star_ids_data, duplicate_pos)\n",
    "        np.delete(cluster_data, duplicate_pos)    \n",
    "    \n",
    "      \n",
    "    return tmass_data_new, cluster_data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ad227-069a-48f1-b1cf-be6e01dc73e4",
   "metadata": {},
   "source": [
    "## Determining extinction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cdc52fa-2a97-4ae8-94d2-9a706ceecef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extinction(k_iso_fit, m_iso_fit, cluster_data):\n",
    "    \"\"\"\n",
    "    Corrects the extincted stars in the cluster data\n",
    "    -------------------------------------------------\n",
    "    Parameters:\n",
    "    -----------\n",
    "    k_iso_fit: float\n",
    "        Slope of the isochrone line fit\n",
    "        \n",
    "    m_iso_fit: float\n",
    "        y-axis crossing of the isochrone line fit\n",
    "        \n",
    "    Cluster_data: table\n",
    "        2MASS data for the cluster\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    The corrected cluster data\n",
    "    \"\"\"\n",
    "    # Cardelli (1989) table 3 values\n",
    "    A_J = 0.282\n",
    "    A_H = 0.190\n",
    "    A_K = 0.114\n",
    "            \n",
    "    A_jh = A_J - A_H\n",
    "    A_hk = A_H - A_K\n",
    "    \n",
    "    # Length of Av=1 vector\n",
    "    len_ext_vector = np.sqrt(A_jh**2 + A_hk**2)\n",
    "    #print()\n",
    "    #Getting slope for extinction vector            \n",
    "    k_ext_vector, m_ext_vector = np.polyfit(np.array([0, A_hk]), np.array([0, A_jh]), deg=1)\n",
    "    \n",
    "    # Adding extinction column to data table\n",
    "    cluster_data['A_G'] = np.zeros((len(cluster_data)))\n",
    "    cluster_data['A_BP'] = np.zeros((len(cluster_data)))\n",
    "    cluster_data['A_RP'] = np.zeros((len(cluster_data)))\n",
    "    cluster_data['A_J'] = np.zeros((len(cluster_data)))\n",
    "    cluster_data['A_H'] = np.zeros((len(cluster_data)))\n",
    "    cluster_data['A_K'] = np.zeros((len(cluster_data)))\n",
    "    #cluster_data['A_JK'] = np.zeros((len(cluster_data)))\n",
    "    \n",
    "    \n",
    "    # Create x value range\n",
    "    min_x_val = np.min(cluster_data['H-K'].value)\n",
    "    max_x_val = np.max(cluster_data['H-K'].value)\n",
    "    #print(any(np.isnan(cluster_data['H-K'].value)))\n",
    "    #print(max_x_val)\n",
    "    x_range = np.linspace(-5*max_x_val, max_x_val, int(1e6))\n",
    "    \n",
    "    # y_isochrone_line - kx_isochrone_line\n",
    "    m_upper_line = (k_iso_fit*0.16 + m_iso_fit) - k_ext_vector*0.16\n",
    "    m_lower_line = (k_iso_fit*0.33 + m_iso_fit) - k_ext_vector*0.33\n",
    "    \n",
    "    ######################################################################################################\n",
    "    #fig, ax = plt.subplots(1, 2, figsize=(10, 8))\n",
    "    \n",
    "    #ax[0].scatter(cluster_data['H-K'], cluster_data['J-H'], c='b', s=10, alpha=0.5)\n",
    "    #ax[0].plot(x_range, k_iso_fit*x_range + m_iso_fit, linestyle='dashed', color='g')\n",
    "    #ax[0].plot(x_range, k_ext_vector*x_range + m_upper_line, linestyle='dashed', color='m')\n",
    "    #ax[0].plot(x_range, k_ext_vector*x_range + m_lower_line, linestyle='dashed', color='m')\n",
    "    \n",
    "    #ax[0].grid()\n",
    "    #ax[0].set_xlim(-2, 3)\n",
    "    #ax[0].set_ylim(-2, 5)\n",
    "    ######################################################################################################\n",
    "    \n",
    "    \n",
    "    # Find stars above isochrone line\n",
    "    iso_line_mask = cluster_data['J-H'].value>(k_iso_fit*cluster_data['H-K'].value + m_iso_fit)\n",
    "    \n",
    "    upper_line_mask = cluster_data['J-H'].value < (k_ext_vector*cluster_data['H-K'].value + m_upper_line)\n",
    "    lower_line_mask = cluster_data['J-H'].value > (k_ext_vector*cluster_data['H-K'].value + m_lower_line)\n",
    "    extincted_stars_mask = iso_line_mask*upper_line_mask*lower_line_mask #\n",
    "    \n",
    "    extincted_stars = cluster_data[extincted_stars_mask]\n",
    "    #print(len(extincted_stars))\n",
    "    \n",
    "    if len(extincted_stars)==0:\n",
    "        return cluster_data\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        upper_line_mask_2 = cluster_data['J-H'].value > (k_ext_vector*cluster_data['H-K'].value + m_upper_line)\n",
    "        \n",
    "        left_stars_mask = upper_line_mask_2*iso_line_mask\n",
    "        \n",
    "        left_stars = cluster_data[left_stars_mask]\n",
    "        #print(len(left_stars))\n",
    "        \n",
    "        left_stars['A_G'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_BP'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_RP'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_J'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_H'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_K'] = np.empty((len(left_stars)))\n",
    "        left_stars['A_JK'] = np.empty((len(left_stars)))\n",
    "        \n",
    "        lower_line_mask_2 = cluster_data['J-H'].value < (k_ext_vector*cluster_data['H-K'].value + m_lower_line)\n",
    "    \n",
    "        right_stars_mask = lower_line_mask_2*iso_line_mask\n",
    "    \n",
    "        right_stars = cluster_data[right_stars_mask]\n",
    "        #print(len(right_stars))\n",
    "    \n",
    "        right_stars['A_G'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_BP'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_RP'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_J'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_H'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_K'] = np.empty((len(right_stars)))\n",
    "        right_stars['A_JK'] = np.empty((len(right_stars)))\n",
    "        \n",
    "        # Create new line for each point by finding its m_value\n",
    "        # m = y - kx\n",
    "        m_values = extincted_stars['J-H'].value - k_ext_vector*extincted_stars['H-K'].value\n",
    "        \n",
    "        extinctions = np.empty((len(extincted_stars))) # \n",
    "        \n",
    "        # Looping over every extincted star in cluster\n",
    "        for i, m_value in enumerate(m_values):\n",
    "            #print(i)\n",
    "            # Find where it crosses isochrone line for each star\n",
    "            # |extinction_vector_star_slope - isochrone_line_fit|\n",
    "            \n",
    "            #x_var = sp.symbols('x')\n",
    "            #to_solve = (k_ext_vector*x_var+m_value) - (k_iso_fit*x_var+m_iso_fit)\n",
    "            #x_coord = float(sp.solve(to_solve)[0])\n",
    "            \n",
    "            diff = np.abs((k_ext_vector*x_range+m_value) - (k_iso_fit*x_range+m_iso_fit))\n",
    "            \n",
    "            # Crossing is where the difference is closest to zero\n",
    "            crossing = np.where(diff==np.min(diff))[0][0]\n",
    "            \n",
    "            # Crossing coordinate\n",
    "            x_coord = x_range[crossing] # H-K colour\n",
    "            y_coord = k_ext_vector*x_coord+m_value # J-H colour\n",
    "            \n",
    "            cluster_data['J-H'].value>(k_iso_fit*cluster_data['H-K'].value + m_iso_fit)\n",
    "            \n",
    "            while y_coord>=k_iso_fit*x_coord + m_iso_fit:\n",
    "                crossing = crossing - 1\n",
    "                x_coord = x_range[crossing] # H-K colour\n",
    "                y_coord = k_ext_vector*x_coord+m_value # J-H colour\n",
    "            \n",
    "            extincted_stars[i]['H-K'] = x_coord*u.mag\n",
    "            extincted_stars[i]['J-H'] = y_coord*u.mag\n",
    "        \n",
    "            # Find distance between/length of isochrone line and data point\n",
    "            dx = cluster_data[i]['H-K'].value - x_coord\n",
    "            dy = cluster_data[i]['J-H'].value - y_coord\n",
    "        \n",
    "            length = np.sqrt(dx**2 + dy**2)\n",
    "            #print(length)\n",
    "            # Divide by A_v=1 length to get extinction\n",
    "            extinctions[i] = length/len_ext_vector\n",
    "        \n",
    "    \n",
    "        extincted_stars['A_G'] = 0.789*extinctions * u.mag\n",
    "        extincted_stars['A_BP'] = 1.002*extinctions * u.mag\n",
    "        extincted_stars['A_RP'] = 0.589*extinctions * u.mag\n",
    "    \n",
    "        #extincted_stars['A_J'] = 0.243*extinctions * u.mag\n",
    "        #extincted_stars['A_H'] = 0.131*extinctions * u.mag\n",
    "        #extincted_stars['A_J'] = 0.078*extinctions * u.mag\n",
    "        #extincted_stars['A_JK'] = (0.243*extinctions - 0.078*extinctions)* u.mag\n",
    "    \n",
    "        # Mean\n",
    "        #print(extinctions)\n",
    "        mean_A_G = np.mean(0.789*extinctions) * u.mag\n",
    "        mean_A_BP = np.mean(1.002*extinctions) * u.mag\n",
    "        mean_A_RP = np.mean(0.589*extinctions) * u.mag\n",
    "    \n",
    "        mean_A_J = np.mean(0.243*extinctions) * u.mag\n",
    "        mean_A_H = np.mean(0.131*extinctions) * u.mag\n",
    "        mean_A_K = np.mean(0.078*extinctions) * u.mag\n",
    "        mean_A_JK = mean_A_J-mean_A_K\n",
    "    \n",
    "        left_stars['A_G'] = mean_A_G\n",
    "        left_stars['A_BP'] = mean_A_BP\n",
    "        left_stars['A_RP'] = mean_A_RP\n",
    "    \n",
    "        left_stars['A_J'] = mean_A_J\n",
    "        left_stars['A_H'] = mean_A_H\n",
    "        left_stars['A_K'] = mean_A_K\n",
    "        #left_stars['A_JK'] = mean_A_JK\n",
    "    \n",
    "        left_stars['J'] = (left_stars['J'].value - left_stars['A_J'].value)*u.mag\n",
    "        left_stars['H'] = (left_stars['H'].value - left_stars['A_H'].value)*u.mag\n",
    "        left_stars['K'] = (left_stars['K'].value - left_stars['A_K'].value)*u.mag\n",
    "        #left_stars['J-K'] = (left_stars['J'].value - left_stars['K'].value)*u.mag\n",
    "        left_stars['J-H'] = (left_stars['J'].value - left_stars['H'].value)*u.mag\n",
    "        left_stars['H-K'] = (left_stars['H'].value - left_stars['K'].value)*u.mag\n",
    "\n",
    "    \n",
    "    \n",
    "        right_stars['A_G'] = mean_A_G\n",
    "        right_stars['A_BP'] = mean_A_BP\n",
    "        right_stars['A_RP'] = mean_A_RP\n",
    "        \n",
    "        right_stars['A_J'] = mean_A_J\n",
    "        right_stars['A_H'] = mean_A_H\n",
    "        right_stars['A_K'] = mean_A_K\n",
    "        #right_stars['A_JK'] = mean_A_JK\n",
    "    \n",
    "        right_stars['J'] = (right_stars['J'].value - right_stars['A_J'].value)*u.mag\n",
    "        right_stars['H'] = (right_stars['H'].value - right_stars['A_H'].value)*u.mag\n",
    "        right_stars['K'] = (right_stars['K'].value - right_stars['A_K'].value)*u.mag\n",
    "        #right_stars['J-K'] = (right_stars['J'].value - right_stars['K'].value)*u.mag\n",
    "        right_stars['J-H'] = (right_stars['J'].value - right_stars['H'].value)*u.mag\n",
    "        right_stars['H-K'] = (right_stars['H'].value - right_stars['K'].value)*u.mag\n",
    "        \n",
    "        \n",
    "        # Replacing all extincted stars' values with the corrected values\n",
    "        cluster_data[extincted_stars_mask] = extincted_stars\n",
    "    \n",
    "        cluster_data[left_stars_mask] = left_stars\n",
    "        cluster_data[right_stars_mask] = right_stars\n",
    "    \n",
    "        ######################################################################################################\n",
    "        \n",
    "        #ax[1].scatter(cluster_data['H-K'], cluster_data['J-H'], c='b', s=10, alpha=0.5)\n",
    "        #ax[1].plot(x_range, k_iso_fit*x_range + m_iso_fit, linestyle='dashed', color='g')\n",
    "        #ax[1].plot(x_range, k_ext_vector*x_range + m_upper_line, linestyle='dashed', color='m')\n",
    "        #ax[1].plot(x_range, k_ext_vector*x_range + m_lower_line, linestyle='dashed', color='m')\n",
    "        \n",
    "        #ax[1].grid()\n",
    "        #ax[1].set_xlim(-2, 3)\n",
    "        #ax[1].set_ylim(-2, 5)\n",
    "        \n",
    "        #plt.tight_layout()\n",
    "        #plt.show\n",
    "        ######################################################################################################\n",
    "    \n",
    "        return cluster_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750e4f1-c876-41d2-a208-f40f31b3afcb",
   "metadata": {},
   "source": [
    "## Calculating extinction values for the different passbands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef6691d4-3e75-4a88-ab6e-988167cea828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Av_calc(Rv):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "    -------\n",
    "    Array with extinction parameters for the colour filters\n",
    "    \"\"\"\n",
    "    # J, H, K\n",
    "    a = np.array([0.4008, 0.2693, 0.1615])\n",
    "    b = np.array([-0.3679, -0.2473, -0.1483])\n",
    "    A_Av = a + b/Rv\n",
    "    return np.round(A_Av, decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a4819-ef87-4790-9c1a-2d595b86f246",
   "metadata": {},
   "source": [
    "## Extinction coefficient function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e1e188b-432f-4625-a4ab-5628a548b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extinction_per_band(band, X, Av):\n",
    "    coefficients = QTable.read('Data/Extinction_law_coeff/Fitz19_EDR3_MainSequence.csv', \n",
    "                               format='csv', delimiter=',', \n",
    "                               names=['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'a10', \n",
    "                                      'Xname', 'Band'])\n",
    "    \n",
    "    coefficients_mask = coefficients['Xname']=='BPRP'\n",
    "    \n",
    "    coefficients = coefficients[coefficients_mask]\n",
    "    \n",
    "    if band=='G':\n",
    "        coeff = coefficients[coefficients['Band']=='kG']\n",
    "        \n",
    "    elif band=='BP':\n",
    "        coeff = coefficients[coefficients['Band']=='kBP']\n",
    "        \n",
    "    elif band=='RP':\n",
    "        coeff = coefficients[coefficients['Band']=='kRP']\n",
    "        \n",
    "    \n",
    "    k = coeff['a1'] + coeff['a2']*X + coeff['a3']*X**2 + coeff['a4']*X**3 + \\\n",
    "        coeff['a5']*Av + coeff['a6']*Av**2 + coeff['a7']*Av**3 + \\\n",
    "        coeff['a8']*Av*X + coeff['a9']*Av*X**2 + coeff['a10']*X*Av**2\n",
    "    \n",
    "    extinction = k*Av\n",
    "    \n",
    "    return extinction*u.mag\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab3bcac-0351-45ee-80ca-122336fc43fc",
   "metadata": {},
   "source": [
    "## Estimating density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e513e4a5-cc30-418f-9964-942bbb658cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def density(ra, dec, cluster_distance, cluster_number, \n",
    "            plot_centre=True, save_plot_centre=False):\n",
    "    \n",
    "    ra = ra[:, np.newaxis]\n",
    "    dec = dec[:, np.newaxis]\n",
    "    pos = np.concatenate([ra, dec], axis=1)\n",
    "    \n",
    "    d_cl = cluster_distance[0]\n",
    "    \n",
    "    estimate = KMeans(1, n_init=100) # Only want centroid of one cluster\n",
    "    estimate.fit(pos)\n",
    "    col_kmeans = estimate.predict(pos) # Predicts closest cluster that each sample in pos belongs to\n",
    "    centroid_x = estimate.cluster_centers_[0][0]\n",
    "    centroid_y = estimate.cluster_centers_[0][1]\n",
    "    centroid = SkyCoord(ra=centroid_x, dec=centroid_y, frame='icrs', unit='deg')\n",
    "    pos_stars = SkyCoord(ra=pos[:, 0], dec=pos[:, 1], frame='icrs', unit='deg')\n",
    "        \n",
    "    \n",
    "    diffs_x = np.abs(pos[:, 0] - centroid_x*u.deg)\n",
    "    diffs_y = np.abs(pos[:, 1] - centroid_y*u.deg)\n",
    "    r_diffs = np.sqrt(diffs_x**2 + diffs_y**2) # deg\n",
    "    max_r = np.max(r_diffs) # deg\n",
    "    max_r_rad = max_r.value * np.pi/180 * u.rad\n",
    "    max_r_pc = cluster_distance*np.tan(max_r_rad)\n",
    "    \n",
    "    r_range = np.linspace(0, max_r, 1000) # deg\n",
    "    \n",
    "    n_stars = len(ra)\n",
    "    \n",
    "    n_90percent = np.round(0.90*n_stars)\n",
    "    n_75percent = np.round(0.75*n_stars)\n",
    "    n_50percent = np.round(0.50*n_stars)\n",
    "    \n",
    "    n_stars_per_radius = np.empty(len(r_range))\n",
    "    \n",
    "    for i, r in enumerate(r_range):\n",
    "        n_stars_mask = r_diffs<r\n",
    "        n_stars_per_radius[i] = len(r_diffs[n_stars_mask])\n",
    "        \n",
    "    \n",
    "    # 90%\n",
    "    _90_diff = np.abs(n_stars_per_radius - n_90percent)\n",
    "    closest_90_percent = np.min(_90_diff)\n",
    "    _90_percent_pos = np.where(_90_diff==closest_90_percent)[0]\n",
    "    \n",
    "    if len(_90_percent_pos)>1:\n",
    "        _90_percent_pos = _90_percent_pos[-1]\n",
    "    \n",
    "    _90_n = n_stars_per_radius[_90_percent_pos]\n",
    "    r_90 = r_range[_90_percent_pos] #deg\n",
    "    r_90_pc = d_cl*np.tan(r_90.value * np.pi/180 * u.rad)\n",
    "    \n",
    "    \n",
    "    # 75%\n",
    "    _75_diff = np.abs(n_stars_per_radius - n_75percent)\n",
    "    closest_75_percent = np.min(_75_diff)\n",
    "    _75_percent_pos = np.where(_75_diff==closest_75_percent)[0]\n",
    "    \n",
    "    if len(_75_percent_pos)>1:\n",
    "        _75_percent_pos = _75_percent_pos[-1]\n",
    "    \n",
    "    _75_n = n_stars_per_radius[_75_percent_pos]\n",
    "    r_75 = r_range[_75_percent_pos] #deg\n",
    "    r_75_pc = d_cl*np.tan(r_75.value * np.pi/180 * u.rad)\n",
    "    \n",
    "    \n",
    "    # 50%\n",
    "    _50_diff = np.abs(n_stars_per_radius - n_50percent)\n",
    "    closest_50_percent = np.min(_50_diff)\n",
    "    _50_percent_pos = np.where(_50_diff==closest_50_percent)[0]\n",
    "    \n",
    "    if len(_50_percent_pos)>1:\n",
    "        _50_percent_pos = _50_percent_pos[-1]\n",
    "    \n",
    "    _50_n = n_stars_per_radius[_50_percent_pos]\n",
    "    r_50 = r_range[_50_percent_pos] #deg\n",
    "    r_50_pc = d_cl*np.tan(r_50.value * np.pi/180 * u.rad)\n",
    "    \n",
    "    #print(r_90_pc, r_75_pc, r_50_pc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Whole radius\n",
    "    _90percent_area = np.pi*r_90_pc**2 # pc**2\n",
    "    _90percent_density = _90_n/_90percent_area\n",
    "    \n",
    "    \n",
    "    _75percent_area = np.pi*r_75_pc**2\n",
    "    _75percent_density = _75_n/_75percent_area\n",
    "    \n",
    "    \n",
    "    # 1/2 half radius\n",
    "    _50percent_area = np.pi*r_50_pc**2 # pc**2\n",
    "    _50percent_density = _50_n/_50percent_area\n",
    "    \n",
    "    \n",
    "    if plot_centre:        \n",
    "        fig, ax = plt.subplots(figsize=(7, 7))\n",
    "        \n",
    "        plt.minorticks_on()\n",
    "        \n",
    "        ax.scatter(pos[:, 0], pos[:, 1], c=col_kmeans, cmap='rainbow', s=10, alpha=0.5, \n",
    "                   label='Cluster stars')\n",
    "        \n",
    "        ax.scatter(centroid_x, centroid_y, c='r', marker='+', s=40, label='Centroid')\n",
    "        full_circle = plt.Circle((centroid_x, centroid_y), radius=r_90.value, fill=False, \n",
    "                                 lw=2, color='darkgreen', label='90% radius')\n",
    "        ax.add_artist(full_circle)\n",
    "        \n",
    "        circle_3_4 = plt.Circle((centroid_x, centroid_y), radius=r_75.value, fill=False, \n",
    "                                 lw=2, color='limegreen', label='75% radius')\n",
    "        ax.add_artist(circle_3_4)\n",
    "        \n",
    "        half_circle = plt.Circle((centroid_x, centroid_y), radius=r_50.value, fill=False, \n",
    "                                 lw=2, color='lime', label='50% radius')\n",
    "        ax.add_artist(half_circle)\n",
    "        \n",
    "        ax.set_xlabel('Ra [deg]')\n",
    "        ax.set_ylabel('Dec [deg]')\n",
    "        ax.set_title(f'Cluster {cluster_number} with centroid')\n",
    "        \n",
    "        ax.set_xlim(xmin=centroid_x-max_r.value-1, xmax=centroid_x+max_r.value+1)\n",
    "        ax.set_ylim(ymin=centroid_y-max_r.value-1, ymax=centroid_y+max_r.value+1)\n",
    "        ax.grid(True, which='both')\n",
    "        \n",
    "        ax.legend()\n",
    "        \n",
    "        if save_plot_centre:\n",
    "            plt.savefig(f'Plots/Finding_cluster_centre_{cluster_number}.png', bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    #if (tot_cluster_density.unit==1/u.pc**2)&(density_3_4.unit==1/u.pc**2)&(half_radius_cluster_density.unit==1/u.pc**2):\n",
    "    #    return np.array([tot_cluster_density.value, density_3_4.value, half_radius_cluster_density.value])\n",
    "    #\n",
    "    #else:\n",
    "    #    print('Not right and/or same unit!')\n",
    "    \n",
    "    densities_array = np.array([_90percent_density.value, \n",
    "                                _75percent_density.value,\n",
    "                                _50percent_density.value], dtype=object)\n",
    "    \n",
    "    return densities_array.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
